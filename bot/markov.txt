I might have posted this before, but for developers looking for a shorn-down Firebug equivalent for Webkit/Safari, you can enter the following snippet into your Mac’s Terminal:

This will give you the ability to “Inspect Element”, which is very, very useful. It brings up the Mac Web Developer Console, a sort of useful multi-tool for the web. In fact, after the appearance of the ubiquitous and incredibly useful FireBug, it would seem that most of the major browsers are going the way of integrated web-development tool modules. Nice!

I’m not going to lie — FireBug completely changed the way that I write markup. Instead of laboriously fiddling with a CSS value and refreshing repeatedly (How does 74px look? How does 80px look? ), I just toss in a nonsense value, then inspect the element I’m working with in FireBug. From there, I can select any of the values that I want to play with, and hold the up/down keys to watch that value change in real-time. You can also add new CSS properties on the fly to see how they change the page. Useful!

The Safari Web Developer Console allows you to inspect elements and change CSS, but you can’t slide elements. Which is okay, I guess. I mean, every product works a little bit differently.

The Safari Console *also* allows you to determine the full download size of a page of your website. Notably, this website’s index page, pictures and all, occupies less than 100kb of space — but Javascript plugins (jQuery, jQuery UI, and the plugin for code rendering) and sIFR eat up another 400kb of space, making the whole site a bit of a pig. Alternatively, I’ve written full-on Wordpress sites that pack tidily into less than 70kb. Google’s front-page clocks in at a svelte 36kb, and Yahoo’s front-page a beefy 1Mb.

Notably, this functionality exists in FireBug, but it’s not nearly as pretty or intuitive, so I never really played around with it.

In fact, the Safari Console has a few features that could be really helpful for someone pulling a page to bits. It lists all of the images used on the page, where they come from, and their size and dimensions. It also lists all of the stylesheets and javascript elements loaded on a page. Actually, looking at my site, one of the reasons that it’s so big is that the JavaScript Code Highlighter that I’m using depends on a number of ‘brush’ files (one for each language family being highlighted), each with a very large, identical copyright notice. I bet trimming that down could cut a couple kilobytes from this site’s hefty frame.

When I started programming in Javascript, I found also that FireBug logs Javascript errors in a tidy format that makes it painfully clear what’s gone wrong with the page. As well, you can toss a console.log( “foo” ) statement in your page, to print output directly to the FireBug console. For debugging, this is like sex cheese.

Notably, this also fills me with frustration whenever a jQuery library module starts throwing an obscure error. Am I doing something wrong?

The Safari Console seems also to have a console for logging. I haven’t really fiddled with it. For that sort of work, I’m almost guaranteed to go to FireBug unless it’s a Safari-specific error.

So, Safari and Firefox both have robust developer console systems, albeit each one with strengths and weaknesses. What does Internet Explorer have?

crickets

tumbleweed

Actually, you’d be surprised. Internet Explorer is home to a small set of development tools as well, for those developers in the unfortunate circumstance of having to develop for it as a primary. I haven’t tried any of them, and they seem to be quite the mishmash of miscellany, but it’s good to know that the tools exist.

Google Chrome has a very rudimentary set of built-in developer tools, although it’s so small as to be nearly meaningless &mdash you can’t even change CSS on the fly.

That just leaves Opera, and, while it was an empty field for a while, they’re currently working on Dragonfly, a yet-another-developer-console, for Opera. Considering, however, Opera’s much-greater-pull in the mobile world, they’re integrating a host of tools that work with assorted mobiles. It’s still in ‘alpha’, though, so the software might not be as rock solid as one might hope.

I’ve recently switched from the Wordpress standard of “Huge Wall of Text” to the perhaps-less-popular “More >>>” system on my website. What that means is that, on the front page of my website, instead of being faced with everything I’ve written for the past month or so, you instead get just an excerpt and a link to more.

I did this, mostly because a select few of my posts have been very, very long. I’m looking at you, Public Static Void Main Args. It can be troublesome to have to scroll through several pages of content when you’re looking to go back a couple of pages looking for a specific blog post.

There are other reasons- I think that the excerpt model is a good one, providing users with a quick decision on whether or not to read the full article. Wired does it, Cracked does it… it seems to make sense. On a traditional blog, though, sometimes it’s nice to just start reading down &mdash without having to page from article to article. Coding Horror manages to make a successful blog out of only ever displaying one blog post at a time, although the articles there are guaranteed to be at least a page each, followed by all of the comments in the world.

So, the question is — which layout do you prefer, and why?

Emma is still afraid of me, though. She’s a red trie, miniature Australian Shepherd, with differently coloured eyes, and just over a year old. Very much less outgoing than Mya, who could only be described as “aggressively cute”. I’m sure she’ll get used to me eventually, though.

In my CMPT 475 (Software Engineering 2) class, the professor has repeatedly posited that “Something Is Always Better Than Nothing” — so far, in reference to the development of naming standards and the adoption of development methodologies.

Horseshit.

Now, ‘no development methodology’ may be a disorganized way to go about development, but a small team can make things work with little more than a source control system and a little bit of proximity.

It’s easy, however, to imagine both development methodologies and naming standards that would be actively detrimental to a project, both in terms of wasting time and in terms of actively confusing the system.

Starting with naming schemes— first and foremost, we can easily imagine a naming scheme that is actively detrimental to any project.

This is, of course, a horrible, horrible naming scheme. A single line might end up looking like _12 = _14 + _29; . The only sensible way to make it work would be to maintain a table of data, mapping ‘n’ values to variable contents (maybe in code comments)? — nevertheless, there is no way that this naming scheme could be made elegant.

That’s— of course— a theoretical naming standard, and a pretty nonsensical one at that. Similar naming systems have popped up at theDailyWtf — the ‘a, b, c, aa, bb, cc’ variable naming standard seems to appear a lot, agonizingly enough. In general, though, we’ll consider this scheme totally nonsensical.

There are other schemes, however, that are very serious and standard, and still actively detrimental to a project. Here I refer to Hungarian Notation— and by Hungarian Notation, I mean “Systems Hungarian”, not the original “Apps Hungarian”. Apps Hungarian, when applied judiciously, can be a good thing for a project. Joel Spolsky wrote an entire article about it, here:

When it comes down to it, Systems Hungarian has some uses— but in many, many arens — for example, a small project in a dynamically typed language — it is utterly useless. It’s just a waste of time that introduces unnecessary code ugliness.

Okay, development methodology can contribute a lot to the success of a project, I will admit. A carefully selected methodology can help a software project come in on time and on budget.

The trouble is, however, the postulate that any development methodology is better than no development methodology.

Once again— two guys with a subversion repository — with no development methodology at all — will likely outperform two guys using a heavyweight system like the RUP. The amount of overhead and paperwork involved in a heavyweight methodology almost necessitate a full—time project manager to learn it and deal with it all. Sure, for larger, longer projects where you’re managing hordes of replaceable cogs, you’re going to need some serious Process — but if you’re building a little blog package with one other guy, well, too much Process just wastes your time and holds you back.

Seriously, the ‘anything is better than nothing’ mindset is almost always a very bad idea in the tech world. Most of the time, ’something is better than nothing’ — I’d rather have the Vault or even Microsoft SourceSafe (shudder) than no source control at all — but we must not confuse minimally functional solutions with actively detrimental solutions.

So, I’ve been experimenting with sIFR, as a way to use Univers fonts on my website without having to generate images for each individual blog-post title on my site.

Now, I love the idea of sprucing up dynamic content with real typography — but I don’t think that sIFR is the answer, at least not yet.

Yes, okay, we’re on the internet of the future, we have infinite bandwidth and all computers are speed demons, sure. The thing is, though, nothing loads faster as blog title headers than plain text. sIFR even seems to underperform properly-tweaked images.

So sIFR is slow. It feels slow.

I’m not sure if you’ve noticed, but sIFR seems to be cutting off chunks of headline at random on my site. Not cool! That’s a gamebreaking bug for me.

My first course of action here will be to replace it with sIFR 3, the fresh version. Should that fail, I’m back to good ol’ fashioned text.

When it comes down to it, dynamically rendering fonts using Flash intuitively feels like it’s the wrong solution for web typography.

For one thing, most web browsers already render fonts, fine. Why go to all of the extra effort to render additional fonts outside of the browser?

In an ideal world, one would just be able to embed a font straight-up in the page, file and all. Most font foudries would, however, get their panties all atwist at the thought of people getting one of their expensive, expensive fonts just… sent to them. Over the internet. And now they can use that font for whatever they want, forever.

So, once again, the mighty beast of copyright stands between us and the most elegant technical solution.

I suppose one could champion a movement for distribution of Creative-Commons or similarly open-licensed fonts. Perhaps someone could push some of the major browsers to include some fonts from the Open Font Library - or at least, allow people to embed fonts in webpages if they are using open license fonts. (This of course creates the problem of people hacking closed-source fonts to make them appear to be open-sourced fonts. See? This is a tough problem. )

The Open Font Library itself could use a new influx of life, through more participation from developers and designers. Developers could introduce some features to make it more relevant and useful, like the ability to preview fonts, sort them by popularity, that sort of good thing. Designers — well — Open Typography needs a hero, an Adrian Frutiger, a William Caslon, a John Baskerville, a … Carol Twombly.

Imagine if each Firefox update came with 3 new fonts that Web Developers could count on. Would it be a bad idea? It would make pages less standard, and developers would have to use the font-family tag properly — first using a OpenFont font, then a Mac Standard, then a Windows Standard, and finally the Default Family.

Typography on the web needs a hero. Or a couple of heroes. Or many heroes. It’s important.

Of course, until the state of open typography on the web improves, our only option for dynamic fonts are to hack them into either Flash or images - and I think that ‘images’ might be the more efficient of the two, even if it’s the less accessible.

The best solution, at least in terms of speed, ease, accessibility, and simplicity, seems just be to stick with the small subset of available fonts that come with the system. But we can do better, right?

Really, you can just drop a HTML widget in and style it. You could do it RIGHT NOW. It’s that easy.

The hard part is… you know… actually using Twitter. I pay for text messages, so I’m not going to go to the trouble of setting that up - and I rarely visit Twitter in the course of a regular day. Someone had a way to automatically sync Facebook status and Twitter status. I should learn about that thing.

This site’s theme has been updated to include more glossy, unnecessary features, and a new logo.

It now uses sIFR and jQuery UI to provide nice fontage and moving accordion-style effects.

Here are some things I’ve learned.

Really, you can just drop a HTML widget in and style it. You could do it RIGHT NOW. It’s that easy.

The hard part is… you know… actually using Twitter. I pay for text messages, so I’m not going to go to the trouble of setting that up - and I rarely visit Twitter in the course of a regular day. Someone had a way to automatically sync Facebook status and Twitter status. I should learn about that thing.

I’m worried that, between Google Analytics, sIFR, Twitter, jQuery, and Code Syntax Highlighting, my page is loading too many things on first-visit. Seriously, the overhead upon first-visiting my site can amount to as much as a second! I’m going to need to look at maybe cutting down on some of the largesse.

I mean, technical features are the wave of the future and all, but Travis’s site is written in straight-up static HTML (he does it with some sort of crazy homebrew macro system, or so I hear) - contains everything he’s ever written, and it still loads faster than mine. Oh, static content, you scamp.

I’ve got jQuery/UI loading from the Google Content Delivery Network (free bandwidth, right? it should be fast, too)- and my site doesn’t suffer from a dearth of images- but thanks to the bulkily written Code Syntax Highlighter, jQuery, and SIFR, the first load of a page precaches about 17 different files on the client computer. Yikes.

Some paring may need to be done.

sIFR is a neat idea- I’m note sure if I quite like it, yet, but being able to use Trade Gothic LT STD as a header font instead of … Verdana, or Arial- well, it’s a nice choice.

The only trouble is, introduce the sIFR text-replacement at the same time as the jQuery Accordion widget, and you have a mess on your hands. After a bit of research on both sIFR and jQuery (”What if I reload sIFR every time the Accordion changes?”) I just decided to drop sIFR from the Accordion effect.

In terms of amount-of-joy-delivered per unit-of-work-expended, Gravatar avatars have been my favourite blog add ever. Heck, I even built a Django template-tag processor that automatically Gravatarizes e-mail addresses. Internet API calls are fun!

I’m not sure if I should replace this site’s favicon. I mean, the favicon that I’m currently using is the first one I ever put up- it went with the first-ever website theme. I’ve since replaced the theme, but I still like that little dude and his arrow.

My new site logo certainly does lend itself to favicoization.

On top of that, I still have the little Cabooses from my last major theme update around. I’m not sure if I should think of them as cute reminders of themes past or crufty remnants of … themes past.

I suspect I should replace the both of them with new elements that match the site.

I also have to update my portfolio (see about getting hired soon, ya?) … oh, and I should include a link to my comic site in there somewhere (Maybe in “About Me”?)…

So much work to do. Tell me what you think!

Many of you who are CS students, gamers, or programmers in general have found occasions where you’re going to need to work for 32 hours at a stretch. The first thing you do is go straight for the cans of Red Bull - or Monster, or Bawls, or RockStar, or EnergyBuzz, or what-have-you.

But if you’re going to stay up late, this is not the right strategy. The sudden, massive rush of caffeine in your system will keep you up a few hours, but you’ll be jittery, you’ll have to pee every couple of hours, and it’ll wear off quickly.

Thus, we have Curtis’s Amazing Stay Up Way Past Your Bedtime Strategy, field-tested with many a far-too-late-night.

Seriously, the first tip is to stay away from any drink that offers 9000 milligrams of Taurine and tastes like metallic chalk with a hint of sugar. Instead, try tea.

Tea? That’s not a manly gamer drink!

‘Sho is! A cup of tea has about half as much caffeine as a cup of coffee, but it also contains antioxidant polyphenols which extend the efficacy of said caffeine. (Source: Alton Brown)

What that means is that a cup of tea has got you covered for at least 5 hours of action, without the jitters, constant peeing, and inevitable crash.

Coding can be a narrow, cramping, uncomfortable process. Sitting at a table for many hours at a stretch isn’t necessarily ergonomically sound in the first place- but pile on a 16-hour-day on top of that and you’re going to hurt yourself. On top of that, it’s impossible to just code for that much time- your brain needs frequent rests to process new information, plan ahead, and just not code.

So- at LEAST every 20-30 minutes- step away from your computer and jog about a bit, or do some pushups, or stretch and move around a bit. Not only does it keep you from seriously injuring yourself with poor ergonomics, it gets your blood flowing and gives you some energy back. And that’s energy you’re going to need for late-night coding.

If you’re going to work for a very long stretch, you’re going to need to fit some sleep in there, whether you like it or not. I find that 4-5 hours will do it for you pretty well.

Short catnaps can be effective for some, but I have the problem of sleep inertia- once I get started sleeping, it’s going to be absolutely horrifying to get back up again.

If you follow my advice, well… try to organize things so that you don’t have to follow my advice. It’s really quite unpleasant. Good luck!

Those of you who browse reddit frequently may have encountered the following paper: Are You Living In A Computer Simulation?.

You can read it, if you like. It’s a bit wordy, but the gist of the argument is this: start with the postulate that posthuman civilizations will have computing power enormous enough to run ‘people simulators’. The argument is then, either,

Humans will never reach the ‘posthuman’ stage.
Posthuman civilizations will never run ‘people simulators’, or
It is almost certain that you are currently running in a computer simulation.
The author argues that - being as we’re unsure as to which one is actually true- we should assign each possibility an equal chance.

Now, here are my objections to the theory.

1. Universes can’t be simulated very easily. While running a ‘people simulator’ shouldn’t be altogether too difficult- I mean, there’s only so much ‘people’ to go around- our environment is a much more tricky matter. It would be impossible to run a simulation of the universe down to the quantum level- for one thing, storing a universe full of data would require at least an equivalent universe full of data storage. (If you think about it, even if we used the quantum spin of every electron in the universe to store data, we would only have enough data storage to hold the quantum spin of every electron in a universe. )

2. Computers are Hard When it comes down to it, some computer problems just can’t be solved in a reasonable amount of time. It’s easy to work on computers and run into a problem that will take too long to solve, regardless of processor power. Very large data sets with exponential or factorial solution times become literally impossible to solve for - and n-body simulation of an entire universe would certainly fall under this purview. Even with nigh-infinite computing power at our fingertips, nigh-more-infinite computing speed would be required to solve some of these problems. The estimate of 10^36-10^37 operations per second to simulate all of human history seems a bit naively low- keeping track of mere gravity for a single galaxy worth of atoms (10^69 atoms- large data set, and then an exponential growth rate to the algorithm’s run time) would require a lot more computing speed than that.

3. Universe-Spanning Supercomputers are Bound To Be Expensive - Even expecting that we’ll find ways to build planet-sized supercomputers that can perform untold numbers of operations per second and store unimaginable amounts of data - assuming there are no as-yet-undiscovered physical laws of the Universe putting hard universal caps on this sort of thing- putting an entire planet or galaxy to work simulating a little mini-Earth would probably be an expensive task. We have a limited number of galaxies to work with, you know.

4. Lossy So, from 1 and 2, one can then conclude that a Universe simulation would have to be extremely lossy - and by ‘lossy’ I mean “If you’re not looking at Pluto, it’s not there.” The only trouble is, that means that in order to keep us from discovering that we live in a lossy universe- by simulating universal properties for us to discover- our simulation needs to be both omniscient and super-intelligent. While computing power may be tremendous in the future, omniscient super-intelligent universe management sounds like a difficult software package to put together, no matter how super-powered the hardware may be. The Universe would need to be Intelligently Designed- not simulated- and most people with a solid grounding in the sciences have trouble accepting Intelligent Design for a number of reasons.

5. Infinitely Nested Lossy Universes. Simply enough- if our Universe is heavily lossy, to save computational time and storage space, we would lack the computational time and storage space to run our own Universe. The sub-universe that we run would have to be aggressively simpler. We then get a sort of Matryoshka doll effect- with each Universe being significantly less complex than the last. I can’t see this being possible for any more than one or two iterations at best. (In the same way, running a VM in a VM in a VM will suck up all of the system resources of most of the VM’s, and going more than a few iterations down becomes extremely inefficient- and sort of pointless. )

So, we now have the three original postulates, revamped to address some of my concerns. Either…

Humans will never reach the stage where they have enough computing power to simulate entire universes, be it by extinction or sheer lack of Universal computing clout.
Humans will not be willing to spend the incredible amount of time and resources required to Intelligently Design and Manage every element of a complex universe.
You are almost certainly living in a computer simulation.
Now, given that these are all unknowns, we could assign them an equal chance of being correct- but that’s not how unknowns work. Instead, we will assign much heavier likelihood to the first two, with a very mild chance that the third- a wacky out-of-third-base theory- might potentially be correct. In the same way, however, there’s a mild chance that the Christian God (or a Greek Pantheon) might be intelligently designing and managing the universe in the same way. I lend little credence to any of these theories.

Thus: Are you living in a computer simulation? Probably not.

I’ve finally put up a site for my comics. It’s at ikoverse.com, and it’s snazzy, new, and awesome.

It’s not just a site for my comics- it’s the early stages of a publishing platform for many comics- although the whole thing needs a lot of work before it reaches that stage.

It’s built in Django, with jQuery, and has a couple of features that I’m at least a little bit proud of. More details here.

And, in order to commemorate the launch of the site? There’s a brand new comic up and ready.

This is part 5 of a many-part series - a crash course on web basics, from Apache to Zend.

With HTML and CSS down, you can create static websites that look great. But that’s web-page-design, and we’re talking about web programming.

All of the dynamic content in a web-page is usually handled by a programming language of some sort- and if you’re building the most simple of dynamic web-pages, that’s all you’ll need. The rest of the time, though, you’ll need some sort of data model.

As a real programmer, the first thing you’ll probably do when dealing with any sort of dynamic data access is produce, manage, and track a series of flat files. You might have one marked ‘users’ with a list of users and passwords, and another marked ‘contact information’, with contact information for each of the users.

This is messy, though.

First of all, it’s hard. You have handle all of the file management mechanics for opening and closing a file, updating, retrieving, and deleting data, and serializing object data.

Second of all, it’s inefficient. If you want to search through the data, either you need to produce some sort of indexing scheme, or you need to open, trawl, process, and search though every line of data in your flat files.

If you’re a real programmer, you’re going to start working on a system- some automatic system that handles the file management, the data indexing, the serialization, the indexing and searching, caching (for efficiency) - the whole works. At this point, what you have built is a database.

A database is a service that runs on your computer- much like a web server. The trick is that, instead of serving up HTML, it just doles out steaming hot piles of fresh data.

Databases are organized into ‘tables’- much like the sort of tables one would encounter in Excel.

Now, imagining you had a giant database table, filled with user information- firstname, lastname, email, phone number, address, city, province, country - all standard stuff. (Although ‘province’ is often replaced by ‘region’ in software that must deal with states, provinces, prefects, and what-have-you.)

If I want to find the address of user ‘Curtis Lassam’, or produce a list of all Lassam family members living in British Columbia, it’s quite easy. I have a database. All I would need to do is connect to the database, send the database a ‘query’ containing the data that I’m looking for, and then have the database send back the requested data. Easy-peasy.

Well, maybe not quite so easy as you’d think. You can’t just send the database a query saying “Please send me a list of all of the Lassams living in British Columbia.”- of course. You have to produce a query.

In order to keep the language small, and the software language-independent, queries are not generally handled in any common programming language. They, instead, are handled by the Structured Query Language, or ‘SQL’.

A SQL query for all of the Lassams living in British Columbia might look like:

view sourceprint?
1.
SELECT firstname, lastname FROM users WHERE lastname = "Lassam" AND province = "BC";
What we get in response would be a list of first and last names in the ‘users’ table. Of course, we don’t really need to select the last name- we know it’s going to be ‘Lassam’, right?

More on databases soon! If you want to learn more, and fast, I highly recommend “The Manga Guide To Databases”, available from Amazon or for free on Safari (if you’re a SFU student.)

I just finished “Spook Country”, by William Gibson

This is the first book I’ve read by him, despite his fame. (Yes, yes, that also means I’ve never read ‘Neuromancer’.)

Intelligence is played up, often, as being exciting James-Bond style work. This is, of course, a complete falsehood. For most intelligence agents, one would imagine, the business involves a great deal more sitting around in coffee shops, listening to inane conversations and filing massive amounts of convoluted paperwork.

And Spook Country certainly captures the feeling of sitting in a coffee shop, desperately waiting for something interesting to happen. The book takes the common formula of slowly dropping hints that something big is going down, building a puzzle of overlapping narratives that - by the end of the book- manage to intertwine and make sense.

And - here I’m warning you that there may be spoilers - I didn’t like it that much.

The story follows three characters - Brown, a stuck-up, over-officious American Homeland Security type, The Old Man, a crisply dressed old ’spook’ of some sort, with connections in seemingly innumerable places, and Hubertus Bigend, a big-business interest.

Of course, following these players and their internal monologues directly would result in the entire book finishing up and closing shop in a few pages, so clearly some mooks needed to be introduced to tail each of the big players, clumsily stumbling into the book’s plot whenever possible.

The underlying plot, once it’s eventually uncovered, is none-too-convoluted. The whole thing is an elaborate sham being pulled over the eyes of Brown & Co., executed by The Old Man. As for Hubertus, for whom is reserved a full third of the book, he was just a curious external interest. At the end of the story, despite the fact that his ‘agent’ (mook) was present at the climax and denouement, he seems to lose interest in the story entirely and drift on to other things. I don’t blame him.

The narrative follows three characters- Hollis Henry, Tito, and Milgrim, each of them a Watson - following along in the path of their associated players- Hollis Henry with Bigend, Tito with the Old Man, and Milgrim with Brown, respectively. Each one of them has their clothes pressed and their schedules made, following all-but on-the-rails paths set out for them by their respective employers.

Tito is talented at Parkour , Milgrim at deciphering Russan text-messages, and Hollis Henry is famous for being an ex-rockstar. Were it not for these skills - of narrow use to each one - each character could just-as-well have been replaced by a trash can or a box of cabbages, wheeled about to various locations to have thin bits of storyline squeezed into them before being wheeled to yet another destination.

If you’re looking to avoid spoilers, they end here.

The reason that it’s so popular in Vancouver is the same reason that jPod was so popular- regardless of the content, much of the book’s action takes place in Vancouver, and we are willing to all-but-shit-ourselves with locational pride whenever we see mention of a local feature in an actual real-person novel. Commercial Drive? WOO YEAH THAT’S A PLACE THAT I’VE BEEN. Sarah Ferguson? WOO YEAH I KNOW A PERSON WITH THAT NAME.

And, don’t confuse my criticism with genuine hatred- I said that “I didn’t like it that much”, not that “I didn’t like it.”

The Vancouver setting, had me, in it’s own manipulative little way. I crave references to the place where I live in popular culture. I just can’t get enough of them- and William Gibson, a Vancouver native, seemed to hit all of the notes - in the same way that jPod, being vaguely about Electronic Arts ( a place where I’ve worked ) and much of the TV show being filmed at SFU ( the place where I go to school ) - well, there’s a feeling of validation in having your experience made a part of the media. It’s the same sense of pride I got when a picture of Vancouver was front-paged on reddit.

The occasional references - to darknets, public-key cryptography, freerunning, GPS tracking, and the like - are interesting, at least.

The book also presents a concept called ‘locative art’ which seems misguided - using virtual reality helmets, GPS devices, and public Wi-Fi to attach art to specific locations? The whole concept is sort of loosely-grafted on to the plot. It doesn’t really have any meaning, storywise, seems a lot more like the author wanted to point at an idea of his and go ‘hey, look at how neat this thing is!’. It’s really nothing more than a sort of reverse geotagging, though. It seems fairly obvious to me that, with ubiquitous GPS equipment will come people who tag all sorts of coordinates around them with interesting metadata- which can then be browsed by other people in the same area- at least, people that you’re following. Like a great giant locational Twitter. (”Curtis Says: Eat here. It’s delicious. Order the Pho” on a restaurant, or “Benton Says: I saw a homeless man pooping here” next to a bus stop.) Honestly, if people aren’t already doing this with the iPhone… I might very well get myself an iPhone and a developer account and go to town on this baby. It seems way too obvious, though.

As for the VR helmets, well, the proof is in the pudding. I’ve been waiting 22 years for someone to successfully mass-market one, and I’ll probably be waiting a few more, at least. Maybe OLED technology has an answer for us?

I’d file the book firmly into the ‘borrow or ignore’ category.

This is part 4 of a many-part series - a crash course on web basics, from Apache to Zend. (Okay, I’m not actually covering Zend, but I couldn’t pass up the A-Z thing. )

It’s time to learn about layout!

Using nothing more than the html elements that we have so far- images, links, tables, etcetera, we can assemble websites, easy-peasy. One needs a few additional tags- font, u, b, as well as a whole bag of tricks- invisible .gif files, image maps, cheating with Dreamweaver, the works.

This is how websites were built, back in the day. Straight-up HTML. It was, generally, a big pile of ugly.

So, instead of cramming all of that style directly on to the page, we use CSS- “Cascading Style Sheets”. CSS allows us to grab certain elements and apply style directly to them, with style rules.

So, for example, if we wanted to make all of the h2 elements on a page blue and underlined, we could create a CSS rule:

So, you’ll notice that ID’s and class elements both work about the same way, right? Of course you noticed that, you’re a smart cookie. Here’s the trick- ID’s are supposed to be used only on single elements - whereas classes are supposed to be used only on multiple elements. This doesn’t matter too much for CSS styling, but starts to make a huge difference when you’re using Javascript. If you select elements by ID, you expect a single result- whereas if you select elements by class, you expect an array.

Well, for one thing, in Javascript, it’s easier to use a single-item result than an array of results, most of the time. On top of that, in a page with ID elements, you can jump to any ID element on the page by adding “#name_of_element” to the end of the URL. (Which is how this works: http://en.wikipedia.org/wiki/Pickled_cucumber#Polish )

When you’re styling an element, you can add margins, which add space around the outside of the element, or padding, which adds space around the inside of the element. They work very similarly. There are a few important differences, though.

A margin sits outside of the element’s border. A padding sits inside of the element’s border. This is important because most of the other element properties happen inside the element’s border- as an example, background color.

On top of that, margins combine. If you have two items, each one with a margin, sitting next to one another, the total space between them is not equal to the added values of both the margins- instead, it’s equal to the highest value between the two.

Okay, it’s not entirely clear. How about an example!

Oh, position: relative and position: absolute. These are ugly times, let me tell you. Setting the position: relative property on a block allows you to make adjustments to the position of the block, relative to it’s original position in the page layout. However, the ‘block’ that the position: relative block occupies during page layout doesn’t change- so you have to be careful not to overlap with other elements. If, say, you want to move a div with id=”potato” up and right three pixels each…

Notice, here, we use another trick- while elements are limited to one ID, they can have as many classes as they like- so we tie common display elements in the ‘floats’ class, and the bits that change in the ‘left’ and ‘right’ classes.

Oh, position: relative and position: absolute. These are ugly times, let me tell you. Setting the position: relative property on a block allows you to make adjustments to the position of the block, relative to it’s original position in the page layout. However, the ‘block’ that the position: relative block occupies during page layout doesn’t change- so you have to be careful not to overlap with other elements. If, say, you want to move a div with id=”potato” up and right three pixels each…

position:absolute, however, removes the element from the flow of the page entirely. Your element- at least in the eyes of page flow- doesn’t exist any more. Instead, it floats freely above the action. Watching. Judging. If you don’t change anything else about the property, it just sits where it was originally supposed to sit, probably overlapping with some text or something.

Now, this doesn’t move the absolutely positioned element 3px up and 3px right, like in position:relative- it moves the absolutely positioned element 3px up and 3px right from the bottom-left corner of the screen.

Unless, of course, the position: absolute block is located inside a position: relative block, at which point it will be absolutely positioned 3px up and 3px left from the bottom-left corner of the position:relative block that it’s contained within.

One thing that you might encounter, having spent some time with CSS, is that layout is a very troublesome operation. It’s ugly, and everybody loses. People have come up with a few different solutions to the CSS-sucks-for-layout-problem.

And finally, we have the last throwback to the old-style of web development- just using tables for layout. While it breaks accessibility, and definitely will have web purists so far up your butt that it’ll take a backhoe to remove them - sometimes it’s just easier to use tables- and some layouts are really only possible using tables. CSS doesn’t handle flexible-width multi-column layouts with fixed-width column elements very well, for example.

If possible, it’s best not to give up and use tables- but a developer’s gotta do what a developer’s gotta do, right?

My blog now offers syntax highlighting for any code snippets, courtesy of Alex Gorbatchev’s Javascript code highlighter, available here.

I’m going to have to donate some money, ’cause this script is all kinds of neat.

The bit at the top is called the “doctype”. It contains the exact version of the HTML you’re using, along with a big pile of unnecessary bullshit. It allows an HTML validator to pick at niggling errors in your HTML, and if you have a doctype, IE6 will be ever-so-slightly more likely to display your site properly.

All of the page’s content goes in between the HTML tags on the outside. You can also specify additional properties in the HTML element’s attributes, such as language and character set.

A ‘div’ tag doesn’t mean anything. It’s just a way to group a bunch of similar elements together, usually for the sake of layout or display.

Span is pretty much the same thing. The difference between ‘div’ and ’span’ is that div is block-level - a div is a ‘block’ of content- whereas ’span’ is line-level. It’s a tough distinction- you could use a ’span’ the way you might use a ’strong’ or an ‘em’ tag, to annotate some text- whereas you might use ‘div’ around a couple of images - in the way you might use a ‘panel’ in a more traditional layout environment.

The one element here that might take a little bit more explaining is ‘form’.

A ‘form’ element is the most dynamic part of HTML- it generates a HTTP ‘get’ or ‘post’ request, and sends it back to the server- along with the values of all of the contained ‘input’ elements.

Looking at the form element- the ‘action’ attribute determines the target of the HTTP request, and the ‘method’ attribute determines whether the HTTP request is a GET or a POST - remember, GET requests should never change internal state, and they should be both bookmarkable and cacheable.

The key-value pairs sent with the HTTP request are determined by the ‘input’ elements inside the form. In general, the ‘name’ attribute of the ‘input’ element corresponds with the key of the key-value pair sent to the server.

When it comes to implementing the HTTP protocol in all of it’s thorny goodness- and implementing it well - you need a server.

You are going to be developing on a Linux machine. No, you are not allowed to complain. A Linux server is fast, stable, and free- aside from hardware. If you want a Microsoft server with comparable features, you’re looking at a financial outlay in the tens of thousands of dollars for the software alone. Ubuntu Server Edition is a great choice- it comes with Apache, PHP, and MySQL preinstalled and preconfigured.

For development, I recommend that you set up Ubuntu Server in a virtual machine on your computer. After setting up SSH, you have shell access (which you can use to develop in Vim or Emacs, if you’re a hardcore old-school type), or you can mount the SSH drive on your home rig- thus allowing you to develop with whatever editor you feel most comfortable with.

I tried setting up Ubuntu Desktop in a virtual machine on my computer and just developing from that, but I can’t stand Gnome. It makes me want to punch kittens. If you’re more tolerant of Gnome or kittens, you might consider that route.

Once you have your OS in place, it’s time to choose your server!

Notably, they’re all fast. None of these are really a bad choice. Well, maybe IIS is a bad choice. However, because I’ve never really used Lighttpd or nginx, I hate IIS with a fiery passion that will burn throughout the ages, and I’m not in the mood to build my own server, and Ubuntu Server comes with Apache pre-installed, we’ll be talking about Apache.

Apache, which is heavyweight, feature-rich, and fast.

IIS, which is heavyweight, feature-rich, fast, proprietary, and mostly limited to proprietary Microsoft technologies.

Lighttpd (”Lighty”), which is lightweight, feature-sparse, and fast.
nginx, which is lightweight-er, feature-sparse-er, and fast.

and … well, countless other possibilities. Python’s Twisted libraries even include a little DIY Python web server that you can tweak to your liking.

With Apache installed, on your Linux machine, you can serve files. If you are using Ubuntu Server Edition, your document root is /var/www and you’re serving files RIGHT NOW.

Put HTML files in there, HTML files will run. Put images in there, image files will download. Put code files in there and… code files will download? That’s not right.

So, you need to tell your web server to run it some code! This is where CGI (the “Common Gateway Interface”) comes in. It’s just, essentially, a system for telling Apache “When the user asks for this file, run program X on that file and send the user the output.” - so, one might configure Apache to automatically run ‘python’ on *.py files, and return the output from the files instead of just the raw Python.

There’s only one problem with this model- a new process is spawned for every CGI request. This gets ugly, fast.

There are two common ways to get around this….

FastCGI is a special, ultra-sexy CGI that speeds up calls by maintaining an open process and just passing it files to deal with as they come. FastCGI is popular- with system administrators, because it’s highly configurable, and with developers, because it supports just about any language under the sun.

However, for users of the most popular web programming languages, there’s an even faster, even closer-to-the-metal solution. Such mods as mod_perl, mod_php, and mod_python, embed the language interpreter directly within Apache.

This is the beginning of a series on the Basics of Web Programming. It’s designed to be an exceedingly fast, high-level look at all of the tools and skills involved in web-programming - not a detailed reference. The point is to get Lorin up-to-speed, and quickly. Ask questions (and point out errors) in the comments, and if you’re curious, look things up on your own!

HTTP, or the Hypertext Transport Protocol, is the protocol that implements ‘the web’. HTTP is implemented with TCP, traditionally over port 80. It’s a request-response protocol- you send a HTTP Request, you get a HTTP Response.

There are a number of different ‘types’ of HTTP Request, most of which you will never use. (HEAD, GET, POST, PUT, DELETE, TRACE, OPTIONS, and CONNECT) The two that your web browser tend to use most are GET and POST.

A GET request contains only the address of the item being requested. (Think of it like “GET http://www.google.ca” ). One might look like this:

Woo, boy, there’s a lot of information there.

The most important part, though, is the fact that we’re looking for www.awesome.com/yeah/file.html- which we can extract pretty easily just by looking at it. The rest of the data, you can do whatever you want with. It’s common for coders to ignore it entirely- the web server handles the important bits already.

Looking at the header data, a few fields contain data of the type thing?q=0.5 . This is a measure of preference. As an example, because my browser is English Canadian (odd assigning nationality to a browser, but whateva’) - it accepts en-gb, then en?q=0.5 - which means that, if the server has a Great Britain localization available, it should send that one- but if not, it should send any other English language version it’s got.

You can also include key-value pairs of data with the request.

So, at least to the innocent bystander, it looks like GET and POST do almost exactly the same thing. That bystander would be wrong! (So wrong.)

First of all, GET requests are limited in the amount of data that they can send- to the amount that can fit in a standard URI.

Second of all, imagine having your password or banking information in a GET request- right there in the address of the site that you’re going to! That’s no good!

Thirdly, and most importantly, GET requests are bookmarkable and cacheable. This means that you should never assign an operation that changes data to a GET request - For example, http://www.ikoverse.com/start.php?delete=lorin would be a bad idea- to cache or bookmark.

Okay, so, here’s the deal. I’m a fanboy, big-time. Whenever there’s a movie that’s based on a book, I read the book first, then watch the movie and internally flinch at every cut scene and every plot deviation.

All movies make creative cuts and alterations to the source material- to render the story even remotely watchable.

Some movies- say, V for Vendetta, or The League of Extraordinary Gentlemen- just don’t cut their lines close enough to the plot of the original. They go in strange directions, mangling themes and achieving a good Hollywood Ending at the expense of their soul.

Some movies achieve a good balance between source material and Hollywood - the Harry Potter movies and Lord of the Rings come to mind. They maintain much of the integrity of the original while simplifying the plotlines and cooking the result down to something that will work on screen.

Some movies, however, are _too_ faithful to the source material. The Golden Compass, for example. Maintaining the plot of the original story, the poor director tried to cram the whole story in to an insufficient amount of time, racing through the important scenes and leaving innumerable unexplained occurrences and unresolved plot threads. Even with large cuts made to the original story, there’s just no way to fit everything that happened in the book into a couple of hours of movie.

I’d have to say that Watchmen found it’s way into the third category. For people who’ve read the original, it’s spot on in it’s accuracy, a spectacular rendition of an interesting and deep story. There are a few logical inconsistencies, the worst sex scene in the recent history of cinema, and some minor botchings- but it’s easy to forget these shortcomings when faced with a perfect rendition of one of the main characters’ Crowning Moments of Awesome.

For people who haven’t read the book, it’s slow, plodding, confusing, violent, morally obscure, and strange, with the themes of the book murkily failing to really make themselves clear.

The verdict is simple. Read the book first. Then read the book again. When you watch the movie, you’ll marvel in the fine details and clean storytelling of a tale you already know. The details- Hollis Mason’s garage, Dollar Bill, the Gunga Diner - they’re spot on, and your inner fanboy will revel at every carefully crafted detail.

But, for the love of god, don’t watch it without reading the book first.

I’m not the sort of person to set a lot of house rules upon moving in with somebody, but I have decided that if I ever have a house with tenants, the following rules will apply:

You may have pets. You may not have any pets smaller or louder than a chihuahua.
Posters featuring the movie “Half Baked” are not allowed.
The movie “Half Baked” is not allowed.
You may drink as much or as little as you so choose, but PBR and Budweiser are not allowed on the premises, for being too ironic and not ironic enough respectively.
Any and all Blanket Forts must pass a cursory check by an accredited home inspector. Alternatively, ask us about our ground-breaking bribery program.
No Irish.
You can dance, you can dance, everybody look at your hands.
Use of the bathroom between 1:00 and 1:04 AM is strictly forbidden. Note: this rule will not be strictly enforced, and has no real justification.
Each-and-every trip to the kitchen MUST end in a mandatory touching of the lucky Blaster. Failure to touch the transformer may result in bad luck.

I’ve been really attached to the theme that I’ve been using for the site, past little while- but I thought it was time to tighten it up in a few areas. So now we have… a slightly altered version of the same theme! Huzzah!

So, I think that, for the first time in my life, I have a little script that *I* wrote, doing something useful. I check it daily, even!

This may not be a milestone in the imagination of most of my more software-development-experienced friends, but for me it’s a Big Thing.

Okay, enough with the self-congratulations. I built PieRC, a combination of IRC-Bot and webpage. It silently logs everything that happens on the #sfucsss IRC channel on freenode.net, and posts it online, in a searchable, browsable format.

The IRC-Bot is Python-powered, and it runs on an ancient laptop which sits, everpresent, at my feet. The whole system seriously needs an upgrade — I’m thinking to Ubuntu Server, because its desktop performance is poor at best, but it’s good enough to run a Python script. I just need to give it the ol’ foot every now and then because it’s gone offline for one reason or another.

I know, I know, IRC logs can also be stored by your computer, and you can grep through them- but PieRC can be -shared-, it’s easy to use, and everybody’s working from the same logs. Also? You can see what happens in channel when you’re not around. It tentatively supports multiple channels, although currently the only channel I have it pointed at is #sfucsss.

Things we say in channel are already starting to pop up on Google, which is going to be pretty incriminating if people start to associate things I say with … me.

My next planned feature might be Github integration, because that would be neato-pants. The source-code itself will be made available on Github in the near future- It’s not quite ready to be released as a ‘product’ yet.

Here’s what I’ve found so far:

Squeak eToys: So far, in Vista, it refuses to save- which is like the third thing I tried to do. I had to go through months of backlogged developer discussion to figure out how to save something. So I’m giving it a “User Friendliness” rating of immediate NO.

Alice: Alice 2.0 has a great tutorial that pulls you through the basics. It’s also as ugly as sin- and UI is a bit complicated, still. I hope Alice 3.0 comes out soon.

LOGO: I can’t even get Kristen to look at LOGO. It’s ‘programming’, not a game. Sure, it’s an easy programming language, but… no.

So, having exhausted the suggestions, I found “Scratch” mentioned in a blog post about Squeak eToys - And I downloaded it.

Huzzah! Scratch isn’t very advanced- not at all- but it’s the most user-friendly introduction to programming I’ve ever seen.

It’s not the most powerful programming system ever- in fact, it lacks even the most basic of functionality in most places- but it’s slick.

Kristen’s trying to put together lesson plans for Grade 7 students. She wants to do more things with techmology.

She wanted to start with Flash, but it’s not installed in the labs at her school- and it’s very, very expensive.

My suggestion of ‘hit them again and again with plywood’ was not well recieved.

She’s not quite tech savvy enough to introduce them to programming basics- although if we found something suitable, I might be able to get HER through some of the basics. (I looked at Phrogram, and once again, it was expensive- although an order of magnitude less expensive than Flash)

It has to be free, and at least moderately educational. Looking to push your own values on a generation of kids? Now’s your chance!

I have to say- I read one blog-post of “Stuff White-People Like” a long while ago, and dismissed it as silly and borderline racist - well, hey, I read the ‘asian girlfriends’ post, devoid of any context. He called UBC the “University of a Billion Chinese” (I happen to know it’s 25,000, tops. ) What am I supposed to think?

However, I just went through the rest of the content, and the whole thing is actually startlingly funny and absolutely horrifying because not only *am* I the guy described on the site (to a certain extent), so are a lot of my friends. I’m not the irritating Vegan guy, but I am the irritating “I don’t have a TV” guy, and I know the irritating Vegan guy. In fact, being up at SFU all the time, I am exposed to the people described in this blog, a lot. Everybody in the entire Political Science department, for example. Also, every single person on Reddit.

The site should come with a warning label. “Do not read all at once. May damage brain.”

I just upgraded all of the blogs on my account (yes, you too, Dom) to Wordpress 2.7+, on account of Dreamhost strong-arming me into it. ( -apparently-, I have to stay up-to-date to avoid ‘critical security problems’. Pff. )

It looks.. very, very different.

Like, extremely different. It feels like a whole different bit of software.

We’ve all had to deal with computer security at one time or another- somebody in the family has a nasty virus or some malware on their computer, and they want you to get rid of it.

I used to do this- now, I don’t.

Once you get something nasty on your computer- it’s game over, man, game over. Malware nowadays gets itself so wedged in to your operating system that it takes hours, specialized tools, and arcane knowledge to exorcise it.

The recipes on the internet for removing Antivirus 2009 involve changing Malwarebytes around so that the malware can’t stop it from running, going into safe mode, scrubbing the hard drive three or four times across three or four reboots, using a few other anti-malware products, scrubbing your USB drives, ritually murdering five orphans in a grand midnight ceremony and sprinkling their blood across the computer’s hard drive, and then manually changing registry values. Even then, there’s still the chance that the malware is still on your computer, sending out spam, reading your mail, and generally cocking things up.

There’s an easy way to clear all of the malware off of your computer- easy as pie. Format the hard drive. Ta daaaaa! No more malware.

Of course, you now have to reinstall your operating system and all of your favourite software- as well as any media that you had sitting on your primary hard drive.

You’ve also lost all of your pictures, all of your documents, all of everything. This is why we make backups of important things.

So, I’m sorta running a HoL campaign, on account of because I can, that’s why.

Between that, and potentially starting a comic project with Lorin, I figured it was time to stretch my doodling muscles and toss together a small assortment of character doodles.

Poor Jonathan. He couldn’t think of anything more original than a character than ‘uh.. a ninja. With a troubled past’. So I gave him Android Hell, a sort of cross between Inspector Gadget and bad software engineering practices.

People ask me, “What happened?” and I tell them, “We all got laid off.” I wasn’t sure what more to say, but fortunately, somebody else has already said it for me: http://www.geckotemple.com/blog/?p=87614440 .

Also, apparently I missed cheap hardware. Color me disappointed- but I’d feel bad profiting off of everybody’s loss anyways.

I love you, Kristen!

This is written in Tomboy- Tomboy is a ‘note-taking program’. You can pop up little notes like this one, group notes together, search-through them and even link them together.

Here’s a quick intro to the computer…

Pidgin Internet Messenger is like MSN Messenger- except it works with AIM, IRC, Yahoo! Messenger, and any other messenging protocol that you can think of.

Text Editor is just like Windows’ “Notepad”, but with a lot more features and functionality (like tabs). It’s useful for quick notes to yourself and for me (if I’m coding).

The “Terminal” is a way for you to enter text commands directly to your OS- sort of like DOS in Windows, but (again) with a lot more features and functionality. You’ll find that I almost always have a Terminal open when I’m coding on the Mac. I don’t expect you to familiarize yourself with the terminal- but if you go to the internet for Ubuntu help, and they tell you to enter a command… this is where you would enter it.

OpenOffice.org Word Processor is the open-source world’s answer to Word. It can read and write Word documents fine- although it lacks Word’s more advanced features. I’ve configured your OpenOffice to always save files in a Word XP compatible format. (Although .odf is a better format, you’re not likely to care. )

OpenOffice.org Presentation is the PPT equivalent, and OpenOffice.org Spreadsheet is the Excel equivalent. They’ve both been instructed to always save in an Excel/Powerpoint compatible format.

Sunbird is a calendar developed by the same people who designed Firefox.

Evolution is the Ubuntu equivalent to Outlook/Outlook Express - It’ll handle e-mail and it also provides a calendar and some other work tools.

Audacity is a sound-editing software package (You might remember it from IAT 100?)

The Audio CD Extractor is a method for converting CD’s into mp3’s.

The Brasero Disc Burner is a … CD Burner. YAAAY.

Songbird is the Ubuntu equivalent to iTunes- once again by the same people who designed FireFox.

The computer comes with Rhythmbox, too, which is another alternative to iTunes.

And finally, Wine is an elaborately constructed Windows simulator- which will (occasionally) allow you to install a Windows program to your computer. Getting things working takes a bit of fiddling, though, and it isn’t always pretty.

You know how you install programs in Windows? Download a file, run it, follow the instructions, blah blah blah?

Well, Ubuntu doesn’t work that way.

Ubuntu uses a system called “Package Management which is very simple. The guys who run Ubuntu manage a “Repository”, which is a huge list of all of the software that you can run under Ubuntu. By opening up the Synaptic Package Manager (in “System/Administration”), you can see the whole list of all of the packages.

Now, this list is (notably) quite confusing. It has libraries and programmer tools all mixed up with the actual programs, and it’s hard to tell what’s what.

So, to make it easier for people to use, there’s also an Add/Remove programs link in “Applications”. Click on it, and it will give you a great big list of all of the graphical programs that you can run on your computer. Just select the programs that you want or don’t want, and Ubuntu will download and install them for you.

You’ll note that a lot of the software in Add/Remove programs starts with a ‘k’ (Kopete, Kboot, Konsole), aren’t installed- that’s because they run under KDE. (What? What does that mean?) - Most Linux systems have two different graphics packages that allow nice graphical programs - Gnome and KDE - and Ubuntu uses Gnome. If you look in the description for the programs, the Gnome programs have a little ‘footprint’, and the KDE programs have a little blue ‘K’. KDE programs will still run fine in Ubuntu, but they’re a lot slower (so keep that in mind.)

Next to the time, there’s a link to the Ubuntu “Update Manager”- this is a program responsible for keeping all of your Ubuntu packages up-to-date. It’s nice, because that means the only software updates you have to do- ever- are all handled by the Update Manager.

As a last-but-not-least, I (notice I said ‘I’, not ‘you’) can also install software by opening up the Terminal and using the ‘apt-get’ command. It’s a LOT faster than using Synaptic Package Manager, but less attractive. (For example, to run the updates I mentioned before, ’sudo apt-get update’ is the command. )

Once again, Ubuntu’s file-storage system doesn’t work quite exactly the same way Windows’s does.

You can get to just about anywhere on your computer from the Places menu (see the top of your screen). Your “Home Folder” is quite possibly the most important place on the entire computer. It contains all of the files on your desktop, all of your documents, some examples of Ubuntu files, your Music, your Pictures, your Videos, your Downloads, everything.

Your “Filesystem” is like the C: drive in Windows- it’s the root where everything sits. It contains a bunch of cryptic folders, none of which you need to understand- bin (programs), boot( important files for booting up), cdrom (your cd drive)… etcetera, etcetera. Long-story-short: Don’t touch any of these, unless you’re me.

As an entirely unnecessary sidebar, your home folder resides in the location /home/kristen/ - Just like it might reside in C:/Documents and Settings/Kristen/ on your home computer.

Okay, on to the easy stuff- when you insert a CD or a Hard Drive, they’ll just appear on your Desktop. Ta Daaa!

It strikes me that people who have experience with Source Control should be exceptionally good at time travel.

My week has been a loop of:

1. Read some header code.

2. Look at the underlying implementation, try to determine what’s going on.

3. Discover some syntax of C++ that I don’t understand too well.

4. Read about said feature in a few references (online or at my desk), or ask friends. (“Are C++ binary shift operators sensitive to endianness? No? OH! Now it makes sense!” )

(Repeat 3-4 a few times)

5. Attempt to filter the new knowledge of the code into some sort of short, easily understandable summary that manages to be useful and non-obvious. (After some time reading the code for a rectangle class, I had an awful hard time thinking of anything other than “YYYup, that’s sure a rectangle. And all the stuff that you’d want to include with a rectangle. ”)

6. Compile Doxygen

7. Check Doxygen-generated page- be unsatisfied with the way the output came out (maybe the comments are in the wrong place or things could be grouped more attractively)

8. Adjust comments, check Doxygen syntax.

(Repeat 6-8 a few times)

9. Get coffee.

I like to think that I’m gradually spending less and less time in the 3-4 loop, but I’m still a tad slow and useless.

This is a logo that I developed for Tony-O’s Restaurant, a little cafe in Surrey - currently closed thanks to financial difficulties. Around the logo, a full website was designed.

One of the major advantages of this website is in it’s flexible layout- the size of the page adjusts to accommodate the browser in which it’s displayed. Tested in Safari, Internet Explorer 7+, and Firefox 1.5+, it’s consistent and standards compliant.

So, yesterday was my first day working at The Humanature Studio. It’s an 8-month co-op, so I have.. let’s see.. 8 months left to go. I’ll have a few pictures for you in the near future, after consulting the appropriate persons about what is and is not a ‘photographable’. (Game companies take their confidentiality very seriously. )

Day 1 had the mandatory “Put Your Signature Here, Here and Here”. After some questions about the contract, I had signed away all of my rights as a human being away for the contractually obligated amount of $1- which I have yet to receive.

After that, my desk. Oh yeah. I’m right up against a window. I’ve never had a software job with natural light before. It’s beautiful. Also? Two powerful computers, each with a 24? screen, set up so that I can either have a dual screen or two computers.

The cafeteria has an espresso machine, a standard coffee machine, and some sort of automated tea beast. I was shocked to discover that the automated tea beast had a mug-space smaller than my large mug. Horrors! This mug has been with me for years!

The office is generally very eco-friendly. I know that every company in the past 10 years has had some sort of ‘green team’ environment-committee- but this one seems to actually have some sway. All of my office supplies are from an environmentally friendly office-supply company. My pens are wooden, and refillable. We have *all* sorts of recycling bin, and - heck- our milk comes in a jar. Really, this is a minimal-packaging office.

The location is fabulous- right in the middle of downtown Vancouver.

Everybody in the office is cheery, friendly, and everybody goes home around 5:30. Thanks to the fairly low turnover, everybody recognizes me as ‘the new co-op’.

Aaand, I have my first assignment. NDA aside, I can say one word and everybody will know what I’m talking about. Doxygen.

Guh.

Between the family, the spectacular amount of good food, ad the time I get to spend with Kristen- Well, while I technically might not be a “Christian” in any way shape or form, I sure do enjoy Christmas.

I was browsing reddit (like always) and someone pointed out that- while many low-level courses require you to program in Java, very few of them explain the well-known preamble of public static void main(String[] args).

So, let’s see what I can explain - anybody who’s not interested in programming, or good at programming, or who already knows - can tune out now.

You’re going to have to be patient with my Java code. I try to avoid Java as much as possible in favour of languages like Python, so my Java’s a tad rusty.

Imagine that you’re writing a program that deals with a lot of data. You’re managing 200 employees, and you’re writing a program to schedule vacation time for each one of them. The first thing that many programmers will think about is how to deal with employee data.

In this case, we’re going to need to keep track of - at the very least- employee names and vacation times. For each employee, we can maintain the employee name as a simple string- and the employee vacation time can be represented as an Vector of TimeSpan objects. I’ll explain that Vector/TimeSpan thing in a second.

So, let’s tie that data together: a string (to hold the name) and a Vector (to hold the dates). We’ll do that with an Employee class...

We can’t be sure how many different vacation ’spans’ an employee might have. Mr. Baker from Accounting might use his vacation days sparingly to turn long weekends into four or five-day weekends all year round, while Mr. Asher from the Hat Department might blow all of his vacation days in one four-week-long trip to Spain. Given that, we have no clue how many TimeSpan objects we’re going to have to store!

It’s a tad ugly, but it does the job. We may talk again later about that 86400000- just plunking 86400000 down there in the middle of the code? That would be ugly. It’s referred to in programming as a “magic number“, and considered bad form. We’re at least naming it, though.

So, we’ve got this handy function to tally up the number of days - but what if we want to do it more than just the once? We have to copy and paste the code all over the place. Not cool. Those of you in the audience with some experience know that this belongs in a function.

Now, being as this function is designed to work on a Vector of TimeSpan objects, we can be pretty sure we’re only ever going to be using it on the Employee. So let’s include the function in the Employee class.

One thing that’s a bit of a pain- before we put any values in the Employee ‘vacationTime’ bin, we need to instantiate the variable with ted.vacationTime = new Vector(); Ideally, this would happen automatically, every time we create a new Employee.

What we need here is a constructor- a function that runs automatically whenever ‘new Employee()’ is called.

Constructors have special syntax in Java. They have no return value, and always have the same name as the class. Constructors exist, with varied syntax, in just about every language that supports OOP.

Of course, the code I’ve written - aside from being untested in any actual Java interpreter - is wrong for a number of reasons. One important way this code can break is that- if an employee has two overlapping breaks, ‘getNumberOfVacationDays()’ will overreport the number of vacation days that the employee truly has. As an example, if I have January 23rd through January 29th off, and I also claim to have January 21st through January 28th off, the system will claim that I have 15 days off, instead of 9 days off. Let’s imagine a function, ‘overlapCheck()’, that runs through the class’s vacationTime vector and combines any overlapping TimeSpans.

There we go- now every time we add a TimeSpan to an Employee’s vacationTime, it’ll check if it overlaps with any other TimeSpan and merge any combined time.

Unfortunately, though, now we have to go back and change all of the rest of our code- replacing me.vacationTime.addElement(christmasVacation) with me.addVacation(christmasVacation) anywhere vacationTime.addElement exists. While this is trivially easy in our simple example, it would be much more difficult if our Employee code was used in a lot of other places.

It would have been a lot easier if we had just written ‘addElement’ when we had first written the Employee class. It would be an almost empty function, just …

Of course, now that we’ve built a getName and setName function, it’s entirely unnecessary- and potentially dangerous- for us to directly access the Employee’s ‘name’ variable. For all he knows, it might disappear entirely!

What do we do to protect ourselves from this eventuality? We make the ‘name’ variable private. This means that it can be accessed by functions within the Employee class, but not accessed by functions outside of the Employee class.

You can also specify that a variable is public. A ‘public’ variable is… well, just a normal class variable, like the ones above.

Okay, let’s talk about another reason why we might want to hide something using the ‘private’ modifier. It’s not that often that we write an entire codebase ourselves. More frequently, we’re working on teams, and other people are going to be using the classes that we write.

Certain elements of classes are important to the class, but entirely unimportant to the programmer using the class. For example, once we’ve implemented the automatic overlapCheck() in our Employee class, the person using the Employee class doesn’t have to think about it at all anymore. He shouldn’t have to think about it. In this case, we make the overlapCheck() function private. While it exists, the programmer can’t see it or call it.

Of course, most of the time, when we’re writing a function in a class, we want it to be public, not private.

Wow, it took a long time to explain public. The rest of the article should take a bit less time. On to… static!.

Remember way back when we wrote the getNumberOfVacationDays() function? We defined a constant ms_per_day- the number of milliseconds in a day- in order to perform the calculation.

But, inefficiently enough, every single time we run ‘getNumberOfVacationDays()’, the computer is going to create a ms_per_day variable, and fill it with the value 86400000. That right there is a waste of time and effort.

Instead, we could define ms_per_day as a member of the class- a private member, of course, because nobody needs to know that it’s there, and we certainly don’t want anybody changing it.

Once again, however, this is not the right answer. In this solution, we have ms_per_day defined once for each employee. If you think about it, ms_per_day is the same for ALL employees- the number of milliseconds in a day doesn’t ever change, really.

So, what we do is make the ms_per_day variable static. What this means is that there’s exactly one, shared copy of the ms_per_day variable, no matter how many times the class is created.

The static variable for functions works much the same way. Imagine that you’ve created a useful function that goes along with a class- but one that doesn’t require any data from class members.

Let’s say that you want to display a vacation (TimeSpan) in a specific way- let’s say, “May 2, 2008 to May 5, 2008? You can write the function as part of the class, like so:

Many new programmers have been raised in a world of Graphical User Interfaces. All of their time is spent in Windows, and when they program, they program in an Integrated Development Environment like Visual Studio, or IDLE, or Eclipse.

Many people don’t even know about The Holy Command Line, the One True Interface. Neal Stephenson wrote a long article about it, and (despite it’s length), You Should Read It. I promise you- it’s worth it. I may even acquire the paperback version. It’s a .txt file, so worst-comes-to-worst, you can load it on to your iPod and read it on the bus.

Want to see a command line? You need to open a console. In Windows, go to the Start menu, find run, and type in cmd. On a Macintosh computer, hunt around in the Applications folder for Utilities, where you’ll find a program called Terminal.

It doesn’t seem like much- a prompt, a blinking cursor, just staring at you.

From the command line, however, you can do just about anything that you could do from the Graphical User Interface.

Windows XP and Vista have DOS-based command lines, and… well… they’re just terrible to work with.

Thanks to the fact that Mac OS X is based - through a long and arduous, albeit interesting history - on BSD Unix, it has an advanced command-line interface with many useful features.

The many Linux distributions are designed in such a way that you can run the whole system from the command-line if you want, entirely graphics-free - and, in fact, if you want to really get a feel for the ol’ command-line, I recommend you install and configure a Slackware box from scratch. It’ll be a learning experience, I promise. (I do it every couple of months or so, but I always chicken out and end up working with Mac-Os X again in a few days- but I do keep a VM of Ubuntu Server Ed. running on my computer at all times, so I’m not entirely a duffer. )

Why is the command line so popular with programmers, and so relatively unknown by everyone else? Why, it’s simple, cap’n. Command line programs are much, much easier to program. Putting something together with a snazzy visual interface- even a tiny little program- will probably take you the better part of a day to get right. A command-line program is the sort of thing you can toss together in minutes.

Command-line programs are usually free, and often very powerful. With ‘gpg’, you can manage strong cryptography, with ‘git’ you can manage a huge shared codebase, and with ‘gcc’ you can compile C programs. With ‘grep’, you can search for just about anything. (”G” is a popular letter. It usually stands for “GNU” but not always.)

Command-line programs can be tied together and automated in ways that graphical programs just can’t- Often, you can pipe the output of one program right into the input of another.

Here’s an example of a simple (Mac OS X) command-line program in action:

I hear that you’re coming to the party on Thursday.
That’s awesome.
I hope you bring Nachos.
If you don’t, Lorin’s going to do that thing with your head again.
He really loves the Nachos.

The “cd” program takes “/Users/curtis/Documents” as an argument, and changes the current directory to “/Users/curtis/Documents”. The cat program takes “message.txt” as an argument, opens “message.txt” if it exists, and prints out the contents of “message.txt”.

See, command-line programs work almost exactly like functions. They take arguments, and produce output.

When you write a ‘console’ program- in Eclipse or Visual Studio- what you’re writing is a command line program. It takes input, or ‘arguments’, and produces output. That’s just about all you write in University. If you were to run one of your Java programs, the way that it was intended to be run (that is, without the huge IDE), you’d open a command-line and go …

(Xianny) Eyebrows, the chubby rogue, (Curtis) Richard, the mage who is also a chef, and (Marcel) The Generic Dwarf, made amends- having forgotten the violent events of last day. The inn that they occupied had also attracted (Kristen) Athena, the somewhat-spacey cleric. She described herself as ‘normal’ and agreed to help with the Kobold problem that everybody was having.

On the road to the Kobold’s lair, the party of four encountered… Kobolds! (surprise!) Having a cleric on the team proved to be a significant step forward, and the Kobolds were summarily dispatched. Eyebrows started to get a feel for the hunt- learning that her sneaky hits from behind did a lot more damage. Spirits were high. The party found a dark little figurine in the hands of one of the Kobolds. Richard successfully identified it as a fetish of Orcus, dark god.

Travelling forward, the team found… more Kobolds! This time, a whole awful lot of Kobolds in a forest. Generic Dwarf managed to shake off several javelins to the important bits. The team worked together and once again made mincemeat of the forest-ful of Kobolds. One of the Kobolds managed to dash off, yelling “Irontooth must be warned!”. How ominous.

The party followed the escaped Kobold into the most Kobold-ful spot yet- a cave, containing Kobolds of all stripe- as well as an axe-wielding goblin with a rather spectacular amount of hit-points.

One well-placed fire-spell managed to clear the caves of 8 of the Kobolds- after which Richard cracked his knuckles and tossed off a pithy comment. Another 2 Kobolds were knocked clean unconscious by a spell of Sleep, leaving only the axe-wielding super-goblin, a Kobold priest, a Kobold skirmisher and a Kobold minion.

The cleric, however, foolishly ran to the front lines, putting her in a position where the remainder of the Kobold forces could concentrate their attacks on her. She fell unconscious. After taking a near-fatal series of blows from the axe-wielding goblin, the Generic Dwarf attempted (and succeeded) first aid on the cleric.

Between the two of them, they managed to stay alive a bit longer in battle, but in the fray the axe-swinging goblin took Eyebrows’ head clean off. In one blow, she went from a healthy albeit battered rogue to a pile of relatively useless meat.

The onslaught proved to be too much- the Dwarf fell, and Athena- unable to heal him any further- instead just decided that an expeditious retreat was in order. “Book it!”, yelled Richard as they made haste for the woods. Again.

Things seemed bad for Generic Dwarf, but luck was in his favour and he rose. Surprising the goblin, he succeeded at an intimidate check (one assumes, yelling “DWAAAARF!”) shocking the goblin enough so that he could nab Eyebrows’ dead body and leave.

Athena arrived at Winterhaven first, and retired to the pub for a nice ale.

The Dwarf and Richard arrived next, quibbling about what to do with the dead body of Eyebrows. While Generic Dwarf favoured rescuing her, Richard argued that the going price for such a resurrection was 500 gold pieces- not a paltry sum, and clearly out of the price range of the team. Richard suggested instead that they dump the body in a nearby creek and attempt to find a new hero willing to join the team. (Note to the DM: If you feel that it’s more appropriate for Richard to be Unaligned instead of Good at this point, I wouldn’t resist it any.)

To make his point, Richard suggested that resurrections don’t just grow on trees, idly tapping the battered lump that was Eyebrows’ corpse with the Orcus figurine that he had earlier acquired. In retrospect, not the greatest idea. Eyebrows’ corpse started shambling up with a new, dark life. Richard shrieked like a little girl (”ZOMBIES!”) and paced away, leaving the Generic Dwarf to deal with the zombie Eyebrows.

Generic Dwarf mistakenly thought that Eyebrows had come back to life, and attempted first aid- only to be slammed by the undead’s fury. At this point, Richard had regained his composure and froze the zombie from a safe distance.

Well, at least the body disposal problem had been solved.

I’d like to take this opportunity to point out that our team’s Rogues are having a definite Spinal Tap Drummer problem.

Throughout my life, I’ve used bad humour to punctuate just about anything that I do. I’m not exactly Mitch Hedberg (or even Carlos Mencia - ugh), but I’m just witty enough to get a hit every couple of tries.

Not just that, I do it all the time. During class, during finals, in Very Serious University Reports, at work, in the boudoir, all the time. Wherever I go, people gradually either decide that I’m hilarious (if they get it) or incredibly strange (if they don’t).

This also means that I get the “appropriateness” talk a lot. Like, at least thrice a year, ever since I was in Grade 4 or 5 and started this sort of thing. I’ve been passed over for some jobs, almost fired from some others, lost marks here and there, but most of all, I get the “appropriateness” talk.

The “appropriateness” talk is a universal constant. It often starts with something along the lines of ‘did you think that we wouldn’t notice?’- Which, of course, I usually nod negatively to. Of course I expected them to read these inappropriate things that I wrote- otherwise to what purpose would I write them?

After that, they’re either a Type A- we’ll call it the Fuddy Duddy- or a Type B- the Coward. The Type A will tell me that the thing that I wrote is directly inappropriate, and not to do it again. The Type B will invoke the potential specter of the Type A- “Some other people might find this inappropriate, so you should be careful about that sort of thing.”

The Type B (Coward) is occasionally a free-spirit who has been crushed by a Type A (Fuddy Duddy)- who then starts believing (falsely) that everybody is a Fuddy Duddy as well. Occasionally, however, the Coward is a Fuddy Duddy in denial or disguise- invoking a straw-man Fuddy Duddy to further their Type-A arguments.

It’s this same mentality that makes Political Correctness and Business Casual the norm- one Type A (Fuddy Duddy) can spawn many Type B (Cowards), and the Fuddy Duddy can then disguise himself as one of the Cowards.

You’ll find, however, that many people enjoy a dash of inappropriate humour with their day-to-day reading. Injecting it into boring project documentation can make it more fun to write and read. Writing a test is a horrifying experience, and marking is a painful chore- a creative answer can really perk things up.

I’ve also found that such inappropriate humour usually ends with one of five different outcomes - here I’m using academia as an example, but it’s the same for work environments:

No change in mark- maybe combined with a question mark.
The Type B (Coward) speech. The warning that ‘while professor/TA doesn’t mind, there will come a time when some other professor/TA will mind, so be more careful/prudent.’ No change in mark.
The Type A (Fuddy Duddy) speech. “This is not appropriate”/”This is not appreciated”. Slight/severe loss of marks.
Smiley face. Your TA/Professor, bored with reading the standard papers over and over again, has had a good chuckle reading your inappropriate comments.
Bonus marks. Your TA/Professor not only had a good laugh at your antics, but evaluated your work more favourably because of it.
Given these outcomes, and the surprisingly low number of *actual* Type A’s, I’ve recieved the Type B speech far, far more often than I’ve ever faced any sort of actual consequences for my actions.

On top of that, the consequences are rarely more than a slap on the wrist- a small price for being my usual distinctive self. As a cherry on top, the fifth occurrence, “Bonus Marks”, while rare, is nice, and seems to actually get more frequent as I get older and (I assume) more people are sucked into the Type B trap of professionalism.

Of course, it can go too far- I still have to complete all of the required work. Humour shouldn’t be a way to avoid the task at hand- just a distinctive flair.

With all of the risks associated, you might ask- why do I do it? Why do I put myself out there? A bad joke on a cover letter will disqualify me from more jobs than it will qualify me for.

It’s simple- if people don’t like it, they’re not going to like me, and I’m probably not a good fit for their company. Any environment that doesn’t appreciate the bad humour- I’m probably not going to be happy there. That’s why I’ve started doing it right on my cover letter. The company that reads a bad joke of mine and goes ‘this guy… I like this guy!’… well, chances are, that is the company that I wanted to work for all along.

A quick summary of the happenings, for those people who weren’t there:

(Angelina) Leukemia, the brave rogue, (Xianny) Eyebrows, the sneaky rogue, (Curtis) Richard, the mage who is also a chef, and (Marcel) The Generic Dwarf, met under mysterious circumstances, ostensibly because they were all seeking fame, fortune, gold, and adventure.

Immediately on their path, they encountered an unfortunate series of Kobolds. The Generic Dwarf stood in the centre of their assault, soaking up damage and occasionally felling a gnome. In his capacity as damage-soaker, his beard was soaked in both napalm and acid. The two rogues popped in and out, dealing minor damage, and Richard felled Kobolds by the handful with his powerful burst attacks. Eventually, the last kobold was felled, minced, and served in a stew that was (everyone noticed) quite delicious.

The characters found themselves upon a small settlement- Winterhaven. While the rest of the team conferred about whether or not the city was safe, Richard merrily waved at the town guard, who waved back. Seems safe enough. The party walked into the town’s tavern and bought a few pitchers of ale. At this time actual beer was brought out (Thanks, Marcel!) and consumed. It was both cool and refreshing.

After a bit of snooping. it was found out that the town of Winterhaven had a tad of a Kobold problem. (Yuh, really?) And if the team would be so kind as to clear out the Kobold’s nest, there would be mad cash in it for them. (Okay, 100 gold pieces and a bottle of fine wine. )

Setting off on the road, the team encountered their second set of Kobolds for the day. The Generic Dwarf went back to taking loads of damage, taking hit upon hit and eventually deciding that it would be prudent to flee. Richard commented that this makes him the “Worst Dwarf Ever”. Without a thick damage soaker to take the front, the brave rogue immediately took a felling blow. In a halfhearted rescue attempt, Richard flooded the battlefield with thunder-wave upon thunder-wave. The Kobolds were severely hurt, but sadly, Leukemia didn’t survive. With naught but a few hit points, a cowardly Dwarf, and sneaky, sneaky Eyebrows, Richard thought that an expeditious retreat was in order.

Richard dashed away, yelling “CHEESE IT!” and leaving Eyebrows the Rogue to his own devices. Eyebrows was knocked unconscious by the Kobolds, and Generic Dwarf and Richard booked it back to Winterhaven.

Upon reaching Winterhaven, Richard and Generic Dwarf stopped to catch their breath, only to encounter an infurated Eyebrows. He attempted to greet them, knife concealed in his palm, but Richard noticed and immediately bellowed “GUARDS!”.

Richard tensed, Generic Dwarf grabbed his Generic Dwarven Weapon, the guards.. guarded… and the session ended, to be picked up next day.

And now for… D&D Tips!:

The team doesn’t need two rogues. Honestly.
Wear all the armour you can. Know why the mage survived? Because unlike most mages, he was wearing Leather Armour.
The only way for a rogue to be really effective is if he has combat advantage -somehow-, usually by flanking. That means you don’t go up and try to deal direct from-the-front damage- you wait for the enemies to engage the Dwarf and then hit them from behind.
You start out with enough money to buy just about all the equipment you need. Asking quest-givers for more equipment is silly. The following conversation will never happen:
Questee: We’re going to need more equipment to do this quest. Hook us up!
Questor: Oh, glad you asked. We’ve been keeping this +3 Sword of Poopflinging just in case somebody asked.
Questee: Wonderful!
the same goes for advance payment - especially if you’re a group of shyster-looking unproven heroes. Maybe if you’re super lucky you’ll be able to finagle a few extra coins. If you’re lucky.

Team needs moar Cleric and Paladin pls.
If your character is named “Leukemia”, you’re going to die in the first game.

Every year, I post a list of things that I would like to acquire for Christmas on the internet, so that those people who buy me things may more effectively buy me these things.

This year is no different! Except this year I just cut-and-pasted last year’s wishlist, changed it ever-so-slightly, and deleted all of the things I bought for myself.

My t-shirt size is, as always, Large.

While I was working at EA, I became a tad addicted to the MySQL GUI Tools. They’re convenient and slick, and they make me a happy man. It’s the Query Browser, really- functionally equivalent to just opening ssh, logging in, typing in ‘mysql’, and entering queries manually. The big difference is the fact that you get a bigger screen, multiple windows, and you can save queries and data.

So, I was encoding timing data right into my Python programs - for performance-measurin’ purposes, for a project I’m working on.

But, lo and behold, I discovered the unix ‘time’ function.

Just run time python yourfunction.py , and it will merrily run your code, then produce timing data. It’s not just for python, it works for any command-line function.

Ah, UNIX- whenever I need to do something, you’ve probably already done it, and better.

So, at some point (I think maybe on Reddit), I discovered this awesome gypsy-jazz remix of the Super Mario Bros. 2 theme.

I surf around on the website a bit, and I discover that Adrian Holovaty, the composer, was also a major contributor to the Django project. Pretty sneaky, sis. I suppose it only makes sense that people with a musical background would name a web framework after Django Reinhardt.

Creative, intelligent people are everywhere. I’m not sure how we’re going to stop them, but I suggest that the answer may be more television.

So, you’ve got your gun pointed at the Series Villain - often a homicidal maniac. He has the gun pointed at the innocent love-interest.

At this point he yells out “Put the gun down, or I’ll shoot her!”, often followed by some sort of “Now get on the ground” schtick.

Now, at this point, the hero always puts his gun down. Now, by my reckoning, the villain (a homicidal maniac) has a gun and both the innocent love-interest and the hero are unarmed and in a vulnerable state. This seems like a negative outcome.

Remember kids: If you’re in a cliche, don’t play it straight. Keep the gun.

So, a few months ago, my uncle opened a restaurant. Tony-O’s- just in Surrey, on King George highway.

A tonne of money and time went into making the place look nice, getting the kitchen up to code, fixing what was essentially a crappy little Chinese-food dump into a respectable little cafe.

Everything on the substantially-sized menu- every last thing- was delicious. Some of you have eaten there- I had a big event there ’round September, and I tried to drag people to the restaurant when I had the chance.

Dinehere had a favourable review of the place, and so did the local newspaper. I stopped by now and then, but the in-and-out flow of the place seemed pretty slow.

And now.. it’s closed. Not enough money to stay in business.

I’m a little disappointed- My uncle’s cooking is highly nom-worthy, expertly executed, good eats. The ability to get it any-time was fantastic, even if the restaurant was a little bit out of my way.

But I can’t say I’m overly surprised. From my first experience with the location, foot traffic around the area is almost nil. The people who do walk by are not the type I’d categorize as the sort who would go for higher-end food- they seem a pretty fast-food bunch. The bright red canopy and clean, attractive little restaurant can only go so far to attract foot traffic that isn’t there.

The new condos being built could potentially provide a large burst of higher-end clientele.. when they’re finished. If they finish. That’s a year or more down the road, though.

As for King George road- well, it’s a major thoroughfare, but that doesn’t mean that the nook-sized restaurant is going to attract a lot of customers. The giant “Food experience” on the banner doesn’t help, either- what’s a “Food experience”? Are they going to rub potatoes on my nurps?

Given that, the little shop had the sort of food that could survive with a cult following- good food, good value, what’s not to like? Thing is, though, developing a cult following takes time. If the restaurant is out of money after being open for 6 months, either overhead’s too high, they didn’t plan far enough ahead, or both. As for the overhead- with the huge menu, one can only expect that food costs are pretty high.

On top of that, the restaurant had little-to-no advertising budget and was only open 11-7, Monday to Friday- leaving out late-night and weekend eaters, not to mention most 9-5ers.

Poor Uncle Antonio- last time I saw him, he just seemed deflated. I hope his next scheme is more successful.

… So, anybody interested in buying a restaurant? ^_^

I always figured that this plan was technically sound- but now that I look closer, I wonder if schools looking for grad students will accept field experience in lieu of an actual decent GPA or research experience. Any insight, interwebs?

Okay, I’ll admit it- Fallout 3 has been eating an inordinate amount of my time.

Honestly, with new games, I usually don’t spend too much time with them. A few rounds here and there- the novelty pulls me in more than the actual gameplay.

Fallout 3, though, it’s .. well, hours and hours of my life have disappeared inexplicably into the hole of Fallout 3.

There are things in the game that are sorely lacking- the path of vice and evil just doesn’t seem quite as evil as in the other Fallout games. You can’t kill children or pimp out your wife, and the game’s main quest has a good/evil divergence.. but it’s almost at the end, not at the beginning, so the bulk of the game’s storyline only really goes one way. I suppose that games like Grand Theft Auto have raised the bar on our random violent urges, and games like KOTOR have raised the bar on our malicious, brooding, planned evil urges.

Good or evil, your ability to sleep with random women is sorely limited- I mean, you’d think some of the girls in the wastes would want to get with the roaming savior of humanity, an intelligent, handsome 19-year old who is rough around the edges but ultimately good-hearted- one who, in many cases, has just saved their families/lives from roving bands of raiders/super mutants. Maybe it’s the mutton-chops?

The combat is.. well, it’s just hard. VATS is great, but once your action points expire, you either have to fruitlessly fire at your enemies or run screaming into the bushes to restore your action points. A turn-based just-VATS system would be sweet, but the first-person shootery is just clunky and lame. I worked around the problem by switching the combat to Very Easy- which dramatically lowers the hit points of all of your foes, in exchange for a much lower XP bonus for killing them. I don’t know- I find it fun to not be dying all the time.

So, why do I enjoy this? If not for the combat and random viciousness, then what? Well, I like me a good RPG. Fallout 3 is a pretty good RPG. I especially like having a shack in which to store all of my various scavenged swag, junk, and garden gnomes. I like building character stats, acquiring goods in unlikely locations, and saving people from stuff in an almost episodic way.

Not to mention, my character looks like a total badass- although, for a brief while, the best equipment available for my character was Talon Combat Armor and a Motorcycle Helmet, which took my character from looking like a western badass to a .. Spaceball.

So, animation is surprisingly difficult. Who knew? I spent a good 16 hours working on this stupid burger and fries, trying to coax some simple speech out of the burger. What I have is.. okay- I’d like to spend more time on it, but everything’s already late.

All with a sort of deja-vu feel- I could swear I tried to do the same thing in high-school when I was fiddling around with 3D-Studio-Max 2 or 3 (and inevitably got frustrated). This burger is *much* better than the one I did when I was 14, but I’m still a long way from good or even competent. Also - and this is funny- 3D-Studio-Max was I think easier to learn than Maya. None of the past 8 years have been spent on UI improvements, at least.

Richard Dawkins’ recent(ish) series, “The Enemies of Reason” takes jabs at both new-age sprituality and alternative medicine, even more firmly placing Richard Dawkins in the firm position in my list of Awesome Heroes ™- a list that includes…

Richard Dawkins- on account of saying everything I’ve ever thought about religion, spirituality, and other similarly made-up things… but in a far more developed and well-thought-out fashion.
Greg Graffin - because once you’re a famous punk rocker, a PhD,*and* a University lecturer- in science, no less, you’ve literally met and exceeded all expectations for awesomeness.
SFU’s Greg Mori, Greg Baker, and Brad Bart- for seeming to actually care about the craft and art of teaching- a rare enough commodity in Higher Education to render it nigh unexpected.
Randall Monroe, and the Penny Arcade guys - for harnessing the awesome power of their comics to create geohashing, PAX, Child’s Play, and ever-so-slightly increasing my bacon intake.
Pizza Hut, for putting the cheese in the crust. I know, guys, it was madness. But you tried. You tried so hard.
Kent Hastings and Chris Archer, for this.
Alan Moore, Neal Stephenson, Neil Gaiman, Douglas Adams, and then Douglas Adams again. Because, you know. Note that Alan Moore might be displaying early symptoms of the Stallman-Beard-Limit-Effect*.
George Carlin, for this.
Kernighan, Ritchie, and Thompson, for introducing “Hello World”, C, and Unix- and also for having awesome beards without suffering from the well-known Stallman-Beard-Limit-Effect*.
* Beard length is directly connected to both technical skill and antisocial tendencies. Past a certain length, the antisocial tendencies start to take over- this is known as the Stallman-Beard-Limit-Effect.

I may have neglected to post this at any point-

Next semester, and the semester after that, I’ll be working for “Humanature Studios” as a software dev, for an 8-month co-op.

Humanature is a division of Nexon, an Asian MMO supercompany. One of their games claims to have over 76,000,000 registered users. Noting that the entire population of Canada is about 34 million or so people, that’s … a little strange, actually. Even WoW only has 10 million subscribers. (Over half of those subscribers are from Asia, though) They’ve gotta be fudging that number a little. 76 million? No way.

But while Nexon is apparently Bigger Than Superjesus, Humanature is a really-very-small company. They take up about one floor, and things seem to happen with a minimum of horrifying bureaucracy.

I have high hopes for this co-op. Fingers crossed.

SFU’s CSSS has recently discussed the problem of Corporate Sponsorship. These are my thoughts.

Sponsorship is a tricky question.

As a VPA, I found that the trouble wasn’t money, so much- it was organization. It takes a lot of time and effort to plan an event, get people to come to the event, advertise the event, get people to bring equipment to the event, keeping people at the event from showing up drunk and blowing chunks in garbage cans, then embarassing themselves in front of professors, staying at the event long enough to clean everything up, drowsily eating waffles at IHOP after the event…

Keep in mind that one of the biggest problems facing the society isn’t usually lack of money- it’s usually some form of Executive Neglect. Keeping everybody interested and involved is the biggest problem.

Now, there are a lot of ways the CSSS could be adjusted to increase the amount of money we bring in- and there are a lot of potential uses for this money.

We could sell advertising space in the Common Room to sponsors. We could accept and manage sponsorship deals. We could register as a Non-Profit Organization and accept donations. We could produce and sell swag. We could farm human bodies for electricity while keeping them suspended in an elaborate simulation of life. We could *blah blah blah blah*.

Thing is, all of these things require close oversight, careful planning, and a lot of work. If at any point, one neglectful executive set comes along, the whole thing could fall apart like a house of cards. Checkmate.

Honestly, we have serious trouble keeping the few fiscal things that we do regularly manage afloat. Pop, pizza, and photocopies, mainly- with Frosh-Week and the FAS Formal as rare and *difficult* occurrences. Do we really want to have to deal with more of that? Is the pop-machine full right now? Are we really happy with the way the copy-machine is turning out? Be honest.

We could bring in more money, but with more money comes more administration, more accountability, stiffer requirements. Events become harder to plan, not easier.

The only way that the SFSS can stay afloat under it’s own stifling weight is because it’s massive bureaucracy is supported by a few layers of administrators that we rarely see. Being a part of the SFSS isn’t any fun- it’s deadly serious. Millions of dollars are at stake. I don’t think anybody or their mother would want to be Shawn Hunsdale right now. The SFSS has precious little ‘community’- it’s more an organization than anything.

The reason the CSSS is what it is.. is because it’s small.

It’s easy to be a member, it’s fun, it’s casual, and even so, we manage to accomplish great things.

If the CSSS executive can sit in the common room and drum up games of 1000-blank-white-cards, or Chess, or Go, or the Chairman’s Game.. the CSSS is successful.

The only reason we run the pizza, the pop, and the photocopier is because people like to eat cheap pizza, drink cheap pop, and make cheap photocopies. Now that there are other places to eat cheap pizza and make cheap photocopies, we could (and *should*) just bow out of those arenas and replace all of that painful administrative effort working on other CSSS services- the much neglected “Old Test Repository”, which could seriously use some love and digitization. The famed “Menu Project”. Games nights, Movie nights, and LAN parties- which need not cost a penny. Tutorials on open-source technologies. Our web-presence.

We could run the entire organization without money at all, and still be a valuable and useful student service- arguably a *more* valuable and useful student service because we’re not exhausting our time and effort painfully administering finances.

The CSSS is successful, not because of money, but because of the time and effort and love of the members involved. Dealing with money- even FREE MONEY- drains our time and effort and love- and in my opinion hurts the society more than it helps.

This Comment Brought To You By The Refreshing Taste of Dr. Pepper. “The Doctor Is In!”

So, the fan-translation of Mother 3 (”Earthbound 2: Finally More Earthbound, You Bastards”) is finally complete.

The game took 12 years to actually finish in Japan, and they (apparently) figured that nobody in North America was still interested.

Which, honestly, if it weren’t for the fan translation project, I wouldn’t be. I mean, Earthbound was a great game- very clever, original, and full of great characters. The ability to *pop* underpowered monsters like overfull balloons was a welcome addition to any RPG. On the other hand, it was a *monolithic* grind. I’m really not a fan of having to work -that- hard to beat a game.

If the button-lock isn’t on (it rarely is) my phone - a chocolate-bar, not a clam-shell - will do random things in my pants. Such randomness has included calling my mom, bursting out into glorious song, and taking hundreds of thousands of pictures of the inside of my pants. (Dark in there.)
If the button-lock isn’t on (it rarely is) my phone will switch from the useful ‘Vibrate’ mode to the useless ‘Silent’ mode in my pants.
Occasionally- about one in 12 times, sliding the phone open or closed will cause the phone to crash. The Motorola logo appears on screen for a couple of seconds, and when it comes back the phone will have no reception, and the background image will be replaced by a dull grey. Only a phone reboot will restore the background image.
The most convenient way to answer the phone is by sliding it open, which, every now and then will cause the behavior I’ve described above- instead of answering the phone, I get an instant reboot.
The software that arrived with the phone refused to install on Windows XP or Vista, claiming a missing .DLL file.
Apparently, no replacement software or patches exist on the internet. I could (potentially) order another copy for some unreasonable amount of money.
My younger brother bought a similar phone- also Motorola- with the same software, but it refused to acknowledge the existance of my phone.
The ‘amazing’ built in features are all broken and totally useless in one way or another:
Mp3 Player: Stunted by lack of battery power. The mp3 jams totally drain the phone and are good for 2 hours, tops. Note that the phone (for some reason) comes with 2 entirely different mp3 players, on the off chance that.. I don’t like one of them?
Camera: Here is a picture from the 2 megapixel camera. No doubt, my younger brother is awesome, but the camera is terrible.
Video Player: See: mp3 player. On top of that, the lack of software makes uploading videos nary impossible.
Mobile Internet: The built-in browser fails to render even the simplest of pages, and Bell’s bandwidth charges are obscene (In my case, $51.28/MB). They clearly want me to cave and add a $7 ‘mobile internet’ plan to my phone if I want to use that feature- well, fuck them.
Text Messaging: $0.15, outgoing or incoming, with a much higher rate if I happen to be texting outside of my default area. They clearly want me to cave and add a $7 ‘text messaging’ plan to my phone. Well, fuck them.
Voice Dialing: Does this work for anybody?
Bluetooth Connectivity: Unfortunately, I’m not a douchebag. Who knew?
Additionally, it totally fails to make waffles. I want a phone that can MAKE ME SOME DAMN WAFFLES.

So, downloading a bunch of Good Eats episodes has had a negative effect on my ability to cram random objects I find around the house into my mouth.

Instead, I thought to myself.. ‘omelette’. So, I found the relevant episode of the show.

My omelette had paprika, chili flakes, basil, cheese, and fresh tomato. Before that, I took some leftover potatoes and fried them up with seasoning salt and black pepper.

This is the ’scene’ I’ve put together for my second IAT 343 (”3D Animation”) assignment.

Those of you with eyes might notice that this is exactly the same thing that I submitted for my first IAT 343 assignment. Notably, the first assignment I prepared exceeded the requirements of the first assignment- and seemed like a candidate for the second assignment.

However, this week, instead of concentrating on the modeling of the various objects in the scene, let’s concentrate on the texturing and lighting.

The book’s material was prepared in Photoshop- the pages are a ‘faded paper’ texture with the words to Alice in Wonderland on a transparent layer on top of it. The book’s ’sides’ are composed of the faded paper texture, again, but less bold, and with straight lines drawn down the centre.

The pencils explore the crazy possibilities of UV-mapping- namely, binding a Photoshop file to a UV map, then painting within the UV map. As a strange note, between Photoshop and Maya, the UV map seemed to shrink- I eventually had to re-adjust the whole thing to make it look proper.

The table is a reflective Phong shader with a wood texture. The wood-texture is then used (in black & white) as the bump-map for the shader. I wasn’t sure if this was going to work properly, but with the bump map, reflections off of the table have a convincing ‘wobble’ to them.

The scene’s light is tinted yellow to keep the scene warm & inviting. The scene’s lighting is composed of four lights- There’s one ambient light to keep the scene from being completely dark around the edges. There are two spot lights inside the lamp- one pointing down and one pointing up. This produces the proper lamp-light-circles (one coming out of the top and one coming out of the bottom)- and then a bright point light inside the lamp to create a brighter feel for the whole scene, emanating from the lamp. Note that the lamp’s bulb is set to glow- which combined with the light, makes the lamp’s reflection in the desk look snazzy.

The lamp’s base is a simple anisotropic material with reflectivity set up a bit- in order to make it look a bit ‘lampier’.

Here are the textures used to prepare the scene.

310 is turning out to be a pretty interesting course.

I spent the bulk of today building a Min-Max Backgammon-Playing Algorithm, and then a Backgammon-Evaluating Function that could be used to try to ‘read’ the board.

My more-advanced algorithm was able to easily trounce the professor’s provided “Random Backgammon Agent” and “Simple Backgammon Agent”. When it played against my girlfriend, however, it had a strong opening game- with an almost unnatural ability to anchor points- but refused to push its lead and ended up losing. It didn’t help that Kristen ended up with a *LOT* of doubles.

As for a quick breakdown of the items in the scene, the book was created with an extrude, two planars, and a couple of lofts, which were then duplicated and flipped around to form the other half of the book.

The lamp was all about the revolve command- both the base and the shade. The bulb is a modified NURBS sphere. The cord is extruded. The fun bits of the lamp mostly revolved around trying to make it work as a light-source for the scene- there are two ’spot’ lights (one pointing down through the bottom of the shade, one pointing up through the top- this becomes more apparent in a shot that’s further away), one ‘ambient’ light (to keep the room visible, even in unlit areas) - and a ’spot’ light inside the lamp to provide general warmth to the scene. All of the lights are ‘yellow’, because most house-lights are yellow (not white).

The pencils are polygonal cylinders, so chosen because they lend well to UV-texturing- which I then used to paint the pencil-bits on in Photoshop. The cup the pencils are sitting in is .. revolved. Poorly. Don’t look too closely at it, you might hurt your eyes.

The table is a plank. It’s bump-mapped a bit so that the reflections on it wobble.

Sometimes, I wish I could drop courses without penalty a few weeks in.

A lot of times, I make a snap judgement on a course (”This is going to be frustrating and horrible, I know it!”), but I don’t drop the course immediately (”It could get better, right?”). This is, of course, a huge mistake on my part. Honestly, a lot of times I just don’t want to be left hanging in some sort of Twilight Zone where I’ve dropped one course and there’s nothing there to replace it.

The Animation course offered by SIAT at SFU is one of those gems. It’s two parts, a two-hour-lecture and a two-hour-lab.

The two-hour lecture is not two solid hours of information transmission. The professor has a thick accent, and his grasp on the English language is … adequate. On top of that, he’s new to the whole ‘professoring’ business, and so not only does he use Powerpoint, his slides are the common trope of “Here are a bunch of pictures, I’m going to talk a bit about this thing”. The topics meander, there is no easy way to summarize what he’s saying or separate important/relevant data from ‘chaff’, and just listening at all is an exercise in frustration.

The two-hour lab is (quite possibly) worse- the professor blazes through a process on a demo computer. *woosh woosh woosh woosh*- and here we have a balloon-puppy! Of course, being as no human being is able to precisely follow steps at the same speed as the professor goes, people inevitably get lost. Some people sit, staring at the computer and the professor like sad, lost puppies. Others (here we have me) inevitably grab the tutorial slides and try to make our way through the tutorial at our own (more appropriate) pace.

Which would be good, were it not for the professor’s aforementioned nebulous control of the English language.

Not only does this tutorial have roughly the same level of clarity as your standard table-assembly-instructions (”Insert left leg (’A') into right peg (’B') also twisting table-top(’C') lengthwise”), it’s painfully short, omits important instructions, contains precious few images of associated steps, and contains no context information.

And let’s not even start with the professor’s exaggerated time-frame for the tutorials. In week one, having spent exactly 0 (zero) minutes using the software, the tutorial quite optimistically assumed that we would be able to learn our way around the user-interface, assemble a fine beer mug, followed by an entire Indiana-Jones-inspired cave-and-bridge scene, in about 2 hours.

Nobody completed these tasks, of course. After about an hour-of-a-half most of us had reasonable mugs going on- but that was after the TA had gone to just about each and every computer and painstakingly explained the process to each individual student.

That second scene found it’s way into the second tutorial, with the following itinerary:

Exercise 1: Surface Bevel & Planar (15 minutes)
Exercise 2: Polygon Duplicate & Color (10 minutes)
Exercise 3: Set Design
–Castle: Polygon Extrude & Polygon Boolean (15 minute)
–Terrain : Sculpt Geometry & Polygon Split (15 minute)
–Bridge: Duplicate (15 minute)
*sigh*.

So, I’ve spent the last few weeks painstakingly trying to assemble enough Maya knowledge to actually construct something useful and reasonable (see: not something directly out of a tutorial) out of various online references and textbooks- although not the textbooks that we had to buy for the course, which have been (so far) pretty narrow in scope at best.

So, today, I discovered that Ryan Estrada is up to Hijinx.

One of my regular-rotation webcomics had a guest comic by Ryan Estrada. No big deal, usually- guest comics are as common on the internet as… uh… other things.

But then, as I was wandering aimlessly through my list of ‘less-often-read’ webcomics, the name “Ryan Estrada” appeared a few more times- each one with a guest comic.

I started going through my list of comics and checking to see which ones had been “Estrada’d”.

Sam & Fuzzy, Shortpacked, Wapsi Square, Real Life, Scary-Go-Round, Dresden Codak, Anders Loves Maria, and We The Robots - and those are just the comics that I know about.

How far does the rabbit hole go? I’ll have to do some investigative journalism.

And add ryanestrada.com to my list of ‘comics to read.’

o, being as I may be potentially working for a subsidiary of Nexon in the near future, I was thinking that I might take a look at one of their most popular(/advertised) online properties, Maple Story.

If I had to describe the game in two words? Poorly translated.

I can’t even begin to enumerate the almost-but-not-quite-syntactically-correct-English in the game. It’s just a step above Zero Wing in terms of translation quality.

You start off with the MMO-standard almost-nothing-at-all. Here’s your undershirt, shorts, and wooden sword. Go kill snails a bit.

As for the user base, it seems to be composed entirely of the 8-12-year-old crowd, a bunch of whiny, immoral, “r u goin 2 mk fun my bff wh0re?” sort of crew that so nauseates me.

I had some fun attempting to perform a trade with someone while pretending to have no concept of what ‘trading’ is, how one might perform such a trade, what ‘money’ is, what value it might have, that sort of thing. (’r u stupid?’ “No, I’m just having trouble understanding the concept- in exchange for 2000 arrows, you will give me… money? What is this.. ‘money’?” ‘it’s MONEY!’ “Yes, yes, saying it louder won’t make it any clearer”…)

The game itself is pretty standard MMO fare- hit things about the head and neck in exchange for points, tiny amounts of money, and countless tiny MacGuffins (”Bring me 281,092,102 horbongler pelts!”)

The game doesn’t seem to have any appreciable draw- the community is too downright young for anybody with armpit hair, the gameplay is simple and slow and boring, and .. wait, I just thought of the game’s one saving grace- the game’s appearance is lively and animated. So there’s that. I suppose if you toss a nice ribbon on a pig, you have … one of the game’s early enemies.

I recently discovered a site (thanks, Reddit!) called “Dear Adobe“, where people gripe about their various beefs with Adobe’s software.

It’s a very consistent set- the top 100 are pretty much:

1. Everything is too expensive.
2. For non-Americans, everything is EXTRA-too-expensive.
3. Acrobat Reader is a aircraft-carrier when we want a Volkswagen Jetta.
4. The Adobe Updater is the worst piece of software ever. Look, we don’t want to close Firefox or restart our computer- these are things that we don’t like to do, especially when we’re using your software and are therefore *busy*.
5. Less “adding features”, more “improving stability” and “running faster”.

Yeah, I agree with every single point there. And most of everything else on the site, but those are the most common ones.

Okay, so, I’m interviewing at Humanature Studios this coming Friday, for a co-op position.

My rather silly cover-letter-and-resume-package was the key.

Apparently, though, they’re rather interested in my C++ skills. Now, I’m a sharp guy- I have a week to remember everything I’ve ever learned about C++ - but C++? After spending time with Python, and, heck, even C#, working in C++ again might make me cry a little.

Have you guys ever heard of this studio? This company?

How does one summarize the Penny Arcade Expo? I mean, without having to worry about all of the work and difficulty of carefully planned exposition.

We drove across the border, along to a carefully chosen selection of funky jams. Being as we left at 6:00 in the morning, the border crossing took almost no time.

Having arrived in Seattle, we hunted for a breakfast place. We found a small Hawaiian cafe, serving various combinations of egg, bacon, and cheese.

There were many beanbags- we lost one of our travelling party to their gaping, beany maws.

We left Kiyomi behind, to fend for herself with the beanbags, and stood in line.

And stood in line.

And stood in line.

We waited in line for 30 minutes, and were then presented with… the main line. We had been waiting in the pre-line line for the past 30 minutes. The main line was spectacular.

Having seen the line (one of PAX’s biggest attractions), we retreated to attempt to rescue Kiyomi from the bags, but we were instead engulfed. We spent the better part of 2 hours fighting with the beany hulks.

We retreated for lunch at a delightful Mexican stereotype, then returned in time for the expo to start.

The floating, disembodied head of Jonathan Coulton commanded me to get his autograph. I did. That and Freezepop, the Minibosses, and the OneUps. I now have mad CD’s, as well.

We ate at Von’s that night. They had barbequed just-about-everything. My younger brother demonstrated the proper system of barbeque safety.

The concert- The OneUps, Freezepop, and Jonathan Coulton- was fantastic. Freezepop finished with Europe’s Final Countdown, and JC rickrolled the audience.

He knows the rules, and so do I.

On day 2, we woke up, and bought more breakfast sandwiches. Delicious breakfast sandwiches.

Time was spent at the Expo hall, wandering and glorying in delicious commercialism. I acquired a “Your Mom Is A Classy Lady” shirt, as well as a shirt featuring Inky, Blinky, and Clyde (not Pinky, though).

Lunch at Johnny Rockets. We had burgers, onion rings, milkshakes, and chili fries. Healthy.

Then Team Fortress 2. Kristen took to it a lot faster than I’d have hoped.

Dinner at the Asaggio- highly expensive Italian food. Also highly delicious.

That night, we played Carcassonne and Apples To Apples in the games room.

Notably, we found a beholder, which ate Kiyomi.

The day after that, there was more Team Fortress 2 (Kristen’s getting pretty good with the soldier) and some delicious chowder at a chowderery. Chowderhouse. Chowder.. place.

Then, we crossed the border, stopping for Fruity Pebbles and Thomas Kemper beverages.

Fun was had by all. Woo PAX!

Google Chrome is, so far, pretty amazing.

In case you don’t know, Google Chrome is a new WebKit-based browser with mad-crazy Javascript speeds. It has tight memory management, so it’s not a candidate for the “Firefox is now eating 800 Megs of system memory!” problem.

It takes the Firefox ‘AwesomeBar’ concept and rolls with it, paring the UI down to just a google-powered SuperAwesomeBar and slick tabs. You don’t know how many times I’ve wanted to drag a tab out of Firefox to make a new window. Now I can! (Huttah!).

Google Gears is (of course) built right in, and the whole project is (of course) open-source-free.

It’s small, and blazingly lightweight/fast. I have to say, I’m definitely in like with it.

Here’s the thing, though- I wouldn’t know or care about all of Google Chrome’s neat features if it weren’t for the informative and highly sexified Google Chrome Comic Book. “Hey, that looks a bit like Scott McCloud”, you might say- yes it is.

Scott McCloud is currently one of the world’s masters in the field of visual expository- I mean, he’s one of maybe eight people in the field, but nevertheless he’s damn good at making explanations concise, readable, and interesting. If he wrote a book on calculus, I might finally understand what the hell a complex number is.

And the comic he wrote- well- it looks like it took a lot of work to make, but I hereby decree that I will take in *any* information presented in this fashion, and like it!

So, today’s my last day at Electronic Arts- Woo, freedom! It’s hard to believe I’ve been doing this for 4 months!

And now I’m free, free as a bird, at least for the next week, at which point I have to return to school to have more information forcefully drilled into my skull.

What would I say about EA? It’s not nearly as bad as I thought it would be. The “horrible grind” that’s so legendary working here has hardly come into play. I just built things with C#, showed them to people, and then escaped in a puff of smoke- similar to my last job at Research in Motion. (Except at Research in Motion, it was PHP.)

Would I come back? Yeah, sure. Honestly, my supervisor’s going off to a new department to work on a project that, while potentially doomed to fail, at least seems like a really interesting concept to work on.

As for me, I’m off to a semester of freelancing- even though I haven’t lined up any clients or potential work, yet. I suspect that through the power of luck and my fantastic eyebrows, I’ll find something to do for money. If anything, I could always teach myself Flash.

Working at EA, I often find myself wondering what my favourite game developed by Electronic Arts would be.

Not a game developed by people who are now owned by Electronic Arts- that’s a pretty big category, dominated by games like Baldur’s Gate 2, Battlefield 1942, and SimCity 3000.

No, my favourite EA game. I’m going to have to say that the pinnacle of Electronic Arts’ sports development had to be Mutant League Hockey.

It takes all of the fun of NHL ‘94, mixed with chainsaws. How could that not be the best thing ever?

So, now, I’m reaching the end of a semester-long project at Electronic Arts, and I’ve been called upon to create a document describing what it is that my software does.

I had to do this near the end of my time at Research in Motion, too.

Here I start my rant- if you’re building a user-interface, it shouldn’t need a manual- nobody’s going to read it anyways- it should be completely usable without so much as glancing at TFM.

On the other hand, if you build tools or libraries in code- which you inevitably will do, if other people are going to use said code- if you haven’t documented it, it doesn’t exist.

Oh, a clever developer can take some time, familiarize himself with your code, understand how it works and what it does- but this is slow, and inconvenient, and a pain in the ass. Commenting your code makes this faster, but it’s still a laborious process for the new guy- and people depending on your code ‘externally’ don’t even want to LOOK in your file, never-mind read the comments.

So, in order for your library to actually be used, and popularly, it needs to be documented. But here’s the question- how do you write good documentation?

I can’t say I’ve hit upon the perfect formula- I still have no clue how to write good documentation, but here are some little tips I’ve picked up.

I’m starting with obvious tips, of course. Start by explaining what the code does, and why it’s there. Why is the library there in the first place? What problem does it solve?

From there, detail how to install it, and any requirements the code might have- even if these instructions are just “plunk the code in your directory, and call it using ‘ include MyLibrary; ‘.

From a purely intellectual standpoint, users can read a function description and know what it’s supposed to do- But the entire time they’re reading, what they’re trying to do is to construct, in their heads, a working example of the thing that you’re describing.

If you say, “First, you have to instantiate the class with the value of the website you’ll be scraping, then iterate through it by calling the ‘read’ member function until it returns a null value”, the first thing the developer does is mentally try to map out what you’ve just said into usable code- say, like this:

I know that I’ve had problems with some programming manuals doing this- not only do they include examples, but their examples are pages long- the examples are entire programs that you’re expected to mentally parse and understand for the sake of learning one new concept. Oh, sure, that’s a way to go, but that’s almost as irritating as being faced with no example at all- you have to work harder to understand the concept in play.

I understand the desire to demonstrate that your examples will work in a large-scale program- but if you’re showing off a large chunk of code, it becomes harder and harder to sift through said code to find out where the actually-relevant-and-new parts are.

Most of us already understand how to build a complete program- that’s not why we’re looking at this example. We’re looking at the example to find out exactly how one specific bit of code works.

If you have a function with a lot of parameters, make sure to explain what the parameters do and what ‘valid’ input values are for those parameters. The w3cschools website does a great job of this with CSS Parameters.

Avoid leaving the user with large, continuous blocks of text to deal with- big chunks like that are intimidating and hard to parse. Breaking up text with headings gives readers a feel of organization, and makes it easier to find pertinent information a second or third time.

As an example of this, image this exact same article, without any headers. Yeah.

Sometimes, a code example just won’t cut it- you need to tell the user to ‘right click on the button to the far right of the screen’, or ‘Go to the file -> options -> monkeys’ dialog. Once again, your reader is smart enough to just muddle through with your instructions- but if you want to be absolutely clear, do the thing that you’re suggesting, press the “Print Screen” button, cut it down to an appropriate size and include it with your documentation.

If you’re explaining a step-by-step task, you’re not allowed to just try to wing it from memory. You’ll almost invariably forget a step or an important detail. Actively go about completing the task that you’re describing, while you’re describing it.

Sometimes, you just have no idea how to proceed. What do you need to write down? Writing in a question and answer format can sometimes provide that additional impetus to get you writing.

What do you mean?

Well, if you don’t know what to write, just imagine some of the questions that people might have about the thing that you’re documenting.. and answer those questions. If people ask you real and specific questions about the thing that you’re documenting, include those, too!

That’s silly.

Silly, yes, but if you’ve got writer’s block while you’re documenting things, you’re in for a world of hurt. Try it before you knock it.


Not that the most of you are overly concerned with my schedule, but next semester, I’m taking Artificial Intelligence, Operating Systems 2, and Animation from the Interactive Arts & Technology department.

I also (as-of-yet) don’t have a job lined up.

This is unprecedented for me- I’ve had a job every semester that I’ve been at SFU so far. Retail, TAing, all sorts of things. Next semester, I have nothing lined up- I’ve purposefully lined up nothing whatsoever. Maybe some contract work? I don’t know. I’m sure I’ll figure something out.

 Well, it’s finished for now. We don’t really know what more to add. It’s time for everybody to hop on the site! Share your video-game connection details with the world! Then, tell us what to add to make the site suck less! Do it for Stan!

As for us? Well, we’re handing it in tonight. (So if you find a real gamebreaker, tell us now. )

There’s a hidden downside to Steam.

Here I am, wanting to play Team Fortress 2, online. I’ve purchased the game, I should be allowed to play it whenever I damn well feel like it, right?

Wrong.

“The Steam servers are currently too busy to handle your request. Please try again in a few minutes.”

This is the thing that has people all up-in-arms about digital distribution systems- I don’t give a flying fuck if Steam’s servers are down. I just want to play Team Fortress 2. The Steam servers should have nothing to do with it. And what if Steam goes out of business? Do I lose the ability to play all of my games forever?

I hate CD’s, so digital distribution is definitely the way to go.. that or piracy- but I wish it didn’t suck so much.

I was really hoping I’d have more time to devote to the project, that Ryan and Sepand would have more time to devote to it, too- it still needs so much work to even start to feel like a real, useful tool. Certainly it’s not going to get that far over the long weekend, which will be the last time we work on it as a team.

I suppose if I have to compromise on the features and functionality, I must at least maintain a high standard of craftsmanship with what we *do* end up putting in. And by a high standard of craftsmanship, I mean *more work on the stylesheet*.

Do I keep working on it after the semester is over? I don’t know. I was never really sold on the idea in the first place- Social Networking really does suffer from the chicken-and-egg problem of ‘where are all the users going to come from?’. I think it best just to polish fri.endcode into a portfolio piece and move on.

I am stuck with a pickle.

I have a large block of code that I edit on a fairly regular basis- and I’m getting slower and slower with this large block of code. It started out small and lithe, but has blown up into 900-lines of spaghetti code- oh, well-structured spaghetti code divided into clearly-named functions, but it’s all getting to be too much to fit into my head at once. It’s making changes to the code much harder than they should be.

So, how do things get so out of control?

Let’s briefly discuss database code.

When you first encounter databases, you almost inevitably have a snippet of database code borrowed straight from The Book just socked right in your site’s display code. This is, of course, messy and horrible.

Soon (for me, it was about 5 minutes), you come to realize that you can fold all of that database code up into a function- saving yourself many hours of time and debugging.

Once you’ve done that, it becomes painfully clear that all of the start-up and take-down code for the database is common to all of the database functions. You set up a database class holding connection data and start-up/take-down code, and then just fill it in with functions for each individual query. This is how I operated when I was in Waterloo, and it was (overall) a pretty slick system that kept code-bloat down and the codebase organized.

As a further refinement to the process- having a master class with connection details, then subclassing it into categories based on the sort of data being pulled- turned out to be a pretty good way to keep the files small and easy-to-edit. No use worrying about Unrelated Table X when I’m making queries against Table Y, right?

But with the project I’m currently working on, the number of things this one database is called on to do is growing to be larger and larger- and with it, the list of functions. And, worst of all, a number of these functions depend on one another to operate properly- the database doesn’t have a lot of clean ‘division lines’.

On one other, also-large bit of database code, I ended up sorting all of the individual queries into their own tidy-little files, with a master class to handle connection details and any complex multi-query datasets. It took about a day to set up, but ended up making my life much easier. I’m thinking that this may be the way to go with my 900-line monster.

But before I do, my question is - how do *you* go about organizing large chunks of DB code?

And don’t say “With an Object-Relational-Mapper“, because that’s cheating- well, not really, but I’m in the last few weeks of this project, and it’s too late to be fiddling around with .NET’s LINQ.

So, there’s a guy in a cubicle right next to mine whose name is “Steve Watson”, and who acts a lot like the Steve Watson that I knew.

I’d tell him, but there’s no non-creepy way to say “You look and act just like my recently-dead uncle, and also you have the same name as him. I bet you’re about the same age, too. Strange, huh? ”

Yesterday, John Boxall of Handi Mobility delivered a presentation on the Mobile Web for our CMPT 470 class.

I learned that the much-vaunted “MyBus” SMS-bus service for Translink was initially powered by screen-scraping- and, indeed, is *still* powered by screen-scraping. Not that there’s anything wrong with that, just a tad surprised.

John Boxall’s a “Ask Everybody A Question And Then Wait” style presenter.

“Does anybody here know where the error is?”

“Can anybody tell me what you’d be looking at if YOU were a genius billionaire playboy web developer like me?”

“Who put the bop in the bop-she-bop-she-bop?”

“Who here has an iPhone?”

The problem with questions like that isn’t the question- it’s the inevitable wait for someone to answer. Always remember- presentations are not two-way, no matter how much you want them to be.

We then got a lot of sales mumbo-jumbo about how mobile web development is the waaave of the future.

In our class of 30 people, only 3-4 of us had ever used the mobile web on our phones. Few of us had data plans, and I was proud to be one of the small group of people for whom ‘text messaging’ is not a thing that I do.

To be blunt, we’re CS students. We’re largely a group of early adopters- and even we haven’t really wandered into the wild-and-wooly world of mobile internet access.

It doesn’t help that Canadian cel-phone companies don’t seem to want you to *use* any of the functions your phone has- well, at least without paying some sort of exorbitant fee.

Phones with decent UI interfaces, 3g, and reasonable data plans are new. Like, this-year new. Most of us are still stuck on a three-year plan with a phone that’s just marginally better than a sack of wet beets.

Hell, I hate my phone (Note to everyone: Motorola = No. Make a note of it.) but I’m on a $30/month no-system-access-fee 3-year contract with early evenings-and-weekends, voice-mail, and caller-id, and unless I plan to start tossing some serious cash at my already-a-bunch-of-douchebags cel-phone company, I’m certainly not going anywhere fast- and guess what? I’m here with most of the consumers. The current mobile environment in Canada doesn’t support speedy cel-phone changes.

Something about system access fees make me angry, too. There’s just some mental block that goes ‘I’m not falling for that’, and I get totally unwilling to consider a contract.

If I wanted to upgrade to a phone-that-doesn’t-suck-for-web-browsing and a data-plan with unlimited-but-slow mobile web access, I’d have to blow about $600 (on the phone) and then spend an extra $18/month on my data plan.

You know what else I could do with that money? That’s right, astute readers- delicious sandwiches.

The iPhone got the ball rolling. The mobile web is coming. It’s going to be big- just you wait. Just not.. yet. Just like dial-up internet wasn’t good enough for ubiquitous internet access, the current mobile web environment (in Canada, at least) isn’t robust enough to support a lot of good apps- and won’t be until everybody’s contract expires and smart-enough phones are their new replacements.

A strange thing I’ve noticed is that anywhere on the internet that criticism of Django seems to pop up, it’s not long before a Django Guy rushes to it’s defense.

Now, using Django more and more, I start to internalize it’s idiosyncrasies and feel like everything is where it is for a reason, so I can see that a lot of the criticism is misplaced- but it’s strange that there’s always someone out there to point that out- some Django Avenger, ready to swoop down and defend his technology of choice against all complaints.

So, um… Hello, Django guy! .. er.. Keep on’ truckin’!

So, I just had a fantastic.. week. A 4-day Stag party, 2 weddings, Dr. Horrible, the Dark Knight, and I found the charger for my DS- all at once.

I’m just waiting for Chris to post & tag his pictures- notably, this might take some time, as he took thousands of them- so that I can summarize the entire week more effectively.

Yay!

I love Valve’s Steam.

Steam is Valve’s digital-distribution center- you pay by credit card and get unlimited access to downloads of a certain set of games. Steam downloads the games, keeps ‘em updated in the background, and if I swap computers, I can either move all of my game files over from the old computer or download them again. I hate having huge collections of CD’s, so that’s good. The only potential problem is that if Valve happens to go under, I’ve lost maybe $500 worth of awesome video game- clearly problematic, I know- but I really enjoy the convenience of Steam.

There are a number of features that Steam lacks- you can’t browse the web from within the Steam browser, although it’s clearly HTTP-based (so why not?). You can’t throttle or cap your downloads (So when it goes, it goes at full speed and if you don’t have QoS on your router, your whole home network is going to be sluggish.) The store makes you go through the exact-same slow-and-boring purchase process for every game you buy- even if you buy ten at a time.

The features- News, Friends, Servers, Settings… well, Friends works okay, but all of the rest of ‘em aren’t exactly great.

Okay, so it’s not exactly the best client out there- but Valve has the best PC games- they have the market clout, and my friends are on Steam, so I’m locked in that way, too. It would be in other companies’ best interest to hop on Steam as well- but it seems that, instead, they’re all trying to release their own digital distribution clients.

The silliest one so far is Stardock’s “Impulse”, on account of they have maybe 2 games on there (Sins of a Solar Empire and Galactic Civilizations).

In order to try to beef up their selection a bit, they’ve got some Corel products and some shitty desktop software rounding out the mix. Okay- we’d all love to have a reasonable Windows package-manager- a Steam for applications, an apt-get for Windows- but that’s such a huge undertaking that you can’t just tack one on to an existing digital distribution system and hope for the best.

The only company at this point that could hope to compete with Valve’s rolling clout is EA, and I’m sure that they’re trying their very best. Having the most popular digital distribution system is a pure gem- right now, Valve is making all of the markup on games from about 15 different publishers sold online. That’s pretty damn schwag.

Here’s the thing, though- all of this competition between digital distribution systems, tall and small, is a pain in the ass. Oh, sure, from the company’s standpoint, they want to be the storefront that people buy from, and sure, competition is good- but I don’t want to run a lot of these things on my computer, have a lot of different usernames and profiles and such. I just want the one. Large companies are sure to try to compete with Valve- there’s no doubt about it- but small companies- you guys should just be trying to get your games on as many content distribution networks as possible.

It’s become a widespread theme amongst my friends- we hate telecom companies. We hate them *SO MUCH*.

Wonder why I don’t use the browser on my phone, much? Well, it’s a Motorola phone (silly me), so the browser is terrible, but even were I so inclined, Bell Mobility has decided that for me, network bandwidth should cost $51.28/MB. It says there right on my bill. Wouldn’t it be neat if your cel-phone doubled as a modem? Well, not if a gigabyte of data ($52,510.72) cost more than a 2008 Lexus GS 350 (starting at $51,000).

Imagine that, instead, you’ve got one of the slightly more reasonable Rogers 3G Phone Plans- these things are built for data, yeah, baby. You’re still paying about $100 for that gigabyte. Oh, it’s a far cry from $52,510.72, but $100 is no chump change.

A lot of my friends bitch and moan about this- and rightfully so. Our cel-phone companies are reaming us, and there’s not a lot that we can do about it. This is a market seriously in need of some friendly competition.

I don’t know about you, but one of my favourite programming constructs is… foreach.

PHP has it, C# has it, Python has an even better implementation of it.. and JavaScript has it, but JavaScript’s version doesn’t do what you think it does.

Look at these two sets of code and tell me which you think looks cleaner:

Okay, some of you are familiar with the concept of “Achievements”. They’re little badges that you can get on the Xbox 360 and on Steam (mostly on the Xbox 360), for performing certain tasks in video games.

Now, one thing that Team Fortress 2 has to offer, is a lot of achievements. There are 17 that came with the game, and then, in free expansions, 39 for the Medic and 38 for the Pyro.

That’s great! I love achievements! It makes a victory all the more sweet to get that victory, and then be informed that you’ve killed a grand total of 100 enemies. You even get a cute little badge.

But here’s the problem- Valve has included new weapons with the achievement packs. They change the game ever-so-slightly for the players. Pyros can replace their shotgun with a flare-gun, Medics can leech life in a vampiric sort of way… but you can only get these new weapons when you get a certain number of achievements.

So instead of people amassing achievements organically, over time, people have set up “Achievement Farms” online, the whole purpose of which is to get people all of the achievements as quickly as possible.

This makes the achievements less fun- all of a sudden, instead of lighting people on fire because you’re a borderline pyromaniac with an itchy trigger finger, you start lighting people on fire because it’s your job.

Well, I’m going to get my achievements the old fashioned way- by lighting tonnes of people on fire. It’s more fun that way. And if you light me on fire with one of your snazzy, achievement-farmed Pyro weapons? Well, you can eat my ass.

When I heard that Ladytron had a new CD out, I was practically vibrating with excitement. I even went to HMV, hoping to buy my first CD in years. They didn’t have it, and I was frustrated, but see how close I came to actually purchasing a CD? Even in this day and age!

Like all of the Ladytron albums (and most albums from any band) there were a few really strong hits that grabbed me from the outset- Ghosts, as a fine example, was just awesome from the get-go. The rest of the CD just seemed like ‘more of the same’, boring, lah-dee-dah. You can’t listen to a whole CD worth of new songs at once from the same band, I’ve found.

I tossed the CD in my morning wake-up CD-player, however, and found myself humming a different song from the CD every couple of days. Aren’t new CD’s always like that? At first, you fixate on the hit singles, but after a while you start to enjoy the whole CD.

Okay, so, these guys have a hit on their hands with “Handlebars“.

Honestly, I usually can’t abide by anti-corporate fight-the-power music. Honestly, from a group that’s owned by Universal, that’s a pretty hypocritical stance to be taking. The feeling that I’m having pre-packaged rebellion *sold* to me is just dirty.

On top of that, as a white upper-middle-class software developer, I am The Man. Convincing people to rebel against The Man is almost entirely counterproductive from my standpoint.

Given that, the CD has a couple of pretty catchy songs.

My post “IRCulated” hit the front page of programming.reddit.com and stayed there for a good two days. On top of that, a bunch of Redditors contributed their own jokes along the same vein.

The page got over 4000 visitors (that’s big, for me). Neat.

If you’re not familiar with the Team Fortress 2 “Meet The *” series, they’re all hilarious. I haven’t even tried the new Pyro updates, yet. But I will. Oh, I will.

Now, here’s the deal. Currently, in Vancouver, we have a huge shortage of high-quality teenagers and easily-taken-advantage-of immigrants- that is, people who are willing to work hard for low pay, on account of their lack of experience and part-time requirements.

This is not a bad thing- hard workers are now worth more than the minimum wage. That’s actually great!

For a fast-food restaurant to maintain a dedicated staff, now, they either need to ride everybody’s ass 100% of the time (at which point they’ll quit and get a better job), maintain an interesting and exciting job (which is impossible because it’s FAST FOOD), or pay a little bit more. They can’t fire people who aren’t good at their jobs- there’s nobody to replace them!

The restaurants that aren’t willing to do these things are not going to end up with the best people- because a better job is always just around the corner, and the job market is good.

I have two relatives in the food service industry right now. If you want to sell food, you’ll always do it better with polite, efficient workers. This is a hard and fast rule.

If it’s in a good area- in a WalMart, or at a Harbour Center, they’ll have customers no matter how bad their service is. They don’t have to pay, they won’t.

So the quality of service in local fast food restaurants- especially ones in high-traffic-areas, has been dropping dramatically. A few weeks ago, I ate at a McDonalds which was apparently manned entirely by sullen-looking 14-year-olds. They were incredibly slow, the restaurant was a mess, and they put my pickles outside my burger. How do you fail at making a double cheeseburger? It’s not that hard!

Slow service from a worker who looks like he’d rather be at home? I don’t want to eat there. I do expect better. I will go to a different restaurant in the future. Service matters. If the restaurant doesn’t want to pay to maintain a polite, efficient staff, I don’t want to pay to eat there.

So, yes, I’m one of those assholes who expects the royal treatment from immigrants and teenagers who are “stuck” working minimum wage food service jobs. I’m not going to try to make their lives more difficult, but if they’re terrible at their jobs, I’ll go somewhere else. (In the case of the SFU pub, that’s the Mountain Shadow, for example.)

Friendcode is a social networking platform that … oh god, did I just say ’social networking platform’ in a non-ironic sense? Kill me now.

Okay, let’s try that again. I’ve got a bunch of online identities- Wii Friendcodes, an Xbox Live Gamertag, a Steam ID, DS Friendcodes, the works. It’s getting hard to share these things with my friends- and the whole point of these things is sharing with friends. Friendcode is a meta-service to organize, sort, and share online identities - concentrating primarily on video games.

I’d like to alert you to a tragedy.

A tragedy happening under your very nose.

Thousands of children worldwide are born- in orphanages, hospitals, even low-income areas of this very country- without names.

Be it because they cannot accurately trace their lineage, or simply because nobody has bothered to pay attention to them, they grow up without that simplest of human dignities- a name.

Currently, North Americans are enjoying a name boom. Everybody is guaranteed two names- even three or four in the case of some more affluent families.

Names are becoming so common that many people are just discarding unused parts of their name. Many professors, teachers, and doctors discard their first names entirely in pursuit of professionalism, while models, rock-stars, and butlers often ignore their last names completely.

A recent medical study shows that over 85% of North Americans don’t use their middle names at all! What a waste!

I won’t even mention the rash of nicknames currently spreading across America.

So I call upon you- the kind, caring readers of my blog- to consider donating the unused parts of your name.

It doesn’t even need to be a full name- Is your name Jonathan? You can contribute ‘Jo’ and keep ‘Nathan’ for yourself. Every little bit counts.

Some names you know are names that have been built by charity. Christopher Bayes and Mary Grace Quinn donated enough of their names to piece together the name ‘Topher Grace’- donated to an orphan who eventually became a star of film and screen.

Those of us at the Name Institute of America hope that you find it in your heart to ensure that those unused bits of your name go towards a good cause. If you’re interested in more details about donating, please call 1-888-YOU-NAME for a consultation.

Thank you for your time.

Just reading an article at Coding Horror, I’m realizing that- as a web programmer- I’m abstracted away from a lot of the deep-magic of actual Computer Stuff.

When it comes down to it, I know the basics about data structures and algorithmic complexity- but it’s fuzzy and only getting fuzzier. I don’t know what the worst-case insertion time of a hashtable, nor do I even remember what a ‘priority queue’ is.

I suppose I should put some effort into keeping my ‘base CS skills’ sharp over time. If I forget everything, what’s the point of paying for this expensive degree?

As a student at Simon Fraser University, I understand that courses have a variety of different outcomes.

Some courses- like Operating Systems I or Data Structures are meant to teach some definite, real-world skills.

Some courses combine theory and skills- like Networking- with a big chunk of graph theory- or Compilers, which works through theories of grammars.

Some courses are all theory- some all skills. As a young, blockheaded guy, I tend to like the ’skills’ stuff a lot more than the ‘theory’ stuff, but I realize that they’re both an important part of the education.

A number of courses are simply meant to help develop peripheral-but-also important theories and skills. As a Computing Science major, taking a course on English or History won’t help you one whit on paper- but you develop important critical thinking and communication skills. Just reading and regurgitating blocks of text on a regular basis will make you a better reader and writer. Kristen, for example, has grown immensely on account of her Criminology degree. The degree’s hours of research and reading and papers have honed her reading, comprehension, research, presentation, and writing skills to a fine point. Those skills don’t just translate to Criminology- they’re important in every profession.

There are, however, a few sinkholes in SFU’s ample course-structure. Courses which are noble-sounding on paper, but lose everything in translation.

Let’s take, for example, CMPT 275, “Software Engineering”. The course is a noble thought- how does one actually go about planning and producing a big software product?

The course, however, loses everything in translation. I’m not going to go too far into how- we’ve been talking about it for ages and ages.

I’ve also heard that under the more-competent eye of Toby Donaldson down in Surrey, the course is actually a lot better.

Maybe that’s a bad example- the course was a good idea after all, they just needed someone competent to pull it off.

Okay, let’s try CMPT 212, “Object Oriented Programming in C++”. This course has long been one of SFU CS’s legendary sinkholes- a random grad student is pulled out of a hat to throw malformed C++ and ancient GUI code at you until you cry like a little girl.

No, wait, Ted Kirkpatrick taught the course one semester and it was apparently quite well done.

Where am I going with this?

Well, as an SFU student, you are frequently called upon to choose between courses. A lot of older students will say “Avoid Course X”, or “Avoid Course Y”- and here’s what you should do: Ask what professor they took the course with. Now your job is to “Avoid Professor X” and “Avoid Professor Y”- and they might move from course to course, so you have to watch out for that. A good professor can take almost any course and make it worthwhile. A bad professor can take any course and make it punishing and pointless.

And avoid grad students (or “Sessionals”)- some of them are good, competent lecturers, but these specific grad students exist only as a theoretical mathematical construct. The one you get will not speak English.

As a postscript, though, some courses are just plain stupid. I’m lookin’ at you, Bridging On-Line.

If you’ve been following the news- and I don’t blame you if you haven’t- you might have noticed a recent cafuffle about some Canadian DMCA-something-something.

Here’s a quick summary: The Canadian government (the Conservatives, mostly) have just recently introduced a bill- a bill which poses as a “let’s fix Canadian Copyright law” sort of bill. Now, I’ll admit- Canadian Copyright law is broken six ways from Sunday- it’s even illegal to record TV shows on to a VHS tape- and this bill addresses some of those issues in a sort of backwards fashion.

It also, however, makes it illegal to contravent DRM- with a fine of up to $20,000 dollars for doing so. This makes it illegal to do any number of things- unlocking cel-phones, for example. With DRM protected by law, a lot more companies are prone to introduce it in Canada.

I’d like to briefly point out that We Do Not Want That.

It’s a lot more complex than just that- I’m trying to hyper-summarize, here, so I don’t get anything wrong. if you’re interested, 0the whole thing has been covered extensively by Micheal Geist, who is informally representing the opposition to the new laws. Even the Vancouver Sun covered the new bill last Friday.

One of the most important things that every programmer learns is that just about everything can be opened with in a text editor and fiddled with. In fact, opening a text editor and fiddling with things is basically what programming is.

Clearly, the text editor is the most important tool in the programmer’s tool kit, and just as clearly, Notepad shouldn’t be that tool.

Oh, don’t get me wrong- As a Windows user, Notepad is still pretty much my go-to editor for anything that’s.. well, a note. My whole computer is littered with little text files with names like “Things Ted Has Told Me To Watch” or “Bacons Of The World”.

But when it comes down to editing code, I likes me a good, general text editor with a lot of features. Code highlighting, code-folding, block-indenting, a decent search-and-replace, it’s all important stuff. Without code highlighting, I’m sure I’d make three times as many errors as I forget to notice that I’ve closed a string or commented out the wrong bits of a code block.

Note how I didn’t say IDE- Oh, I like IDEs, too, but an IDE is for programming in an environment. Visual Studio is for programming in /insert Microsoft Technology here/, Eclipse is for programming in /insert Sun technology here/, and you never want to jump beyond the bounds of their technology barriers.

For anything that you’re editing that’s not Java or .NET- and that’s a wide world- a nice, general purpose text editor is definitely a must-have. I’ve tried a couple, and here’s my thoughts on them.

You may not have heard of jEdit- most people haven’t. It’s been my go-to editor for some time, and I am quite fond of it- if anything because I’ve grown used to it’s quirks, ins, outs, etcetera.

It’s a Java-based text editor, using Java plugins to add functionality for just about everything. Of course, because all of the plugins are built in Java, most of them don’t actually work well or do anything.

The feature that got me on board more than anything was the dockable file browser. When I’m working on a project, I like being able to see all of my files from that project in the left-hand pane. Said dockable file browser can also be ham-handedly coaxed into working with FTP or SSH, both convenient bonuses for remote work.

My love of jEdit, however, is somewhat diluted by that same property that eventually had me migrating from Azureus to uTorrent- Java may be cross-platform, but it’s the same across all platforms: clunky, ugly, and hugemongous.

So, having recently purchased a computer from the fellows at 1 Infinite Loop, I decided, instead of embracing the way of the cross-platform Java editor, I’d try to see what Apple’s large fanbase has cooked up as a way of editing text on the Mac.

TextMate is *gasp* shareware. If you want the full package you have to pay for it. Now, I’ll support that- I use my Text Editor more often than I use Team Fortress 2, Microsoft Office, or toothpaste. I’m not really willing to pay for it until I’ve decided that it’s a must-have text editor for the Mac, though.

I am impressed by TextMate so far, however. Like unto jEdit, it has a variety of plugins (in this case, “bundles”) that can be used to extend the simple text editor into an IDE for every platform. The difference, however, is that TextMate comes with a whole schwack of good ones.

While it’s good, though, it hasn’t yet blinded me with science. (beep boop)

So, as a programmer, you’ve long heard that there are two and only two text editors: eMacs and vim. They are the ’shizzat’, the cream of the crop, the top of the heap, and they did it *myyyyyy waaaaaaay*.

So given the fanfare, I’ve tried both of them. Oh, I don’t use either- in fact, I find them both quite frustrating. I don’t want to poke any bears- but eMacs and vim are difficult to use, and a lot of their fantastically wonderful functionality have been replaced by a recent technological innovation- the mouse.

On the other hand- you should pick either emacs or vim and learn enough of it to navigate around. See, the thing is- if you’re doing work on a remote server, your choices are limited to emacs/vim or…

Pico, or Nano by another name, is the command-line equivalent of Notepad, except with even less features. There’s no ‘undo’, even. Honestly, pico/nano is quite possibly one of the worst text editors out there. I’m not ragging on pico/nano, here- they’re not meant to be big, beefy, powerful, serious text editors- they’re designed to be small and convenient, which they manage expertly.

So, recently, I attended a presentation by Will Wright- at the Vancouver Art Gallery. It’s part of the KRAZY! series that they’re doing right now, and as an employee of Electronic Arts, I managed to nab some time off to attend.

If you don’t know who Will Wright is, I’m not entirely sure why you’re reading my blog- perhaps you’re a family member? Will Wright is the thin, nerdy-looking fellow responsible for designing such games as SimCity, the Sims, and the critically acclaimed SimTower.

Okay, maybe that last one wasn’t his crowning achievement, but it was a pretty solid game.

Now, he’s working on Spore, a new game featuring.. uh.. well, it’s hard to describe, but it looks pretty sweet.

When he stood in front of the group, he said that given the small group, he’d rather have a Q&A session than deliver a presentation. Prompted for a question, we started with the following:

As an important caveat, every word of this is horribly mangled and paraphrased, by me.

It’s definitely harder now than when he started. Games have teams of over 100 people, and if you want to be on the creative side, you need to be able to effectively sell your ideas.

Given that, not every game has to be a gigantic $50-million effort- cel-phone games, indie games, online flash games, even Xbox Arcade games have a much lower barrier to entry than traditional console games.

A good way to work is with quick prototypes. He often uses targeted prototypes- no more than a week of work for a talented coder- to help him explore one aspect of gameplay. It also allows the team to go through little miniature production cycles- design, production, and testing, all within one week.

As a creative person trying to sell people on your ideas, it’s super-important to be able to program. If you have a lot of little prototypes, you can impress people and it gives you a grasp of what’s fun.

As an anecdote- originally, The Sims was a game about home architecture. It was more about designing a house than living in it. At some point, some engineers prototyped a group of people to wander about in the house, ‘judging’ how good the architecture was by living in it. It turns out, this group of people was a lot more fun to play with than the house itself.

It’s true, nobody’s willing to drop $30 million dollars on an unproven idea. Most of the innovation in the industry comes from small groups of students- 4 to 5 students from Digital Arts institutions or Digipen. (As an editorial note, a small group of Digipen students wrote “Narbacular Drop”, which became the basis for the fairly well-known game “Portal”)

With services like Xbox live out there, how do we get people back to paying 5 bucks for a game that a small group has put together- and how can we get back to a shareware model where people try a lot of inexpensive games?

In a lot of industries, the structure has a lot of apprentices working for years and years under a master. As a chairmaker, you’ll build a thousand chairs before you get to go through the process required to call yourself a master. The interesting thing is, though, that in fields like that, you’ll actually build a product hundreds of times before you learn any theory about it.

In the University model, you learn all of the theory before you build a single thing. You don’t get to learn from failure because so much of what you learn is designed to insulate you from failure.

Will Wright is not entirely sure whether this is good or bad- maybe good- you have less design-by-failure, and the system is producing a lot of great interns.

Part of this is to step away from the game and look at the franchise. We’re in the entertainment industry now more than the ‘game’ industry.

Imagine Grand Theft Auto 4 on a cel-phone- it wouldn’t be very good, would it. Once you treat a game more like a franchise than a specific game, you can start taking advantage of the individual qualities of each platform.

Imagine Spore as a musical- or a television show. There aren’t a lot of good science shows for adults, maybe the Spore franchise could fill that niche.

How would you make a Star Trek cel-phone game?

The metagame outside of a game is also rich with opportunity. See Lost as an example- a lot of additional content for the show was provided online.

Make a tonne of games.

If you’re not obsessed with the topic, don’t even bother.

Pick a topic- obsess about that topic. Read everything that you can get your hands on. Then try to find some way to share that topic with others.

Discuss it with everybody. You start to develop a really great pitch.

The fun part about the game is the mental model that the player develops- This starts when the game is first pitched to the player- the very first time they hear about it, they start developing a mental model of the game (”Butterfly Combat”), and if it sounds fun, they’ll be more likely to pick up the box and try to expand their mental model (”With realistic finishing moves”).

The game has to be fun on the box, and in the imagination, for people to buy it.

For Spore, at least 200 prototypes were created. About 20-30 of them actually ended up in the game.

Games often fail because there’s too much in them, as opposed to leaving too much out. If the makers of the game were to just polish one or two of the provided game mechanics instead of trying to nail them all, they’d probably do a lot better.

Playtesting is huge. People tend to fail visibily and usefully when they’re trying to play a game. It’s good to test with new people all of the time, too- people who have been playing the game for a while start to get used to the bits that are confusing and work around them.

In a series, you have to keep people who enjoyed the last game entertained without alienating new players. Think of the hardcore FPS market- it’s easy for an FPS player to pick up a new game, but it’s pretty closed off to new players.

SimCity 4 was super popular with hardcore SimCity players, but it had so many features that it was hard for most people to figure out what they were supposed to be doing with it.

A lot of what “fun” is is problem solving and challenge. Easy is boring, hard is frustrating, but just enough challenge is fun.

Dynamic Difficulty Adjustment is working to help address this- but players don’t always like it if the game seems to get easier or harder based on their performance.

Spore leans on player-created content and tries to learn from the way that you play.

Persistent worlds, like World of Warcraft, aren’t exactly the equivalent of social spaces like Facebook.

People are starting to see virtual landscapes or Facebook pages as part of the real world.

While World of Warcraft has expanded out of the single player experience to encompass all of your friends, Wii gaming has expanded to include a whole room of players, out from the screen.

Spore has an asynchronous form of collaboration- your world is populated by creatures and creations from other people’s games.

Think about goldfarming- online economies are interesting. It turns out, the hourly wage for playing World of Warcraft is equal to the average hourly wage of Bulgaria (unsourced, I suppose).

Will Wright never finished a degree- instead, he learned a bit of everything. He said that the biggest influence on his development was a Montessori school that he attended when he was younger.

The style of a Montessori school is that children learn more effectively through self-directed play than through rote memorization.

A computer with an internet connection, these days, is the equivalent of having the entire Library of Congress at your fingertips. The question becomes- how do we get people interested in all of this?

Think about emergence- the theory of complexity arising out of simplicity. An ant is a stupid little finite-state-machine, but an anthill is roughly as intelligent as a dog.

One thing to consider is that there are some things that computers do better, and some things that humans imagine better.

In the Sims, the Sims speak in Simlish- because the quality of procedurally generated speech is so low, people would get either bored or turned off with the things the Sims would say. With the Sims speaking Simlish, people can imagine what they’re saying- something that people are fantastic at.

It’s also important, in a simulation, to manage which strings the player can pull- and how much they affect the game. The player should be able to causally link actions and reactions.

SimEarth, for example- was a fantastic simulator- but it wasn’t a very good game. People would accidentally melt the entire planet and they wouldn’t know why.

In a lot of games, the failure states are more interesting than the successes. The things that people get interested in are not the successes but the interesting failures.

So, Curtis, what are you going to do as soon as you graduate from University?

Are you going to travel the world? Are you going to get a job? What are you going to do, Curtis?

I have a number of different plans, of course- all of the standards. I’d like to travel, I’d like to get a job and finally move out with my girlfriend, I’d like to start my own company, I’m sure you’ve heard it all.

But, here’s the thing- this may be my last opportunity to have a big block of free time. Nobody in the industry has the opportunity to just take 6 months off and do something interesting, do they? That’s right.

So, maybe I’ll just take a big chunk of time off. Nothing. For 6 months. That’s a long time, isn’t it? Nothing for 6 whole months. It almost seems painful to think of doing nothing for that long.

Well, the first month is a trip to Egypt with Kristen. There’s the adventure portion of the ride. What do I do for the other 5 months, aside from drive my parents absolutely bonkers?

This idea is still in it’s infancy, but it’s borne from a talk from Will Wright that I just recently went to (more on that later!). He had a specific anecdote- there was a pottery making class, he said, that split into two groups. One group was marked in terms of how nicely they could produce one single pot. The other group was marked in terms of how many pots they were able to produce over the course of the semester.

The interesting thing was that the quality of the pots produced by the second group was much higher than the quality of the pots produced by the first group. The process of doing things again and again allowed the group to develop a number of different ideas, learn what worked and what didn’t work, and in the end produce a high quality product.

As a segue, throughout University, I’ve had a number of ideas- little bits of software here and there that I’d love to write if I could only find the time. I’m great at writing software if I can dedicate a full 8-hour chunk of my day to producing something useful- but I just can’t get into development when it occurs in fits-and-starts.

Here’s the idea: I will produce one new project every week. One project per week, every week, design, development, and testing, for 5 months. Some of the projects will suck, or fail. Some of them might not. What goes into the projects will be the bare minimum feature set required to implement each project.

At the end, I hope to be a better coder, and maybe if I’m lucky, I’ll have a couple projects that are actually popular with people- projects that I could pursue further. It’s always easier to get coding when you have a codebase to work with.

Heck, it worked for Jonathan Coulton.

So, today, I was dealing with a nasty problem, and I discovered another potential use for Hashtables.

What I decided had to do was to populate a number of data-sets with long lists of data, and then query these sets again and again to determine if they contained a specific value.

My initial thought was a Binary Search Tree- you might be familiar with such a concept from the obligatory Data Structures class that you’ve taken at some point or another in University.

I couldn’t, however, find a Binary Search Tree in the .NET libraries.

Now, this irritates me to no end- I believe that there are a number of things that programmers do all of the time- sorting, dealing with sets of data, the like- and that these operations should not have to be re-implemented every time.

A clever company will have a common library with all of this sort of thing in it, but a clever framework should, too.

On top of that, I tend to always trust that someone else’s implementation of foo is more intelligent than my implementation of foo, and more standard, as well.

I’m sure, however, that .NET has these things- it’s huge, remember. I’m just not sure where to find them.

I’m getting off-topic, though.

I had a quick chat with the internet, again, and they suggested that I use a simple Hashtable for the process that I had just described.

Yeah, I guess that would work fine, too.

If you wish to destroy America, I urge you to consider the following targets:

The executive team responsible for Beverly Hills Chihuahua, and any team members involved in it’s production who failed to summarly quit or throw themselves off of a bridge in horror.

The Guy From The Guitar Hero ‘On Tour’ Promo, and any game that once emphasized the sheer badassitude of rock that is now rated E for Everyone.

Micheal Ian Black. He knows what he did.

Microsoft, for introducing Windows Vista, and failing to ‘get the point’ for their next offering.

And finally: Cheez-Whiz. They’ve had it too easy for too long. Somebody has to do something.

So, for a lot of the last class in CMPT 470, our professor has been delivering an assortment of HTTP-related lessons.

This is actually proving to be mighty interesting- Apache and basic HTTP have a lot of features that I never knew they had.

It’s also managing to be pretty interesting- because the REST web-service architecture is so closely tied to HTTP, all of the stuff we’re learning almost directly applies to some architecturing I’m doing at work.

SOAP is a XML-based “Simple Object Access Protocol” often used for Remote Procedure Calls- SOAP messages are sent as XML data and responses are recieved as XML data.

WSDL is an XML-based “Web Service Definition Language” which tells clients what the server offers- This means that a clever client can look at the WSDL and automatically provide an API to work with the SOAP-server- which is exactly what .NET does.

SOAP and WSDL ‘piggyback’ on HTTP, but can be used with other data transfer protocols (even SMTP!)

You all remember that I bought a MacBook, right?

So, I find myself doing web development, and wondering how to do all of the Linuxy stuff I love without abandoning this Macintosh paradigm that I’ve grown to enjoy so much in the past few weeks.

Some people- bearded, angry people- might suggest that all platforms are equivalently useful for web development, but I’m a big fan of convenience- and the ability to apt-get things I want is just too useful. Dependency-management by hand is for schmucks and Windows users.

Fortunately, IRC came to the rescue once again, and suggested sshfs. Investigations proved fruitful.

I’m using VMWare Fusion to run Ubuntu 8.04 Server Edition within the Macbook.

VMWare Fusion makes it almost painfully easy to install an operating system within the Mac. Download the Ubuntu ISO. In VMWare Fusion, add a virtual machine, select ‘Linux’ and a few inconsequential configuration options.

Ubuntu 64bit or 32bit both work fine. VMWare Fusion can handle either.

When prompted for the CD, instead “Browse” for the Ubuntu ISO that you originally downloaded.

Then you just run through the standard Ubuntu installation. No problem.

The Server edition of Ubuntu comes with SSH already installed. Should you find yourself without it (maybe you’re using the Desktop edition?), just run sudo apt-get install openssh-server and sudo apt-get install openssh-client. Everything will configure-itself for you.

At some point, you might need the local IP of your Ubuntu server- ifconfig will produce the information you’re looking for.

Now, we want to mount the virtual Ubuntu filesystem like it was a local filesystem within the Mac. Install MacFuse, then MacFusion. It’s as easy to install as everything traditionally is on a Mac. (It has clicking AND dragging.)

The MacFusion program will appear in the toolbar. Click on it, select ‘easy mount’, followed by ‘SSH’, and give it that IP address that you pulled out of your Macbuntu earlier.

The name and password are the ones that you initialized the system with. Like magic, this will grant you access to your Ubuntu filesystem from within the Mac. Glorious! But, of course, it’s only good for file editing.

If you don’t already know how to use the Mac’s built-in SSH functionality, shame on you. Find and open the ‘Terminal’ program, and type in SSH your_ip_address -l your_username

Figuring out what to do with the Ubuntu terminal is beyond the scope of this article- all you need to know is that every system administration task you need to perform can be done from the command line, and if you weren’t such a dyed-in-the-wool noob, you’d be able to do text editing from within the command line too. (Don’t worry- I prefer graphical text editors, too.)

VIGS Summary

The Vancouver International Game Summit began with a visit from two B.C. political types (Larry Campbell and something something)- one of whom delivered a moderately rousing speech about how B.C. supports it’s game developers, and the other of whom briefly said something about ‘game something something’ and then launched into a diatribe about how he was committed to lowering the cost of living in Vancouver.

Shane Kim, corporate Vice President for Microsoft Game Studios, sat in a rich-and-quiet Microsoft sort of way while a journalist completely failed to get any interesting comments out of him.

He somehow claimed that Xbox Live has a lot of features for non-subscribers- which I took a bit of offense to, because I’m pretty sure that you need to subscribe to *play games with your friends* - and what other cool features are there?

Bungie is mentioned- Microsoft (of course) wants to continue a healthy business relationship with them. Xbox Live might do full digital distribution someday but they’re not going to commit to anything, and Xbox Live Arcade is the bees knees for small game companies. Nothing on a motion sensing controller, or Blu-Ray.

Mr. Kim said “milestones” a lot and “paradigm” at least once, earning him my eternal enmity.

In the first session, I was offered the choice of learning about ‘untapped markets’, ‘new frontiers in animation’, or ‘the story and focus narrative’. I ended up choosing the third of the set- I wouldn’t be writing this in the first place if I wasn’t interested in writing, ya? It was a panel of three writers.

The first thing established by the board of writers was that players don’t listen to dialogue, or read dialogue. They just skip through it as quickly as possible to get their next quest.

A lot of times, as well, the story created in the character’s head overrides the story provided by the game.

In order to get a story across to these people, you have to aggressively simplify it and hit them with it over and over again. For the more involved players, additional storyline bits can be left optionally throughout the storyline.

Players also frequently save and quit, and come back to the game again later- so the story’s narrative has to be redundant in many places to remind people what’s happened and what they should be doing next.

A game comes with a predefined story and a large set of constraints to work with- be it limited characters and animations, limited props, and limited quests. A lot of game writers have had to work around the fact that the world is completely littered with crates, or that 95% of the quests are ‘get me 22 rat’s tails’.

With the vast amount of NPC’s that you meet in many games, it’s good to give them distinctive traits- speech patterns, quirks in appearance, little stories.

It can have emotional clout to make the player do something in the game that the character would do- but the player wouldn’t.

In KOTOR, most of the people took the good path, a smaller group of people started down the evil path, couldn’t take it, and then went down the good path, and a much smaller group of people went all of the way down the evil path.

One writer said that in games with creative directors, elements like art and writing seemed to gel better.

The Hero’s Journey is alluded to as a common structure for game narrative.

Some writing exercises are discussed: What’s the worst thing that could happen to a character? What’s the worst day for a character?

Then, lunch.

The next presentation was on the technology track. Three panelists talking about the difficulties they’ve had working with the PS3.

While theoretically the talk was about developing software for the Xbox 360 and PS3, apparently the gap in functionality between the two is so aggressively weighted towards the Xbox that the real problem was getting developers to work with the PS3.

The companies all had different approaches. EA had a deep layer of abstraction allowing the games to take advantage of the power of both systems.

Propaganda Games did a lot of work with middleware to produce a solution that ended up working on both platforms- mostly, working around the many deficiencies of the PS2.

Also, Propaganda Games reminded us that the one and only game that they’ve produced has been Turok.

In the questioning period, the panelists all drove home the point that developers should get things working on the PS3 first- because it’s the more difficult system, and then getting it to work on the Xbox 360 will be less troublesome.

Scott Greig, the senior architect from BioWare, delivered one of the best presentations of the conference- his information was organized, fast-paced, and structured.

I have pages and pages of notes that may not translate the best into a blog post, but let’s try anyways.

A technology roadmap is a strategic, ongoing planning tool for everyone in the company. Content-creators (animators, artists, writers..) need to know what sort of capabilities they’ll have available in the games and when.

The technology roadmap is a plan for what capabilities are needed, when they’re needed, and how to deliver them.

As a couple of general rules:

The process discussed was one to determine what the company’s focus is (in Bioware’s case, storytelling), what capabilities are needed to support that focus (in Bioware’s case, some capabilities include systems to deal with massive amounts of dialogue and create dozens or thousands of unique character models), then plan for how to deliver these capabilites- who will do the work, when can it be done, etcetera.

A lot of little tips were thrown in for each step of the way- but looking back at them they seem almost too disjointed to write down.

A talk about leadership. If you’ve ever heard leaders talk about ‘what is leadership’, you understand quite exactly how boring this talk started out.

After that, the discussion turned to women in the video game industry- mainly, the lack thereof.

I can’t believe that people managed to talk about it for a full hour.

My thoughts on the matter? Western culture drives women away from math, science, and engineering. The only solution is to not do that so much. I know if *I* have daughters, they’re getting the full nerd treatment.

The Lo-Fi Prototyping panel was pretty slow. It was a panel discussion, but not a planned panel discussion, so there pacing was pretty slow. The panelists talked about how getting any prototype of a game running is a fantastic way to tweak the game for gameplay elements.

It was pretty slow, and in the next room some big audio started to play. I really had to investigate.

When I first came into the audio production room, they were talking about how to make music more interactive. I immediately spaced out and started thinking about how I would implement an interactive music system- first of all, I thought about how to deal with prerecorded music- mix a variety of intensity values of the same song, with filters to increase and decrease intensity, and prepare transitions between states. The intensity could then be tied to in-game variables. It would, of course, be incredibly time-consuming.

Then I thought of dynamically generating the score based on a ’seed’ score and a variety of variables- and that would be less ‘time consuming’ but far more difficult.

So, watching the presentation, the Halo team at Bungie used a dynamically generated score - and they presented a gameplay clip from Halo 3 that was amazing. The music flowed responsively with the game, and wasn’t even interrupted by a cut-scene.

Another presenter had worked on the Def Jam games had tried the first technique that I had thought of - the table based one. (Clearly, the game industry is several years ahead of me). It wasn’t quite as seamless as the Halo offering, but it was still pretty good.

A Lucasarts guy mumbled his way through a boring demo, perked up by the occasional grandiose bouts of John-Williams-esque fully orchestrated music.

We started with Athomas Goldberg, from EA Canada, describing EA’s ANT framework- which is developed by EA’s central tech, used in a variety of games, managed by a central team, and contributed-to by many different EA teams and groups.

The ANT system is very plugin-based- with plugins to work with inverse kinematics, foot-plant management, locomotion control, etcetera…

The project was described as being ‘internal open-source’, which kinda yanked the short-hairs of my internal free-software pedant.

We then saw a short demo of some plug-ins on a NBA player.

Wayne Gilbert from EA showed us a movie of some skaters skating in mocap, and complained about how game animation isn’t held to the same high standard as traditional animation.

Mr. Gilbert works with the Skate team and seems to be a heavy advocate of quality over quantity- something I wouldn’t usually expect from EA. He is on the Skate team, though- maybe I should give that game a try…

Brad Kinley from Bioware, working on Mass Effect 2, talked about the animation tree used to generate most of the animations in the game. The whole ‘animation tree’ concept went a bit over my head- he showed us the tree, but I had little to no clue how that tree would translate into in-game animations.

Apparently, Mass Effect’s character animation framework was so heavyweight that only a few characters could be reliably animated at the same time- limiting the amount of on-screen characters that they were prepared to show. Mass Effect 2’s trees will be streamlined to allow for a lot more simultaneous animations.

In order to deal with the massive amount of dialogue in a Bioware game, Brad Kinley went over the process by which conversations were automatically generated by the system- with lip-synch automatically generated and paired with body gestures and motions. It still looked pretty wooden, but as 100% procedurally generated dialogue goes, it was some of the best I’ve seen. (”Bronze animations”)

For most scenes, they took the procedurally generated dialogue and layered emotions and additional gestures on top of that. (”Silver animations”) - this might take a couple of days per scene.

For important scenes, they went much more closely into camera control, emotions, and available animations. These could take as much as a week to get right- “Gold animations”

Christian Gyrling from Naughty Dog’s Uncharted: Drake’s Fortune described their animation framework- a multi-layered abstraction that’s not too complex- the animation itself is an object that handles requests for things like ‘running’ or ’shooting’ and manages state. The amount of programmatically generated content is very slim- all of the animation is lovingly hand-crafted from motion capture, and then animations are additively blended (running + turning + shooting) to produce a variety of slick animations.

Past that was a finishing keynote which I missed out on in order to miss the rush home.

This is the third time this year (gasp) that I’ve eaten Hyatt banquet food, and it’s proven to be a less-than-pleasant experience once again- theoretically, it’s fancy food, but it’s got this greasy, disappointing feel to it every time. Blah.

Okay, gradually, I’m determining that the codebase that I’m working on isn’t so bad.

At first I thought it was ugly and cryptic- a hacked-together mess. I reserved judgement- complaining about other people’s code on your first day is unprofessional at best- and it might actually be laid out in a sensible fashion that I’m just not grasping. All coders innately hate unfamiliar code, so I try to give things more of a chance.

And I discovered that this codebase, it’s a hacked-together mess. But it’s that doesn’t have a lot of bugs, maintains a lot of internal consistency, and uses functions and classes in a reasonable fashion.

Compare this with the PHP App that I was handed at Research in Motion to maintain- an amateurish set of ’scripts’, only loosely connected- and this system seems downright pleasant. Sure there are a lot of ugly decisions, sure there are messy hacks and a lot of things are structurally wrong- but it’s all wrong in a consistent way, so once you understand why it’s wrong you can adopt it’s messy hacks and bad structuring yourself and make it work.

The worst part is that I’m trying to be subtly wrong in the same way as the last coder, because the internal consistency of the bad architecture is a strong point of the system, and if I were to rebuild a single file or class to make more sense, I’d be compromising a major feature of the system.

So.. this is good, or bad? I don’t know. I’m at least having some fun with it. Maybe if I’m lucky I’ll get to architecture something from scratch.

This post is going to be full of pretty ugly technical stuff, methinks.

I’m going to discuss one of my favourite programming language constructs, the mighty hashtable.

Let’s start with a little code snippet to illustrate what I’m talking about. (I hope I remembered to include a .code class in my stylesheet, but if I haven’t, it’ll be around later today to provide monospacing and special effects and whatnot.)

Just about every language has something that passes for a decent hashtable- C# has the Hashtable object, Python has the Dictionary, PHP has a sort of multi-purpose list object that can store objects hashtable style in a “associative list”.

The basic meaning of the whole thing is that, instead of using numbers as array indices, you can use anything you want, so long as it can be hashed. Some languages restrict you to strings, but that’s pretty much all you need, most of the time.

There are lots of ways to implement a Hashtable- I built one in CMPT 379 using a chained-linked-list- but you should almost never have to, as all modern languages provide one for you. The only reason to know the details are if you want to start fiddling around with the implementation for optimization purposes.

Okay, enough jibba-jabba about what Hashtables are- what are they good for?

Well, a lot of things. They’re a general problem-solving tool, a-la regular expressions, that tend to come in handy quite often.

You can use them as a lazy/quick replacement for a struct, although you probably shouldn’t. (Sometimes I do, but then I feel bad about it later- it’s a bit junk-foody)

Really, any time that you have data that would be better indexed by strings than integers, a hashtable is a good way to store it.

A good example is Environment Variables- they tend to come in big batches. You’ll often get them in a string like this: "PATH='/eat/my/ass';NUMBER_OF_BOOTIES=9;QUIDGETS='jambipoop'"

Now, a lot of people will just separate that into an array of strings via “;”, containing pairs of ‘equals’ separated values- "PATH='/eat/my/ass'" - and that’s a perfectly valid way to go about things. But it’s only marginally more work to parse the set into a hashtable, and then you can do this:

In my search for some decent source of Asp.net documentation, I never tried a simple Google search.

I found a website called, appropriately enough, asp.net with reading material, tutorials, the works.

A little bit of sleep and I feel much better.

Today I’ve been learning about ASP.NET all day- I finally found a good reference online (Programming ASP.NET 3rd Ed., O’Reilly) which significantly improved my mood, and I’ve committed to learning it- which could take a couple of days to get a bit of a grasp on, and a bit of hacking to really get a handle on.

I managed to find where they post the cafeteria menus online.

Interruptions are frequent around the desk- conversations, and food, and meetings- but I’m making forward progress.

And, at the end of the day, they rolled a cart over filled with ice cold, expensive beers- Heineken, Guinness, Stella, all sorts of different alcohol variations, a few soft drinks, and a veritable plethora of snacks that I’ve barely touched for fear of ruining my dinner with Kristen.

I’m frustrated all to hell today. It seems like everything has gone wrong at every turn.

I wrote a great big blog post detailing every shitty little thing that’s happened to me today, but the grand point of it all is that my day has been full of a whole boatload of minor annoyances that normally wouldn’t bother me too much at all, except to contribute to a general feeling of irritation.

But when one thing really pisses you off, all of the rest of those things go from minor annoyances to great-big-fucking-deals, and by the end of the day you just want to shriek and pull on your hair and cry and punch stuff and generally throw a queen mother of a hissy fit.

Of course, if you’re over the age of 12, you probably don’t, but inside your head that’s exactly what’s going on.

The thing that’s been pissing me off has been ASP.NET. I’ve been recently exposed to it- and as a nebulous concept that I don’t have to expressly deal with, it’s not bad. As something that I actually have to work with, though, it’s generating a great deal of deep personal not-happy. ASP.NET is Microsoft’s answer to Java’s JSP technology- as if there weren’t enough bloated, weighty structure-heavy ways to try to do web programming while steadfastly trying to avoid dealing with a web-server or actual HTML code.

I was hoping that- being web programming- my LAMP proficiency would make this a much easier and faster technology to get a grasp on. What would have been a better intro, I think, would be if I had instead spent far too much time working with Java’s excessive class hierarchies or Microsoft’s idiosyncratic CLR.

But with this albatross hanging over my shoulders - the combination of stress because I don’t know how things work, the frantic feeling of being under the gun (because I need to learn this, and yesterday), and the innate anger at having to deal with big clumsy Java clones instead of small, modular FOSS technologies - this has made me less patient with every other element of my workspace.

A co-worker joking around with me (”Oh, yeah, co-ops don’t do any work in the first few days”, “We need to get you working harder.”) goes from an annoyance to a mortal insult- I want to yell at him. I’m busting my balls, here.

Little annoyances pile up- there’s no menu in the cafeteria, just Powerpoint presentations that are incomplete, so I have no way of knowing what I can order or what half of the items on display are (or how much they cost.).

The Library is surprisingly tiny and has maybe 4 ASP.NET books, none of them any good, even though ASP.NET is the de-facto web programming framework for most of the company.

I can’t listen to music in my cubicle because my headphones won’t reach the back of my computer. Nobody seems to be listening to music around here, even though the working space is small enough that a little sound-induced privacy would be a godsend. Maybe it’s because the process for listening to music at your desk can be quite technically involved- you need at the minimum to hunt down a headphone extender, then buy and burn a DVD full of mp3’s and keep it in your computer at all times because having mp3 files on your hard drive is strictly forbidden.

The cubicle space is small. Two cubicles are shared by 4 people, working in a square with an employee at each corner. With 4 people in a cubicle, you feel guilty whenever you leave your desk or don’t look busy. All of the fancy perks in the world don’t matter if you don’t feel comfortable leaving your desk long enough to actually use them. There’s always noise about, lots of noise. Like always, managers are in private offices, so the people who need to concentrate and relax and think clearly are in the centre of things surrounded by others, while the people who need to communicate constantly and keep on the pulse of things are sequestered away in private offices.

Your teammates are happy to answer your questions, but they’re also super busy, so you feel guilty interrupting them and I can’t get my printer working because the network permissions are set up wrong, so I’m going to have to wrangle with IT and I have a long commute so I can’t stay late and I’ll be home late anyways and AAARGGGGHHH.

I can see some of the reasons why people think of EA as a grind. I bet if I sleep for a half-decent amount of time, though, I’ll feel a lot better. I also get to see Kristen tomorrow, so that’s a bonus.

So, today was my first day of actual ‘work’.

I forgot my security badge and cel-phone at home- not exactly a great start. I went to sleep at a slightly more reasonable time, securing almost a full 8 hours of sleep, but that just seemed to make me more tired. I’ve been exhausted all week. I’d love to get more sleep tonight, but it’s already almost 11:00 (the 8-hour mark) and if I want clean clothes to change into tomorrow, I’m going to have to baby this laundry load until at least 11:15.

Getting my schedule running properly is going to be tough. 9 hours at work (assuming a 1 hour lunch) + 3 hours of transit + 8 hours of sleep leaves only 4 hours of leeway, which isn’t a whole lot of time for things like .. well, food and such.

So, after getting a temp badge, I met my team for the first time. There’s Joshua, who seems to have a great deal of knowledge on every conceivable topic, Graham, who seems like the ponytail-wearing grizzled old code hero (I’d say he’s maybe in his early thirties, which is old by software dev. standards). If you can imagine what Dan will be like in another 6 or 7 years, this is it. Then there’s a third guy. His name slips my mind. It’s a good name, though.

First things first, I got the intro speech. “So, you might be disappointed, but we don’t actually work on games here. We do /*configuration management blah blah blah*/”

I had to at some point interject that I was not, in fact, disappointed by this- I chose the ORCA team specifically because I was interested in /*configuration management blah blah*/. This seemed like a pleasant surprise for Joshua, who clearly had disappointed a couple of co-ops in his day.

He gave me a few resources to peruse over the course of the day, and I sunk in. I had a bit of setting up to do- two monitors, but they were configured backwards, and the Start Menu wasn’t where I wanted it to be. I bookmarked some of my Firefox favourites and set up an odd program or two- then delved into documentation.

Then came lunch. There was a suitable amount of bitching about the old co-op. It seems like once again, I’m replacing someone who wasn’t very gung-ho about his job. Just like at RIM. Apparently, some co-ops are so disappointed about being placed on a Tools team that they just fold up and stop caring entirely.

On top of that, he didn’t like seafood.

This is good for me, of course- as always, the low expectations set by the flaky last guy will change how the team thinks of me- and I’m a pretty chipper, gung-ho, get-things-done type of guy.

Honestly, the game guys are probably debugging C++ code in almost-complete-games all summer, and that sounds to me like a very flavour-packed layer of hell anyways. I get excited about Perforce and Buildforge and that sort of thing.

After lunch was a meeting. My manager was in-and-out, and she’s off doing some presentations or something for a few weeks- I guess I’m directly reporting to Joshua for now. They did some questions around the table about what to call the team- the whole department is going with “Works” in the title- Artworks, Techworks, and we’re… not sure, yet. I suggested “Skunkworks” and one girl went “Eeew”- perhaps she didn’t know the long and illustrious history behind the name.

I was introduced as “The Co-Op”, which is my role. I tried to play up as much as possible that I know how generally useless and temporary I am, with a smile.

Later, I drew Asok on my whiteboard, with a list of my various skills. (”Portable!”)

At the end of the day, I had a list of some questions, got them answered, wrote them down, and took off (early) for Harbour Centre, where I’m taking CMPT 470 with Greg Baker.

Oh woe is me, there will be no sleep this semester.

I didn’t budget enough time to get there, I think, and arrived 15 minutes late. It wasn’t too consequential, though- he was describing course preliminary stuff- where the marks are coming from, what the assignments are going to be, administrative mumbo jumbo

Then, after that, he went into an intro to web development, which included a big chunk of information on the topic of Valid Markup- which, I have to say, I already know pretty well. It was slow, and I spent most of the class sketching out ideas for the project that I’ll be working on with Ryan and Sepand.

I was actually quite impressed with Greg’s lecture. He didn’t use Powerpoint, he spoke clearly, confidently, and charismatically, and he used lots of examples. I’ve known him for a while and I’ve never actually heard him lecture- so.. huzzah.

I’m just hoping there’s something I can learn from the class- I’ve already worked as a web ‘professional’ (and I say that in big quotes because it was on intranet-only software) and while I certainly appreciate a class where I can just use existing expertise to whop together an A, learning a few things here and there can be nice too. Given the solid coverage that he gave XHTML, though, I’m sure I’ll pick up some best practices that I didn’t know about before.

After class, I took the Skytrain home with Sepand and Ryan to start discussing our project. I immediately decided I’d nab ‘team lead’ because I have the most experience with websy stuff, and because I’m an egomaniac. I asked if anybody had any ideas, and we all started tossing some things out. I suggested we prepare one-page briefs for our ideas and toss them in a pot next week to sort and decide on one.

After that, we started describing all of our various ideas- Sepand thought of a system for farmers to hook up their wares with local restaurants and stores.. which was a good idea, but I thought it might be tough to find test users. Sepand also thought of a system for online code reviews, which poses an interesting challenge and could be a good project.

I tossed out a few things- a better WebCT (and by better, I mean ‘a whole lot less features, a whole lot more not sucking’), a system for managing and swapping online-game-account-credentials (like Wii Friend Codes, XBox Gamertags, Steam accounts, blah blah blah), and a tree-shaped Wiki for smaller, more focused/organized bits of documentation.

So far, I think the most popular idea’s been the system for managing online game-account credentials. We might do away with the briefs entirely and just start brainstorming features for that. The only problem we saw was that it wasn’t complex enough to be interesting, but in the skytrain ride alone we thought of at least a couple of inherent problems that might require a little bit of noodle-scratchin’ . On top of that, we could put together a Facebook plugin for the whole tool.

Sounds neat. I seriously need to go finish that laundry and get to sleep, though. Night all!

So, being as I’m new to EA, and I keep having little epiphanies that aren’t ‘confidential’ but certainly require sharing with the world, I’ve set up a Twitter account.

Also, that gives me the fun of eventually integrating the little Twitterbits into my blog.

Today was my second day at Electronic Arts- today was the Software Engineering training.

First off was a few hours working with source control. At RIM, I would have *killed* for a few hours working with source control, but here it was a bit boring because I’ve already learned how to use it.

Our host for the day was a question-asker. You know the type- he asks a question (”Does anybody know one thing that the art team produces?”) and then proceeds to discard all valid answers (”art?”) until the crowd either manages to hit upon that one highly obscure word or phrase that he’s looking for (”assets?”), or until he’s been waiting for a good 10 minutes and nobody’s managed to hit upon the answer yet. This manages to fill time, make the presentation feel more interactive, and make everyone in the crowd wish for a swift death.

Lunch was okay- we were ‘freed’ for an hour around noon, so I had time to venture up to the cafeteria- which was packed to the gills. I suppose everybody feels a little lunchy around noonish. I nabbed a table and ate some garlic-sausage and cheese sandwiches I had prepared.

The trick to EA, I think, is to buy breakfast (which seems cheap and fillin’), sometimes lunch (reasonably priced), and forego drinks (too expensive). Being as I haven’t yet found any water coolers, I might need to organize something on my own. Of course, the water coolers are probably deep within cubicle country.

After lunch, a long presentation about general software development practices, EA software development policies, etcetera. At one point during the orientation, we were introduced to the old-fashioned trifecta of software development- high quality, on time, under budget. (Choose two) Our host asked us which one of those things must never be allowed to slip, and we all answered with the most obvious (at least to software craftsmen)- high quality. I’ll leave it to you to determine which one EA chose.

While I understand that the only companies that are truly unflinching about quality are Valve and Blizzard- at the expense of running massively overbudget and producing games that are frequently months or years late- it still surprised me a little. Blockbuster games like that are enormous financial risks- they cost millions to develop, may or may not and up being popular. The quality-first policy may have lead to Portal and Starcraft, but it’s also lead to Daikatana and Duke Nukem Forever. We all know that the bottom line is king, but we’re at least aware of the common pretension that quality is the number one priority. Really, with EA, it’s been clear since day one- we’re not here to produce the best games in the world, we’re here to produce truly embarassing amounts of money for executives and company shareholders, and in exchange, we get a decent wage, job security, and a variety of nice perks. I guess that’s a way to look at things. It certainly puts a damper on the ol’ motivation, though- the person I’m most interested in producing staggering amounts of money for is me.

My motivation isn’t so much the feeling of a job well done, but the EA Knowledge Repository, a great big resource containing just about everything they’ve written down about a variety of topics. I’m hitting that like a fat kid hits cupcakes.

Our last part of the day was dropping us into some C++. Here’s a chunk of code that’s broken- please debug it. First, it wouldn’t compile, and then secondly, it had a number of runtime errors.

This was a bit like jumping directly in to cold water. It wasn’t really C++, more straight-up C- and the last time I even touched code like that was over a year ago, when I was working on a Compiler for Shermer’s 307 course. Since then, it’s been high-level programming languages all the way- PHP, Python, and Lisp. Here I am, debugging a C++ program? It’s certainly a kick to the junk.

I was still refamiliarizing myself with C++ when just about everybody else in the class had already fixed the various build errors. We had an hour, and nobody fixed the program before the time was up- although a clever fellow next to me managed to finish about 10 minutes afterwards. I had made a bit of a dent, clearing up the most obvious errors and starting to dig into a deeper understanding of the program in general- but left to my own devices, the error probably would have eluded me for at least a day as I painstakingly went over each function in the code trying to more completely understand why the whole thing seemed to be failing from what was essentially a great big logic error- or maybe littering the whole thing with printf statements in hopes of catching the error (like one would catch a rabbit).

“But why not use the debugger?” - Ah, well, while I can use the Visual Studio debugger at least at it’s most rudimentary, I’ve never found a good description of how to effectively debug with it. No tutorials, no TFM to R, no nothin’. In fact, I’ve found documentation & tutorials for the Visual Studio IDE itself pretty lacking as long as I’ve used it- maybe I’m missing something?

The whole time, I couldn’t help but think that I could reduplicate the entire codebase in Python or PHP, bug-free, in 5-10 lines of code (read a file, line by line, into a hash table, then search through it) in less time that it would have taken to debug. Of course, Python is entirely inappropriate for video game design, but it still gruffed my boxes a little bit- one of the reasons I love high-level programming languages so much is because I never have to deal with pointer allocation, memory management, or, worst of all, debugging those things.

It’s also been made quite clear that this (while not exactly the same) is at least similar to what all of the other software devs are going to be doing for the next few months. Lots of popular franchises relaunching soon means lots of bugs to fix. I’m really, *really* glad that this is not my job description for the next few months. I don’t want to suggest that endlessly fixing bugs is ‘below me’- I’m certainly an inexperienced developer, just the type to get doing trenchwork like that- but it sounds like a pretty dull time.

Well, if my job calls for it, I can speak the C++ lingo too- albeit a bit reluctantly- but I hope I don’t have to. Even C# would be a big step up.

For those of you who haven’t heard, I’m working at Electronic Arts this semester.

Yes, I’ve heard the rumours.

The first day was almost a parallel experience to the first day at Research in Motion. Sit in a big room, have people talk at you. Everything that RIM did for it’s employees, though, EA has done either bigger or better- at least so far.

I’m under a pretty stringent NDA, so I’m keeping quiet about specific details. Fortunately, I don’t really have any, anyways- except boring contract stuff, and you wouldn’t want to see that anyways.

We started with a Development Designer or Project Development Developer or Captain Develeperino or whatever his title was. He went through the standard “Oh me, I’m so fine, I’m so fine I blow my mind hey me” executive self-jerkery, and then quickly gave all of us a quick overview of the development cycle for games, described with the sort of gushing effluence of a man who’s clearly been championing the process for some time. He defended it as a way to control costs more effectively- surely the way to win a developer’s heart. Nothing gets me soggy in the pants like hearing about how I can help somebody else make a tonne of money.

Lunch was a generic sandwich-triangle-buffet fare- but I was actually surprised at the quality of the sandwiches. With obscure ingredients like ‘horseradish’ and ‘jalapenos’, clearly at least a little bit of love and care went into these sammitches. There were also devilled eggs and little cookies, and smoked salmon.

After lunch, the security and signing of forms. classam, 05/05/08. classam, 05/05/08. classam, 05/05/08. After reading the assorted contracts, I no longer have any legal rights as a human being, and should EA want to clone my DNA to produce a human clone of me to perform as a slave, I’m sure they could.

Then the EA tour. EA has facilities like Italy has pasta- all over the place, and guarded by stout Italian women. That simile might need some work. The numerous sports-courts are impressive, but none of my chubby, lazy business. At best I’ll use the nice little gym a couple of times per week. At best.

No, I’m an arcade man.

The most interesting EA service would be EA University- a variety of courses from prominent EA techies, artists, and producers about technology, art, and production. If I can clear it with my manager, I’m taking everything in the EAU pantheon that’s available during the summer. That and my CMPT 470 course should keep me busy this semester.

Finally, the co-op advisor giving us the old fashioned “How to be successful in your co-op” talk. I think I’ve heard ‘you get out of it what you put in to it’ quite a few times by now.

Then, IT policy, which can be summarized as follows: “No.”

Just getting some decent jams to listen to while at work is going to be a significant production involving at least three people, a trained acrobat, and a heist of epic proportions. (Or maybe just a write-only DVD, we’ll see.)

Shawn Jansepar was there, too. He seemed a lot more excited about the whole process than I was- perhaps because it was his first time with corporate shenanigans like this.

I have prepared a soup that I shall name “Curaga”, because it contains every folk remedy I can think of- hopefully to see me free of this cold by tomorrow afternoon.

Chicken broth, simmered with a head of garlic, a baggie of barbequed chicken from the supermarket, a spoonful of powdered ginger, a very, very spicy dried pepper, chili sesame oil, bean sprouts, soy sauce, green onions, celery, and every other spare vegetable found in the fridge.

It’s good, but really spicy. I underestimated that tiny, bright orange, dried chile pepper. For once, though, I actually WANT to clear out my sinuses. Also, a bulb of garlic that’s been simmered in chicken broth for about 30 minutes is soft and really, really delicious.

Of course, I’m accompanying this with mankind’s *second* oldest cold remedy, NyQuil.

First Impressions: “Whee heeee!”

For every Nintendo system released after the Nintendo Entertainment System, there’s been an accompanying Mario Kart game. Super Nintendo had Mario Kart- a spectacular racer at the time, but technically very difficult. The Nintendo 64 had Mario Kart 64, a much easier game that put the emphasis more firmly on smacking the bejeesus out of your opponents with items, which managed to make the game even more fun than before. Mario Kart 64 also introduced the power-slide-heavy game mechanics which have become a cornerstone of the series since.

The Game Boy Advance had a pretty spot-on recreation of the original Mario Kart.

With the GameCube came Mario Kart Double Dash, a game that concentrated so firmly on beating the ever-loving snot out of your opponents that you could actually get an entire person dedicated to that task on one controller. The GameCube also introduced a couple of series standbys that have become synonymous with the series, popular or not. Blue sparks and the dreaded blue shell, to name a few.

Mario Kart DS ended up being a fantastic balance between all of the elements we had seen so far- there was just the right amount of racing, just the right amount of ‘beating other people up’, the multiplayer was tight and attractive, and everything was beautiful and perfect- at least as far as I’m concerned.

So, what do we get from Mario Kart Wii? Well, first of all, it’s the closest to Mario Kart DS in terms of gameplay- a balanced racing-and-fighting experience. It’s the most customizable of all of the series so far- racers can tweak a number of different variables in the races, from item type to the variant of karts that opponents will use.

Mario Kart Wii introduces the Wii Wheel. Don’t worry, though- you can still play with the good ol’ fashioned Gamecube controller if you’re looking for the traditional Mario Kart experience. Or the Classic controller. Or the Wiimote and Nunchuk. The controller feels tighter and delivers a more comfortable racing experience for those of us who are veterans to the series- but I’ve been forcing myself to use the Wheel, and it’s turning out to be a seriously satisfying experience. Okay, it’s not nearly as ‘tight’ as using the controller, but it’s just plain ol’ more fun. I only have the two wheels, so far.

I introduced my parents to the series- they’re not much further than Wii Sports when it comes to playing video games, but with the Wii Wheel on Time Trial mode they were able to pick up and enjoy racing almost immediately.

In Mario Kart Wii, you’re racing against 12 opponents instead of 8. This can make it a lot tougher to recover from a bad position- when you’re in 8th place, you’re not getting the super-powered items that will slingshot you back to the front- the people getting those items are right behind you. When you’re in 12th place, there’s almost nothing that’s going to shoot you to first- even with a bullet or a well-placed star, you’ll be lucky to get into 7th place, where you’ll be struggling the old fashioned way to overtake the other racers.

As an unfortunate aside, you can’t play the Grand Prix in two-player mode, which was one of my favourite features from Double Dash- I don’t want to beat Mario Kart on my own, I want to beat it with Kristen. (Also, I want to beat Kristen, but that’s beside the point.)

The graphics are unspectacular. It’s just how the Wii rolls.

Some of the game mechanics from Double Dash and the DS are toned down a bit. There will be no ’snaking’ in Mario Kart for the Wii- slides take a fixed amount of time, and you’re probably going to have to go around a corner to have enough time for the slides to be a good idea. In addition to the Karts are Motorcycles, an alternative to the Kart that instead of blue-sparks-slide-boosts can pop a wheelie for a quick boost. The wheelies are easier to pull off than the slides, but don’t confer as much of a bonus.

The game also introduces Automatic and Manual play- in Automatic, you don’t need to worry about sliding around corners- the game will perform a slide automatically if you turn deeply enough. You lose any ability to boost yourself, however. I’ve been playing a lot of Automatic- while it’s not quite as difficult, it just feels more natural with the Wii Wheel.

All in all, the game is a lot of fun- and as of right now, there are ten thousand reviews of it on the internet, so you don’t need to hear my thoughts. Want to give it a try? I’m probably bringing it to Phil’s barbeque.

So, I’ve finally bit the bullet and purchased a brand-new MacBook- the more-expensive white model. Thank YOU, Tax Refund.

I’m just now deeply engrossed in my usual process of installing important software.
I know for Windows, I’d die horribly without PuTTY, FileZilla and to a lesser extent TortoiseSVN. The CreativeSuite pack and OpenOffice are also my long-time friends

I’m wondering, Mac users out there- what is your essential Mac software? You know - the stuff that you just can’t live without.

Of course, I understand that you’re both pretty set in your ways- AND you’ve already registered the name (that’s a couple of hundred bucks right there!).. heck, I’m already camping 778pizza.com on the off chance that you’ll need it (or on the off chance that I want to stick a picture of my own butt on the internet)- given that, though, I at least urge caution with the name. “That’s stupid” is *not* the first thing you want people to think of when they think of your restaurant.

With the quality of pizza you produce, you could be successful with ANY name (”Poop Sandwich Pizza”), but you’d be surprised at how much of a difference the name can make- both in attracting customers and making sure they remember your pizza. The time to make changes is now, before you start establishing a brand.

I’m no marketer, but the time I’ve spent learning about marketing (it’s one of those things you try to pick up if you want to get into design) - suggests that your name, your logo, and over-all, your *brand* is SERIOUS BEANS.

On the other hand, like I said before, with the quality of pizza you produce, I’m sure you’ll be successful with *any* name. Good luck!

Now, I don’t know about you guys- I worship at the altar of good barbeque.

Okay, it all started when my mom was dating a guy who had a serious barbeque hobby- he had a smoker, and went to competitions. When they broke up, I was hurt- not because I’d miss him, but because I’d never have those delicious mustardy smoked ribs again. They also made a Texas-style chili that turned me into a chili-lover. This chili is the only concievable reason I would return to the Cloverdale rodeo, even risking exposing Kristen to grizzled, attractive, cowboy-hatted horse-ridin’ men in order to get it.

Hours of watching the Food Network celebrate the many varieties of traditional southern barbeques didn’t help.

But I digress- good barbeque is an art, and an exceedingly rare one in Vancouver.

So, one of my dad’s old roommates, Boonie, has opened a little restaurant, just in the Cloverdale fairgrounds- inside the Curling rink. It’s more a cafeteria than a restaurant, really- except that there has never been a cafeteria that could prepare food of this calibre- or for these ridiculous prices.

No, the venue is not exactly the Ritz-Carlton (or even the Taco Bell/KFC), but it doesn’t need to be. Boonie has a website, featuring the location and the menu, and a few other things. It’s very 1995, but it gets the basic idea across.

Enough of that, though. The ribs will blow you clean out of the water. They’re good. Really good. There are a few little Italian places (Rosa’s, in Port Moody) that serve ribs that have been braising in tomato sauce all day, and those ribs are knockout delicious- but that’s a totally different class of food, a different type of meal. If you’re looking for Southern style home cookin’ (with the apostrophe instead of the ‘g’), Boonie’s is the place to go. Let’s take a quick look at the menu.

Now, the first thing that you might notice- this food is not expensive. A full rack of ribs is a lot of food. A 2-patty burger should not be reasonably possible for under $8. It’s confusing, to say the least.

The food is plentiful, too. The “Full Meal Deal” managed to fill up my brother. Now, my brother, a pretty normal guy in most respects, qualifies as almost demi-human when it comes to his capacity for meal consumption. He’s the only person who’s ever gone head-to-head with Rosa and almost come out on top (I’m pretty sure Rosa had emergency food on the occasion that some champion eater came around.). He’s the only person I’ve ever known to go to IHOP, point at the window at the top of the menu (the one with about 5 breakfasts on it, all laid out attractively), and say “I want that“. Filling Jonathan up on $20 is tantamount to stopping the Mongol Horde with a toothpick and a half-can of beans.

The thing that the menu can’t get across is the taste. The ribs are worth the trip out to Cloverdale, even for those of you who regard Cloverdale as “Somewhere between Vancouver and Toronto”. Everything else on the menu is delicious. I had the first ‘real’ pulled pork sandwich I’ve had in years, and I do plan to go back for more- I’m taking Kristen there next available opportunity.

Boonie is tonnes of fun, if you can keep up with him.

Great food, great prices, no atmosphere. My highest recommendations! Go eat there now! Do it! Spread the word and let the joyous ribs spread across the land!

Wait, not that one. Well, Let’s just say that the game is addictive, but the single-player mode rapidly loses ’spice’ as it starts to become too easy- once you’ve established a foothold and have a hold on the pattern of push forward, fortify, replace lost units, push forward, fortify, replace lost units, etc.., it starts to become a bit monotonous.

Initially, creating a safe haven for your troops is difficult and fun, but at some point you’re just rolling across the map, performing tedious mop-up operations. Part of this may be because of my exceeding thoroughness. Capture every point, fortify the hell out of everything, set up camp, be safe, etcetera. The unit caps- which are rather low- at least keep things from getting too easy- at some point in a scenario you can replace troops as fast as they die, but if you play your cards poorly they’re still going to die by the truckload and territory might even be lost.

Not too monotonous, mind you- I’ve managed to seep a good 6 hours or so out of it, and I wouldn’t be too adverse to going back for some more.

The game captures the theme well, all of the guns sound different and your troops give you useful information. (”Engineers are under fire!”) It feels a lot like someone watched Saving Private Ryan or Band of Brothers and said “I want to do THAT.” I’m still not a fan of the World War 2 theme- it’s an unimaginative, safe way to go about things.

Company of Heroes definitely feels like another Relic RTS- You can almost feel the Dawn of War roots. The tech-tree and base-building aspects, however, are heavily de-emphasized in favour of squad-level tactics (Fortify that building! We need an armored division in here now!). The ‘combat’ part of the game is MUCH stronger than in the Dawn of War series. The battle animations are there in their full glory- less creative however, because in WWII there were explosions and bullets- no giant walking avatars of death. The amount of thought that needs to go into a balanced attack is so much more than just pumping out units and throwing them at the enemy defenses- which, of course, would lead to a humiliating loss.
Cover, chokepoints, and the construction of de-facto defenses (sandbags, mines, tank-traps, gun emplacements…) make the game far more fluid.

I haven’t even TRIED multiplayer yet. Nobody I know owns the game, and people online are (as a guideline) total douchehats. This is, you see, why I’m trying to get you into the game. I need opponents. Come to me! *gwa ha ha*

So, I have two ways of handling Analytics on my website- there’s Google Analytics, handily built-in to my blog, telling me that I’ve had about 775 users hitting my blog in the past month. The most popular articles are the following:

So, just recently, Reddit found it rather hilarious that the Onion’s joking shot at Gillette (Fuck Everything, We’re Doing Five Blades) turned out not to be quite as silly as once planned - in fact, the Gillette Fusion has 6 blades, 2 aloe strips, and a BATTERY.

In fact, most of us- at least, those of us who shave- are starting to feel like the commercial razor industry is starting to get a little bit excessive and silly for it’s own pants. It has to be pretty wasteful to toss away 6 blades, 2 aloe strips and a *battery* after a week of shaving.

I have to admit- I tried the Fusion. Just before I left for Waterloo, my uncle hooked me up with a Fusion Razor and 9 ‘heads’. It’s a pretty clean shave, and thanks to the ridiculous number of blades and my fairly lax shaving schedule, I managed to drag 8 razor-heads out for my entire 4-month stay in Waterloo.

Nevertheless, I’m still curious about a more traditional, less-wasteful solution that’s (hopefully) a bit more economical than buying a tonne of cartridges- especially as I’m finding the need for a good shave more and more prevalent. A straight razor shave is not for me, though- it takes skill, and an incredibly sharp blade plus a sleepy morning is a recipe for a trip to the hospital.

So, I found this article on MSNBC (honestly, when have I ever linked to them?) called “How to Get That Perfect Shave” - an article detailing the old-fashioned ‘wet shave’. Amusingly enough, a lot of the concepts covered in the article were similar to lessons I’d learned from my dad, then forgotten, then learned again when I checked the internet to try to figure out what the hell I was doing.

Chances are, I’m not going to go whole-hog and try the old-fashioned double-edged safety razor with a brush and expensive shaving cream- but I’m at least open to the concept, and if I see some of that stuff for a decent price in my wanderings, I’ll pick them up and give them a try.

At least the future of web-apps.

I’ll admit, that’s a really broad statement. The future is not, in fact, Python-Powered, but it makes for an incredibly catchy title that draws you in to the rest of my article.

Anybody who browses programming.reddit.com or any tech news sites to stay abreast of current trends should be familiar with the brand new Google AppEngine.

The Google AppEngine could be considered a direct competitor to Amazon’s Cloud Computing infrastructure- but where Amazon provides a configuration-friendly piecemeal offering that offers a great deal of flexibility and configurability, the Google AppEngine takes an entirely different tack and provides a stable, secure system that’s not to be fiddled with- providing an application environment out-of-the-box- this is what you get, take-it-or-leave-it, and nothing more.

Google provides a limited environment. You are only allowed to use one language- Python- but the Google folks have pleasantly massaged the Django libraries into there. The Django model for database access doesn’t work, however- you’re stuck with the Google-built webapp system. This also means that you can’t use Django’s admin interface, but that’s not too much of a loss, either.

The Google environment also doesn’t allow for a lot of server-side junk that was traditionally allowed if you were to have your own server. No writing files to hard-disk, for example- there is no hard-disk to write to!

Well, I can’t give you too-in-depth of a review. I’m busy stewing over Haskell, marking, and emergency-studying. Oh, but come Friday, there’s going to be a serious net-fiddling. Fortunately, Todd Hoff at highscalability.com has already done all of the ground work for me!

Google AppEngine: A First Look!

I don’t see this even directly competing with Amazon’s Cloud Computing services, really- it seems like it would be more likely to be popular with hobbyist developers- the type to tool about with a shared PHP server in their spare time, instead of a massive homebrew beast-machine running a custom-compiled version of every language under the sun and failing constantly. The type that demands easy, well-documented interfaces with minimal fuss and muss. The type that is… well… me!

It was a long haul. After a conversation with the professor, it was decided that I probably couldn’t use my original topic, Procrastination, for the final assignment. This was really irritating, because the whole paper was almost done (pdf), darn-it!

So instead, I decided to write on the incredibly dry topic of setting up a LAMP server. Of course, the actual process of setting up a LAMP server is something that only takes about 10 minutes and a copy of Ubuntu Server Edition. So I padded it out by calling it the process of web development with a LAMP server, giving a complete overview of all of the things one would need to get started developing web-applications, from the server-set-up to MySQL to PHP coding. Of course, if this was an exhaustive overview, it would certainly go over the 10-page limit, so it ends up being somewhat.. brief. Extremely brief, really.

I made it exactly one sentence into Philip K. Dick’s “Do Androids Dream of Electric Sheep”.

The first sentence of the foreword by Roger Zelazny. That’s as far as I got.

“Once there was a man who repaired trash compactors because that was what he loved doing more than anything else in the world.”

That’s interesting. I wanted to know more about this man. I read a little further, but it wasn’t about him at all. I couldn’t progress any further than this trash compactor repairman.

So I pulled out LyX and wrote a story about him.

It’s long, and you don’t need to read it unless you’ve got a thing for (exceedingly) amateur science fiction. I’ll run it by Sarah to proof it later- not the Sarah that you know, the Sarah that I know.

I can’t believe I had a sudden urge to write a short sci-fi story about a trash-compactor-repairman.

I’ve never written sci-fi before.
I’ve never written a short-story before.
I don’t know anything about trash-compactor repair.
I suspect that my incredibly short attention span and high levels of impulsiveness are eventually going to lead me to the limits of the interesting things that a human being can do in the 2 hours before whatever it is gets boring and something else catches his attention.

Well, Josh, if you were the subject of a prank, I wouldn’t knowingly choose something like the Canadian Forces - I’d pick something that you were unfamiliar with. The amount you’re able to get away with, vis-a-vis subterfuge, is pretty evenly balanced against how much *you* know about that thing, and how much someone else knows about that same thing. In the same way, I wouldn’t try to fool Phil about, say, Reggae, nor would I try to play a Slackware-themed prank on Travis.

What I know about the Canadian Forces? Almost nothing. Hierarchical authority gives me the raging angries, anyways. But I know more about it (after 5 minutes of Internet research) than my parents do, so I can pull it off.

What do I know about Uzbekistan? Almost nothing. But I created a fake Uzbek driver’s license (for poops and giggles) on the general theory that NOBODY in my circle of friends has any idea what an Uzbekistan driver’s license looks like. Neither do I, but as long as nobody who’s actually seen the real thing comes along, it’s a perfectly convincing looking license. (Okay, maybe the name’s a little silly, but aside from that…)

So, after cooking up a somewhat convincing letter in Photoshop, a curt hand-written note, and rustling about the house at 4 in the morning, I managed to convince my parents that I left early this morning to engage in a 1-month Technical Officer Training program at a Canadian Forces base in Hope.

My dad was so convinced that he was telling people at work that I had left for a month in Hope. Some people called him on it - It must be an April Fools joke! But no, he said- he has this Canadian Forces letter.

Apparently, they all had a good laugh at his expense when I phoned him at work and let him know.

So, over the course of the past day or so, I’ve purchased jPod, read it, downloaded the show, and watched the first couple of episodes.

It manages to capture the insanity of Vancouver and the inanity of tech work. Yeah, everybody knows at least one person who’s worked on-with-or-around a grow-op. Those of us in the tech industry *are* all borderline aspies- the sort of person who would read a book, then download a show, then get irritated at the differences between the two despite the high quality of both.

The Neotronic Arts logo is hilarious. The guy who plays Steve in the T.V. show totally captures a marketing guy I worked with at one of the companies I’ve worked at. (At least I think he was marketing- I never really knew.)

The show isn’t as bleak as the book. Which I like, because the book hit a bit close to home. If you read it, it might hit you there, too. The show doesn’t capture office-life quite so well, though. Toss-up.

And the show has some seriously hilarious moments.

So, here’s the one that caught my eye. The best programmers are up to 28 times better than the worst programmers.

That number just keeps getting bigger. 28? Why 28? Is there now well-established research for the number 28? I could argue that the best programmers are infinitely better than the worst, if anything because there are some problems that bad programmers just can’t solve, bless their retarded code-cut-and-pasting souls.

It’s the 28 that baffles me, though. 28 times. This is a pretty damn exact number. It also makes me feel bad- how much better than a bad programmer am I? Am I 5 times better than a bad programmer? 10 times? At what measurable order of magnitude of coding performance better than this theoretical unter-programmer do I become a useful addition to a coding team?

Are you irritable before coffee in the mornings? Do you feel uncomfortable when people get into your personal space? Sufferers of Normal Humanity often display these symptoms. Ask your doctor about Mordex, the new Normal Humanity medication.

Okay, I’m going to admit it- I kind of like Big Bang Theory. It’s a nerdy show. They make jokes about Black Holes and quantum thermodynamics.

But I just can’t shake the extreme CBS-ness of the whole thing. It’s produced by Chuck Lorre, the mastermind behind such fantastically clever shows as Two and a Half Men, Dharma and Greg, Grace Under Fire and Roseanne.

I’d like to point out that Grace Under Fire is actually a show about a girl named Grace. That is an extremely clever pun, and I am blown away by the cleverness of said pun. Blown away.

So, there’s a history of shows that I don’t like to watch, but I’m not going to let that stop me from watching a show about theoretical physicists. And it turns out that it is, in fact, a clever show. There are lots of snippy in-jokes and nods to nerdy stuff.

But there are still a few things that I just can’t stand about the show- the Sitcom Problems that drive me absolutely bonkers.

The laugh track. I hate laugh tracks. I abhor them. The people in these laugh-tracks are obviously selected from the somewhat sparse group of mentally retarded nitrous addicts, because there is no way that a single human being could otherwise keep up such a consistent level of laughter at every snide comment, awkward stare, deft-turn-of-phrase, or de-pantsing.

From a comedy standpoint it makes sense- comedians are known to ‘work the crowd’ by finding the people in the audience most subsceptible to their humour and targeting them. It’s not just about having funny material- if other people around you are laughing, you’re more likely to laugh. There’s a logical reason why these laugh-tracks are there.

When watching a show, though, sometimes you just want them to turn it down a couple of notches. These people laugh at everything. Knocking on a door? Hilarious. Someone gets some cereal? That’s a laugh riot. The whole script is broken up by muffled giggles from an unseen crowd- and heaven forbid that a potentially emotional moment is driven home with some well-thought-out silence. The crowd will quickly commisserate with our hero in a rousing “Aaaawww” or “Wooooo!”.

The worst part of a laugh-track is that it makes the viewer feel patronized- the show doesn’t feel like you’re smart enough to know when it’s done something funny.

Video Games on TV- honestly, you have a show about nerds, how hard would it to accurately portray video-game playing? It’s boring, I know, but it doesn’t cost you anything to depict it as such. Unless you’re playing a Capcom game, wildly flailing at the keyboard and/or controller will result in only pain, suffering, and sadness.

Sitcomminess - Wacky situations, static characters with easily summarized personalities, and wacky situations! You can almost hear the elevator pitch for the show and the episode in your head while you’re watching it. “See, it’s about two nerds who live next-door to an attractive girl.” “So, one of them wants to go to a conference, and the other one doesn’t- wackiness ensues!” “The Indian guy has to deal with his parents trying to arrange a date for him- wackiness ensues!” etcetera etcetera. Yes, yes, you’re a sitcom, we know.

Nerdiness As A Negative Stereotype - Come on, now- I love nerdiness. I’m a huge nerd, and proud of it. I’m intelligent, creative, social, and I have little-to-no upper-body strength. But as a nerd, watching a show that attempts to pander to nerds, it still seems that the stereotypes are still all there. Okay, I’m not going to say that the common nerd stereotypes aren’t at least a little true- but even my most stereotypical nerd friends have a few ‘normal human qualities’. (For example, Ryan plays soccer!)

There’s a pretty clear line in Big Bang Theory between the nerds and the everybody elses, and it’s made perfectly clear that the two aren’t compatible in any way. Nerds don’t date attractive women, and everybody is either hopelessly unattractive or a Los-Angeles runway model.

Okay, so I’m a pretty nerdy guy, but it’s not like a black-or-white yes/no thing where one minute you’re an all-American Football player and the next you’re a hideous gnome arguing about operating system choices on IRC. Okay, I was arguing about my operating system choice last night on IRC, but that doesn’t count. (Shut up.)

Finally, I’m going to say that Big Bang Theory, despite it’s many flaws (many of which are just centred about the somewhat formulaic nature of the show) still has a lot of good nerd-content, some clever in-jokes, and a catchy theme song by the Barenaked Ladies. Yeah, yeah, I’ll torrent the next episode when it comes out.

In recent news, recently, Paul Graham wrote a self-serving blog post about how everybody should be starting their own company. Jeff Atwood called him a narcissist. Everybody else on the internet made the simple-but-apt connection that Paul Graham- who *has a company that makes money from startup founders*, might have a vested interest in- I don’t know- convincing people to start companies.

I, for one, have heard enough about this, and therefore turn my interest back to internet memes and Allen Pike rambling about web browsers.

Okay, so, I’m fiddling with the Half-Life 2 SDK. I’m curious, darn-it, and I want to see how easy it is to make mods with it. I’m a nerdy guy, right?

My first step was to install Visual Studio 2005, MSDN, and the free Softimage Mod Tools.

Now, there’s a tutorial available at Valve’s Developer Center. One thing that I’ve found so far about the Developer Center is that it’s a wiki, not a reference document. And because it’s a wiki, a lot of the articles are confusingly written, and there’s a lot of missing information.

Immediately, I encountered my first problem. When I tried to use the SDK to create a mod, stocked with all of the delicious code required to get started, I had to deal with a confusing error. “The source code distributed with this version of the Source SDK is not compatible with the “Orange Box” version of the Source engine.”

So, now what?

Solution: Right-click on Source SDK in Steam, go to Properties, then click on ‘Set launch options’, and in the box that pops up, type in “-engine ep1? (without quotes) and then launch the SDK.

Okay, so I’m running an older version of the Source engine, but I’ve started. Huzzah! Let’s continue. I just have to load the project file in
Visual Studio, and I’m ready.

Okay, now for the second problem. The tutorial mentions a file to edit- hl2_dll/weapon_rpg.cpp. This file is nowhere to be found.

Solution: Ignore it for now, I’ll hunt for it later.

Okay, let’s compile! (compile compile compile)..

And 20 minutes later, we’re ready to rock! We’ve now started Half-Life 2: The Modded Version. It’s just like Half-Life 2: The Unmodded Version, except that it doesn’t have any maps and I can’t start a New Game. This is good, though, at least it works!

Okay, so.. how do I put some maps in the mod? I want to try walking about a bit, at least.

Solution: Download and install GCFScape, then go into the Program Files/Steam/steamapps directory and find half-life 2 content.gcf. Open wide, and it’s maps directory is full of maps that can then be copied directly into the Maps folder of the mod that we’ve just cracked open.

Unfortunately, this method, at least according to the tutorial, is illegal if I want to distribute the mod. There aren’t any articles on why (perhaps someone could suck enough information out of the assorted mods to reconstruct HL2 for free?), nor are there any articles on how to legally nab HL2 maps. Maybe it’s just not allowed at all? I don’t know.

So, finally, in order to wander in to the map, I need to open the developer console. Tilde. Tilde. TILDE, dammit! Why won’t you come up?

Solution: In “Options”, “Keyboard”, “Advanced”, there’s a checkbox to enable the developer console. Aha!

After dealing with that one, last problem, I’m on my way, running a HL2 mod that has no new content in it whatsoever. It’s a start! I’ve also come to the conclusion that the Mod documentation needs some serious work. I’m going to keep a record of my discoveries, and try to keep the Wiki up-to-date so that other people don’t have to slog through the same problems that I did.

Well, this is neat. WASTE is a decentralized, encrypted p2p system for small groups.

Yes, yes, technology from 2003. I’m really riding on the pulse of the technology wave, here. Nevertheless, I thought it was neat. I was thinking of maybe looking over the technology required to set it up and pitching it to the crew at #sfucsss.

If anything, I just want to be part of a Darknet. Doesn’t that just sound hells-of sweet?

The more time I spend with web-technologies, the more it irritates me to see developers specifying that This site must be viewed in FireFox.

Okay, it’s not quite so bad as specifying that a site must be viewed in Internet Explorer, which is a really anger-generating move.

Even so, though, at a bare minimum, your site should be usable in Internet Explorer 7, Firefox, Opera, and Safari. If you’re really masochistic, you can shoehorn IE6 support in, there, too. Modern standards-compliant browsers can take just about anything you throw at them, if you’re using a flexible standards-compliant layout. Occasionally you have to add a couple of extra lines of code to accomodate IE7, but even then it’s not too much trouble.

This site must be viewed in FireFox means, to me, too lazy to test in Internet Explorer, Safari, or Opera.

So, it’s day one, and I’ve just cracked open a fresh copy of Smash Bros. Brawl.

Well, I also cracked open a fresh Wii, and a couple of Wiimotes, some nunchuks, a bunch of cords, and a snazzy new hat. Today has been an expensive day, for me.

So, what do I think of Smash Bros. Brawl? I’m sure you’re just dying to know. You’re all hanging with bated breath at my every word. THE POWER! OH THE … let’s just move on.

It’s exactly the same as Smash Bros. Melee.

What about the controls?

Even playing with the Wiimote, after a while you feel like you’re playing a slightly-clumsy version of Smash Bros. Melee. The best way to play is with a Gamecube controller, which has maintained an almost perfect adaptation from the original.

Just starting the game from scratch, we have a group of well-known-and-loved Smash Bros. characters. Mario, Peach, Zelda, Link, Bowser, Yoshi, Kirby, Marth, Pikachu, Ness, boring, boring, boring. Some of the new characters are.. well, really, just old characters- now there’s a new counterpart to Ness, Lucas, who plays almost exactly the same as Ness. Laazy.

King Dedede throws Waddle-Dees and Waddle-Doos. This is an awesome ability, and there needs to be more of this in every game, ever.

I was hoping for more characters from different games, though - of the 12 new characters added to Brawl, 8 are inconsequential characters from games/universes that were already there. The other four are Pit (from Kid Icarus), Olimar (from Pikmin), Sonic (from Sonic), and Solid Snake (from Barbie’s Horse Adventures.)

We haven’t unlocked Solid Snake yet. He seems kind of out of place.

Finally, the game introduces “Final Smashes”, which are just excessively powerful screen-clearing special moves that can only be used if you catch the “Final Smash” item and beat the bejeesus out of it.

So- Smash Bros. Brawl. If you loved the other two, you’ll love this one! If you hated the other two, you’ll hate this one! And the toolboxes who played constantly and beat you every single time before.. will beat you every single time again.

Thanks to daylight-savings time, these changes took me an unexpected hour-and-a-half.

I removed the line of code responsible for scrambling everybody’s names in the comments. (It was fun while it lasted, but it was starting to descend into jerkery.)

I added dates to individual post-pages, I switched from all-caps to upper-lower-all-caps, I increased the size of navigational elements, and moved the dates a little bit closer to the post titles. My CSS file is still really short.

Tomorrow morning, I should check to make sure I haven’t pooched the XHTML validation. It’s time for bed- it’s surprisingly late.

When I was starting out at SFU, and I complained about the crappy math and theory courses, people told me ‘If you don’t like it, go to BCIT” with a tone of derision- as if learning how to program as a trade was some sort of horrible, menial thing.

What I didn’t know was that they were right, and I should have listened to them.

So, Python 3000 won’t have reduce, apparently.

As well, they’re taking out map and lambda functions - not because they don’t expect people to use the features, but because they expect people to use the Python syntax for these things, and not the Lisp syntax- which makes sense, because as far as I’ve seen, Lisp syntax is always horrible.

So, goodbye, map, reduce, and lambda functions. We’ll be replacing you with inline functions, and [function for x in list].

I’ve been writing in this blog for.. I don’t know, a couple of years, now? I spend a lot of time reading and writing and trying to understand how to improve my own writing.

The first and foremost thing I’ve found- quite possibly one of the most important lessons that I’ve learned- is that you should always have a strong opinion.

You should try to avoid littering your writing with words that defuse the meaning of what they’re trying to say. Let’s give an example.

Whenever you qualify your statements with “In my opinion” or “I think that”, you’re sucking all of the authoritativeness right out of the statement. Of course it’s your opinion- of course that’s what you think!

Everything you write has the implicit “THIS IS MY OPINION” attached to it and you don’t need to make that any clearer.

Putting things like that just makes it sound like you’re trying to cover your ass in case you might be wrong. “Oh? Well, it was just my opinion.”

Even worse is stacked qualifiers.

I just recently went through 70 exams, performing some marking on the first chunk of each exam. It took the entirety of my Sunday and most of Monday- my Saturday having been occupied by a funeral.

Let me tell you- marking is quite possibly one of the most boring things in the universe. Any sustained time spent marking is just a big pile of wasted life.

I’ll be glad to get out of academia if I ever get a chance.

Just last Wednesday, it was once again time for SFU to host a career fair- this time for all of the students, instead of just the technical types. I put on a suit, Her Evil Majesty put on some nice duds, and Chris Demwell came in a leather jacket, looking very software developery.

We worked out a list of things that we could talk about. I would cover the basic canon- The history of Aperture Science, our big Operating System project, the Take a Wish foundation, the Heimlich Counter-Maneuver, and the man-sized ad-hoc quantum tunnel through physical space with possible applications as a shower curtain. I would also discuss such interesting topics as our constant need for temps in the “QA” department, our fast-paced, travel-oriented workload, and our benifits package (We’re the only company in Seattle to offer full life insurance!) .

Her Evil Majesty would provide valuable support and professionalism.

Chris would affect a heavy Russian accent and talk about software development, occasionally dropping the accent accidentally when he got excited or irritated.

We decided that if we started to run out of material, Chris and I could bicker about whether or not “Web Development” counts as real software development.

So, we wandered around the career fair a bit- and, wait-look! One of the booths is packing up early. Everybody stand nearby and look busy. Don’t look directly at them. Are they gone? They’re gone. Quickly- steal the table!

We nabbed the table, put down Chris’s heavy metallic briefcase, our flyers, and our business cards really quickly. Having set-up, we started sitting down and smiling at people.

Greg and Her Evil Majesty took pictures, available here and here.

The only sad thing about the ruse was that- most University students don’t seem interested in these booths. We pretty much ignore the people in these booths year-round.

Ah, well, when OpFair comes around next, we’ll be ready- with supplies, a smooth sales pitch, glossy, Aperture Science leaflets, and maybe even a projector!

So, it would seem that my NSERC application was rejected by the gub’mint. I can’t say I’m all-too disappointed- I was beginning to have second thoughts about the whole process anyways- I was kind of wishing I had just done a normal Co-Op.

The rejection was (of course) because of my grades. When it comes down to it, I shoot for C-’s in Math courses and really dry, theoretical CS courses- and waste my time learning More Interesting Things. Personally, I think that makes be a better developer- although it means I’m probably not going to find my way into graphics or statistical analysis any time soon. I’ll leave that to the people who enjoy math.

Much like most of those upper-level students at SFU, I’m becoming more and more disillusioned with the university experience- I really am starting to just want to get out ASAP. I’ve still got 10 courses to go- 3 of which can be from any faculty, any level, really anything. (Honestly, can’t I just give the university $1000, get three A’s, and we’ll call it a deal?).

Past that, it’s one, last math course to desperately try to get a C- in, despite my poor understanding of every prerequisite math course since about Grade 10. That leaves 6 CS courses, of which 1 must be Greg’s Artificial Intelligence, 1 must be the other Greg’s Web-Based Information Systems, 1 must be Operating Systems II, and.. well, 1 more 300-level and 2 more 400-level, perhaps drawn at random by throwing darts at a blind man. (I can’t think of anything else I really want to take. Computational Linguistics looked fun, maybe?)

So, now, it’s time to apply for a couple of jobs! I’m going to hit up IBM, Blue Castle, maybe take a look at a few other companies.

So, apparently, CS is seeking out slogans to put on T-Shirts. I wasn’t sure if we were allowed to plagiarize, because there’s a couple of quotes that I’d love to have on a T-shirt:

Yes, I think we can all admit that this website is beautiful and fantastic. But many of you might not know that this is maybe the third iteration of the site.

curtis.lassam.net is powered by Wordpress.

The first website theme was one of the first Wordpress themes I had ever put together. If I’m lucky, we shall never speak of it again.

The second website theme, named “Travelous”, had served me in good stead for over a year. It was simple, it had lots of curved lines, and worked with my innate love of themes that combine a single colour with white and black. (You’ll notice that same thing about the current theme.) While it was, at least in my opinion, attractive, it lacked a few features that were really important to me. It wouldn’t validate as XHTML, it wasn’t very standards-compliant, it didn’t display well on mobile phones, and the layout wasn’t very flexible. It didn’t display as well in Safari or Internet Explorer 7. The CSS was poorly organized and difficult to read. There were lots of problems with it that needed retooling. Thus, the third theme.

This new website theme, “Georgia Caboose”, is the one you’re looking at right now. It’s actually less visually compelling than the last one- but it has that element about blogs that I love so much, simplicity. It’s designed to use only one font, “Georgia”, and comes with my caboose logo plastered all over the place.

The site’s also pretty flexible in it’s layout. Try it- resize the page a bit. It grows. It shrinks. If you go below a certain threshold and leave it there, it’ll do away with the sidebar entirely- this with my first-ever foray into JavaScript.

So, where do I go from here? Well, the site still needs a mobile and a print stylesheet. Being as I’ve been learning more and more JavaScript over time, the site-resizing algorithm could be improved.

After Friday’s wackiness, me, Her Evil Majesty, and Chris, have decided to try some similar Aperture-Science style hijinx at the upcoming career fair.

So, I was sitting outside of Opfair, brooding. Don’t want to work there, don’t want to work there, especially don’t want to work there. I chatted a few representatives up- but whenever I started to go into my lust for beautiful, beautiful, beautiful, scripting languages, they all replied with the same stock line: “Oh, you’re into scripting? Well, we do mostly more mainstream stuff- Java, C#- but we’ve got some Perl development going…”. That’s my cue to exit.

The reason the Obfuscated Perl contest shut down, I’ll postulate, is that one year the code that one of the judges wrote to automatically test-interpret contest entries was accidentally submitted… and won.

And then the inspiration hit me. When I had first heard of this year’s OpFair, I had wanted to set up a booth of my own, so as to represent Aperture Science. There was going to be a poster and everything.

I frantically looked around for some booths, but they were all full. Curses!

I had forgotten, and was disappointed. I explained this to Her Evil Majesty, and she thought that we might be able to nab a booth at the end of the day, while everybody was cleaning up. She was right- we nabbed the Sophos booth just as they left. We sat down a while- she had a professional looking pen, I had a bottle with another company’s logo on it, and we were both looking rather sciencey- me in my collared shirt and sweater, Her Evil Majesty in her.. um.. evil clothes?

.. We didn’t have much time. Everybody was packing up. I grabbed the first person I saw- a somewhat dapper looking asian guy in a suit. “Would you be interested in a career with Aperture Science?”.

It started off well. We were, at first, curious if he had heard of us. “A little market research”, I quipped. I explained that we’re working on a rather revolutionary operating system, the Genetic Lifeform and Disk Operating System. Her Evil Majesty chimed in with “GLaDoS!”

“We’ve also done some work with shower curtain technology, and a few other things. We do a lot of general R&D.. have you ever heard of the Heimlich Counter-Maneuver?”

“No.”

“Well, it’s a fantastic maneuver to induce choking.”

“Induce.. choking?”

“Yes, yes, well, I guess you haven’t heard of it. How about the Take a Wish Foundation? We take wishes away from sick children who won’t be able to enjoy them, and pass them on to healthier children who will appreciate them more. ”

“Oh yeah!”, he went.

He looked around- our table was pretty empty. I panicked - “Oh, we’re just packing up right now- we’ve got everything all boxed up and we’re ready to go.”

Her Evil Majesty deadpanned “We had these awesome little plush companion cubes to give away.”

We then started to discuss what we were looking for in applicants.

“We’re looking for flexible people”, I said. “You’re expected to do a lot of traveling, and deal with some extremely adverse situations.”

“What’s the application process like?”, he asked.

Her Evil Majesty had this one. “VERY intensive.”

He then talked a little about himself- he had a degree in Electrical Engineering at the University of Waterloo, and was just finishing his MBA at SFU. At this point, me and Her Evil Majesty exchanged a glance and started shooing him away in a sort of graceful manner.

“Oh. I suppose you’re not what we’re looking for right now- we’re going for a lot of lower-level types- C, C++, that sort of thing. ”

We shook his hand without even taking his name. He asked for a brochure, but we explained that we had already packed all of the brochures away and were, in fact, just getting ready to leave.

He then took off. Me and Her Evil Majesty retreated to the common room, high-fived, and laughed and laughed and laughed, while telling the tale to everybody else in the room.

Me, Her Evil Majesty, and Chris Demwell think we’re going to set up a booth in the AQ next Friday. Are you in?

Okay, so I haven’t been to my Tech Writing lecture in a while. Tech Writing, while interesting at times, has not been an urgent class where lots of important facts are imparted. Things have come up.

This Wednesday (today), for example, I had to meet with Stella Atkins about some marking- in order to have my Thursday (Valentine’s Day) free to spend with Kristen. We’re going to have breakfast, go to the aquarium, make some cashew-chicken-stir-fry, and go to a Valentine’s Day Party tomorrow. These things are more important to me than 376. (Addendum: While Christians are super-creepy when they’re preachin’, when they’re having parties they’re good folk. )

On Friday? I have to be at a Tea Club & Robotics Society Meeting. I have to go, because I have a FEVER, and the only cure is MORE ROBOTS.

Next Friday? I have something clever planned. Something clever and evil. (More on that tomorrow.)

So, I’ve been skipping out on 376 a lot lately. Greg Baker tried to address the problem of What 376 Is For- and while the theory is sound, the course itself so far seems a little bit light on content.

Now, I’m not one to think that my English is perfect, beyond the boundaries of improvement- but meta-discourse on the topic of English is both dense and incredibly boring. Some far-away authorities have managed to come up with a codified system of rules to define both English language elements and how they can be effectively used. Retrieving this knowledge in it’s codified form, however, seems entirely beyond my limited mental faculties. The best way to really get a feel for these rules would be to read a lot of well-written articles, try to write your own, and have someone slap you about when you’re not writing things clearly enough. (Of course, no University course in existence has enough manpower to accomplish that in 4 months with one TA.)

Free-writing is a good thing and a valuable exercise. Okay. Lesson learned. Do we really have to spend class-time on it every lecture? It feels like it devalues the lecture itself to spend time with a professor doing something that I could reasonably be doing at home, or at school, or on the bus on the necks of unexpected passengers. (This being why I carry a sharpie.)

I came to 376 with a few very specific questions in mind:

How do I write effective documentation?
How can I write an effective technical specification?
How can I write effective and convincing product reviews?
Are there other critically important technical documents that I’m not thinking of?
How do I write those?
Now, I was hoping to have those questions answered- (Hoping being the operative word)- but instead I’m getting drilled in the fundamentals. Now, I’m sure the best answer to each one of those questions is “Write concisely and clearly”, but maybe I was hoping for a little more of the Software Engineering bits, too. Of course, that could get tedious, fast, as well. I certainly don’t envy Ted the task of putting this course together.

I’m not sure who this “MacKenzie” was, but I think he’s getting a bad rap from the crappy cafeteria. Every time I go in there, it doesn’t seem like they have anything worth the exorbitant prices they’re charging.

A lot of people read my site using a technology known as RSS - for you non-technical types, that’s pronounced “russ” or if you’re a really clear enunciator, ‘ruutaaabaaagaaa’.

I was wondering if RSS just picks up the articles from my site once, or picks up the most-recent version of any articles that I write. I tend to do a lot of editing after I publish articles, to the point where anything that gets published on my site probably gets a complete working over about 5 minutes after it’s published.

Just wondering. TEAM LAZYWEB, GO!


For me, becoming an atheist was a deeply personal experience- Through soul-searching, study, and meditation I managed to discover the true meaning of the universe. A duck. Having concluded that the universe is a rather silly and unknowable entity, I took the pragmatic position of militant agnostic- I don’t know and neither do you! Eventually, a series of articles and books convinced me that this sort of general disbelief really falls more under the aegis of atheism, so there I went.

This is all a bit of a prelude to the following story, where by some hookery and crookery, Kristen managed to drag me to a bible study. It wasn’t entirely a swindle on her part- she told me that it was a young-adult group organized by her church, and that there was likely to be religious people. I was a bit wary, but fun activities were promised, and Kristen wanted to go, so I tentatively agreed to go with her.

This meeting of the young-adult group - and Kristen assured me that this is fairly rare- happened a bible study, a long and painful experience of forced-churching. We got to talk about God’s Grace, and doesn’t that just sound fabulous.

In case you’re wondering, in a biblical sense, Mercy is when you deserve something bad but don’t get it, and Grace is when you don’t deserve anything but you get something good anyways. Ah, that old biblical standby- you suck, you’re horrible, but even though you don’t deserve anything, ever, God will be your cosmic hook-up.

While I find Christians perfectly tolerable while they’re, say, getting owned at a game of Civilization, when they’re going on and on about how god had/has a plan for their life, I start to wish I was at the dentist, having hot needles poked into my gums. This is why I don’t go to churches- I end up sitting quietly, nervously hoping that nobody calls on me - because when pressed for information, at some point I’m going to have to reveal that I’ve slotted ‘God’ in the same mental cubby as The Easter Bunny, Santa Claus, and Good Tech Support.

At some point, someone said, “My Grampa said, kill ‘em with kindness’ “. I came up with the ever-so-horrible response, “My Grampa said, ‘kill ‘em with pillows while they’re sleeping’, but they took him away a long time ago. ” Somehow, I managed not to say it, although I can imagine I turned beet red for a couple of minutes and probably fidgeted uncomfortably.

At the end of the night, plans were made for a big post-romance Valentine’s Day party, what with chocolate and boyfriends and romantic movies. I suggested that we watch my favourite romantic movie, “Evil Dead 2?, and the one other guy there who wasn’t a Christian has a bit of a chuckle. (He then tried to explain it to his girlfriend- it doesn’t sound like it went well.)

So, I ended up making an agreement with Kristen. I’ll go back, but I reserve the right to say whatever might be on my mind at any given moment- and if I get kicked out, set on fire, or sprinkled with holy water, so be it.

Those of you who are slightly more observant (and aren’t using RSS) might have noticed a few minor changes to the website. Like, for example, the total redesign. It’s still in development- there are a few things that need to be adjusted- but this is generally how the site’s going to look.

I have to add Google Analytics, add some space below each post, a little o’ this, a little o’ that. I have to switch the favicon about. I have to do some minor tooling-about to get that XHTML-validation award. Maybe toss in an explanation of the caboose. Or not.

The one thing that won’t be coming back? The blogroll. My apologies to anybody who’s lost their space on said blogroll, but I don’t think that it’s a very useful feature. I’ll try to read your blogs and post whenever you do something interesting, instead.

Also, and this is my first foray into JavaScript, the site-style changes if you view it in a window of less than about 775 px. Give it a try! Neat, huh? I still have yet to put together a mobile stylesheet, but that shouldn’t be too much difficulty.

I’ve tested it in the Big Three. I am loathe to say that I like Safari the best- anti-aliasing makes my giant-text decisions look snazzier. I’ll vet it on Opera & Opera Mini later.

So… what do you think. I DEMAND YOUR OPINIONS!

After that, we went into a slightly-less interesting discussion about Content Organization, which failed to blow me away.

Then, a look at visual organization with a few interesting grid layouts as examples. The examples given were the sites for Pentagram Design, TED, and SamataMason, with a discussion of some peripheral concepts like eyeflow and proportion.

One of the concepts during the presentation that I found really interesting was that constraints can breed creativity. This struck me as immediately both true and a fantastic idea. There is nothing more alarming than a blank screen- but once you set a constraint for yourself, things start to flow. It has to be blue, and no wider than 700px. It has to be in one font, and you can only use one colour. So with constraints come creativity.

Finally, and here I’m looking at the smattering of rules that I had taken as notes, a couple of rules of good typographic practice.

And that’s it for that presentation.

After the presentation, we had lunch at the Hyatt. This was one of those semi-fancy food buffets that you always eat at halls and hotels, office-function food. Salads, starches, and a few trays containing assorted meaty products.

I found the meal unbalanced, as buffet food almost always ends up being. Offering up so many choices- say, a stuffed ravioli next to a southwestern-style flank steak- just seems to colour the whole meal a bland gray. The meal was not memorable.

More tomorrow!

So, I attended Web Directions North last week.

Web Directions North is a Vancouver conference for web developers and designers. As a kind of quick summary, it was 12 lectures from a variety of speakers on topics relevant to the web.

Thanks to my Symbolic Computing homework and the astronomical distance between me and the Hyatt Hotel in Vancouver- right next to Burrard Skytrain station, if you’re wondering- I had about 5 hours of sleep. 5 hours of sleep might be appropriate for a first-year Comp Sci student, but I’m starting to need at least 8 a day to feel like a productive member of society.

I met up with Allen and Kumar just after the first keynote- Kumar’s distinctive yellow hat was like a beacon, and as soon as I saw it I knew he was there. It’s actually a really good idea- Kumar has his own brand already.

The keynote speaker was Jeffrey Zeldman, publisher of “A List Apart” and web-standards advocate, describing his history with Web Standards. While it was interesting to learn a little bit more of the history behind web standards, there wasn’t anything really new or interesting, and the talk was a little slow.

After the keynote, we had breakfast. Tea and baked goods are always a good way to start the day, although I found the tea lacked the necessary caffeine to pull me out of my yawning, tired funk.

The first presentation of the day was Josh Williams’ “Bedroom To Boardroom”. Josh Williams discussed how his company, Firewheel Design, moved from small-scale consulting to development of their own products. Josh Williams had some good advice- my favourite bit being this: When consulting, it’s more profitable (and fun) to hyperspecialize in a niche than it is to be a little bit good at everything.

Apparently, also, there is a lot of work out there for icon designers, if we happened to be interested.

I don’t actually work with icons that often for sites- but it’s definitely something I should look at.

More tomorrow!

I just recently purchased a new computer. Happiness ensued- quad of the cores, 3Gbs of the memories, and a big hard drive.

Of course, even given it’s many specs, it was a Best-Buy Special, so the computer inside lacks a decent motherboard or reasonable power-supply- a mere 300W.

The on-board Intel graphics irked me most of all- with all of that computing power, you might as well have at least two monitors. Okay, so I bought a cheapy ATI Radeon HD 4200 Pro, a low-end 256mb graphics card, to support an additional monitor. Given the powerful core-ful computer, I figure even a low-end graphics card should be able to support some mild Team Fortress 2, as well.

So, I get home, open the motherboard, cram that PCI-Express card in there with much gusto, and power on.

Nothing.

The computer’s clearly abuzz with activity, but none of the monitors are working at all. Okay, that sucks.

I remove the graphics card and it’s connected monitor, and just try it with a single monitor. Everything’s fine, Vista takes 11,000 years to start, the old same-ol’-same-ol’.

Something’s wrong with the graphics card. I try the card again, figuring maybe it wasn’t fitted snugly enough. Nope, fail.

When I turned the computer on with the two monitors the first time, though, it did turn on, turn off immediately, and then turn on again and stay on. Maybe the problem’s a power thing?

It’s time to check the manual. I pull the CD out of the drive, start reading the manual, and.. hey, this manual is for an AGP graphics card! And a totally different model of graphics card that apparently requires at least a 750W power supply.

I check the box. Yep, it says ‘300W or better’ in the power-supply requirements.

So, ATI clearly failed to include a pertinent manual. Let’s check their website.

The support system on the website is terrible. It’s organized poorly, the information I want is all over the place, and nothing seems to solve my problem.

Oh, here’s something- if I can’t get an image through POST, I need to check if I have an integrated graphics card (yeop) and if I do, disable it in the BIOS.

What’s POST? Shouldn’t there be an explanation of that around here somewhere? I’ll just check Google. Power-on-self-test- oh, yeah, that’s the important first bit where the BIOS starts everything up and displays images and whatnot. The other explanation is that (surprise) I may not have enough power.

But.. wait- if my graphics card isn’t working, and I disable my built-in card.. and it doesn’t work.. then I have no card at all! And no way to fix it, without a monitor!

Okay, I need further support. It’s time to contact Tech Support. Finding out how to contact Tech Support is the first step- it’s a horrifying ordeal on AMD’s webpage. They don’t have an 800 number, just a bunch of miscellaneous long-distance numbers that I can call if I want to spend $15 to wait on hold.

Oh, here’s an online ticket form. Great!

First, though, I need to sign up. Name, e-mail address, location, blood type, favourite colour, etcetera etcetera. I hate signing up just to get support.

Now I’ve reached stage 2- actually submitting a ticket. The system informs me that filling in the fields adequately will help my ticket be dealt with, so I fill in the model number, information about my computer, my Oscar picks for 2008, just about everything that I can tell them. Then, a quick description of my problem.

I send it off, secure in the thought that my problem might be solved. Eventually.

I check my e-mail.. nothing yet. I know it’s going to take a while, but maybe they have an automated reciept or something?

Now it’s 2 hours later and I get an “automated response” with such useful information as where to find manuals, where to go on the site to learn about cool features in ATI’s newest product, and a place to learn about new features in ATI’s software.

To add insult to injury, the instructions about how to get to the manual - the one bit of information I could have used- didn’t even come with a link, instead with the vague instructions “If you are looking for a manual please click on your product and select “Manuals User Guides & How-To’s”.”

Now, being that I can’t actually click on my product (it’s external to the computer) I guess they meant my product’s homepage? I don’t know, they didn’t provide a link to anything.

On the incredibly slim chance that this amazingly useful support would *fail* to solve my problem, I’m now instructed to log-in *again* and update my ticket- once again without a useful link to get me to where I’m going.

Now, I’m frustrated, both by the fact that my card doesn’t work and by the momentously poor customer service I’ve been getting from ATI, with a little bit of peripheral frustration at Acer for building a moderately high-end computer with such a terrible motherboard and power supply.

Long story short: I hate all human beings.
Oh my god! Curtis hasn’t posted for TWO WHOLE DAYS!

Yes, things are afoot. I’ve been hugely busy this week-

Sunday was a memorial for Grandma Judy.

Monday I was so exhausted and drained from Sunday I just slept for most of the day.

Tuesday I worked on my Symbolic Computing homework (Small Lisp!) and finished 66% of it.

Wednesday I went to Web Directions North (School was closed anyways), left before the closing keynote, and finished the last 33% of my Symbolic Computing homework, getting it done a mere 20 minutes before the midnight deadline.

Today I went to Web Directions North again, all day this time, and this time I stayed for the whole thing- then dinner and a hosted party with unlimited free booze.

I’ve had maybe 9 hours of sleep over the last two days and I am exhausted- so exhausted that I left the party after two-and-a-half hours, only three high-balls and a beer. Next year- and I”m definitely going next year- I’m going to have to plan ahead, sleep more, and drink more than double my weight in, as Allen termed it, “Free Infinite Alcohol”.

There have been lots of big names, I’ve had a great time, and I have a whole whack of blog posts in mind- two ‘restaurant reviews’, one long-overdue bacon post, and a bunch of Web Directions 08 stuff- But for now I just need some sleep. I’ll see you all tomorrow!

I am a big fan of webcomics- I think they’re a unique art-form that really could only come about with the internet in place. They’re more personal, more shocking, more experimental, more adult, and more interesting than the sort of comics you’d get in your newspaper- and still pretty darn funny.

So, of course, over my travels, I’ll occasionally encounter new and interesting webcomics that I’ll add to my list and not tell anybody about. Some of my favourites are the ones that everybody knows about already - Penny Arcade, Sinfest, Something Positive, Saturday Morning Breakfast Cereal, xkcd, Dr. McNinja…

But the ones I’m going to talk about here are the classy ones that few people have heard of.

A few days ago, me and Ryan were getting a ride to the bus station from Phil.

On the way, he asked if we were hungry and suggested a nearby Jamaican place.

I was snorgbaffled. Jamaican food? I had experienced some Caribbean food before, once, but it was in a strange little cafe in North Vancouver and the thing I had (A sort of spicy avocado eggs benedict) seemed more like a once-off concoction than some sort of traditional food.

Okay, I wasn’t that hungry, but I volunteered, and cajoled Ryan into it, too. Who would miss an opportunity to try something new?

Phil took us to a little hole-in-the-wall called “Taste Nice” just next to Gateway Station in Surrey. Now, I’ll say this right now- I have nothing but respect for this sort of restaurant. Nothing compares to little family-owned joints with fresh, authentic home-cookin’. Apparently, the proprietors of this restaurant are also pretty close to Phil.

Upon entering the restaurant, I was immediately confused. There weren’t many tables or chairs. Maybe it was it a take-out restaurant? Nothing on the menu-board seemed like it would be a portable item, but why else would there be so few tables and chairs? Maybe they were just cleaning up for the day when we arrived- or maybe the menu really is a more casual take-out kind of fare. (Phil?)

Some unidentifiable reggae music was playing- I can differentiate 86 individual types of electronic music, from Trance to Electroclash, but to me, reggae always falls into the fairly large and faceless category of “music that is far too slow to concentrate on”.

Phil just blazed in to the kitchen, greeting everybody. An older fellow came out and started bantering back and forth with Phil in a thick, unintelligible Jamaican Patois. I’m sure they started by talking about the music- how it was a remix and something something, but everything after that just faded into a blur of sylabbles with the occasional English sounding word.

He turned to Ryan and me, dialed down his accent a bit, and explained a few things about his restaurant- his simple home-cooked philosophy, and how “Taste Nice” was his attempt at truth in advertising.

We ordered beef patties and drinks- Ryan had a Cream Soda and I tried a excessively refreshing citrus drink called “Ting“. The patties were mildly spiced beef surrounded in a slightly-greasy home-made pastry- I liked them, and I’ll have to go back for a more substantial meal at some point. I don’t know what to order, though. ( Phil? )

Then a younger guy came out- the proprietor’s son, perhaps? He had a bit of Comp-Sci education and talked shop with us for a bit. While a patois may leave me high and dry, I’m sure nerd jargon can be an impenetrable mass to digest for outsiders, too.

So.. Taste Nice tasted good, awaiting further scrutiny. And I’m going to have to find some sort of local Ting supplier to satisfy my newfound grapefruit-drink cravings.

Hello, all. For my CMPT 379 class- that’s Technical Writing- I’ve been assigned to sock together a recommendation vis-a-vis Test Driven Development for a small team. Let’s see what we’ve got.

What Is Test-Driven Development?

Let’s start with a quick summary of what is and what isn’t Test-Driven Development.

Cheese isn’t Test-Driven Development.

Muffins aren’t Test-Driven Development.

Kittens aren’t Test-Driven Development.

Okay, defining Test-Driven Development negatively like that is going to take a while. Let’s start with what it is.

Test-Driven Development is a method of program design and layout. Test-Driven Development tends to proceed as follows:

Look at the current system, even if it’s a blank slate. What functionality isn’t there that should be?
Write tests to check that functionality. These tests will, of course, fail immediately.
Write code to pass those tests.
Imagine boundary conditions, extreme input, and other potential ways to break the code.
Write tests to check those points of failure. These tests will, of course, fail immediately.
Refactor the code to pass those tests.
Imagine some sort of overarching major design for the system and how your feature will fit into it.
Write tests to check that the design is in place. These tests will, of course, fail immediately.
Refactor the code to pass those tests.
Repeat until the entire system is built.
$$ PROFIT $$
And that’s it- that’s Test-Driven Development.

It’s A Highly Modular Black-Box Bottom-Up Design Method

In Test-Driven Development, individual features tend to be designed from the bottom up. Writing the tests before the code mean that before we put any code down on paper, we’re thinking about the interface that we want to use for the code- and that encourages good design principles.

Functional Programming is currently en-vogue for it’s many apparent benefits- writing a program out of many small functions with clearly-defined interfaces that have no side-effects. That’s justs a recipe for easy debugging, easy parallelization, and stable, manageable code. In Steve McConnell’s “Code Complete”, he makes it very clear that functions should do exactly what they say they do and nothing more, with no side effects. Planning out a function beforehand and building it independendly of the system is a good way to write this sort of modular code.

On top of that, the functions are tested all to hell before they are used anywhere in the system. Being able to treat functions as trusted little black-boxes with well-defined tasks makes development faster and easier.

Having Tests Makes For Easier Development

With tests available for development, checking the correctness of your function merely requires the press of a button. Compile and check your test result. If it’s green, you’re good. Having a design in mind and a set of small, easily achievable goals can make development a much simpler process.

From Wikipedia:

Programmers using pure TDD on new projects report they only rarely feel the need to invoke a debugger. Used in conjunction with a version control system, when tests fail unexpectedly, reverting the code to the last version that passed all tests may often be more productive than debugging.

Regression Testing is a Very Good Thing

Once you’ve built all of these tests, you can always immediately find out if some change in your code has broken any part of the system. While the system’s loose-coupling hopes to reduce the possibility of this happening, it still makes debugging much, much easier if you don’t follow the “Fix one bug, accidentally introduce three” model.

With regression testing and version control, it’s much harder to get into the sort of situation where nobody wants to touch the code for fear of breaking everything forever.

You’re Going To Hear The Word Granularity Bandied About A Lot

When talking about Test-Driven Development, it’s common to talk about how much of the code is being tested at one time. Some developers like to write a lot of small tests and refactor the code each time- this would be considered a very low granularity. Some developers like to write entire test suites before getting started with their coding- this would, of course, be high granularity.

Okay, So What’s Wrong With Test Driven Development, Then?

Aha, here’s the really juicy part, the part you’ve all been waiting for. Let’s rip into Test Driven Development, shall we? Let’s really tear it a new one!

Surprise! I actually think that Test Driven Development is a fantastic thing.

Why would I advise against it, then? Am I a schizophrenic? Perhaps I have a short memory?

No, none of those things. I feel that “Test Driven Development” combines three problems that I find in a lot of software development- it’s too formal, a bit heavyweight, and it’s not comprehensive enough.

Not Comprehensive Enough

Let’s start with the most important criticism. Test Driven Development is a way to test systems, but it’s not the only way. Unit testing is only one element in a whole toolkit of testing types - and the other types of development are very important as well. Joel Spolsky wrote a very critical review of unit-test-only development in his recent talk at Yale:

This seems like a kind of brutal example, but nonetheless, this search for the holy grail of program quality is leading a lot of people to a lot of dead ends. The Windows Vista team at Microsoft is a case in point. Apparently - and this is all based on blog rumors and innuendo - Microsoft has had a long term policy of eliminating all software testers who don’t know how to write code, replacing them with what they call SDETs, Software Development Engineers in Test, programmers who write automated testing scripts.

The old testers at Microsoft checked lots of things: they checked if fonts were consistent and legible, they checked that the location of controls on dialog boxes was reasonable and neatly aligned, they checked whether the screen flickered when you did things, they looked at how the UI flowed, they considered how easy the software was to use, how consistent the wording was, they worried about performance, they checked the spelling and grammar of all the error messages, and they spent a lot of time making sure that the user interface was consistent from one part of the product to another, because a consistent user interface is easier to use than an inconsistent one.

None of those things could be checked by automated scripts. And so one result of the new emphasis on automated testing was that the Vista release of Windows was extremely inconsistent and unpolished. Lots of obvious problems got through in the final product… none of which was a ‘bug’ by the definition of the automated scripts, but every one of which contributed to the general feeling that Vista was a downgrade from XP. The geeky definition of quality won out over the suit’s definition; I’m sure the automated scripts for Windows Vista are running at 100% success right now at Microsoft, but it doesn’t help when just about every tech reviewer is advising people to stick with XP for as long as humanly possible. It turns out that nobody wrote the automated test to check if Vista provided users with a compelling reason to upgrade from XP.

There are major types of testing that Test-Driven Development will fail to provide.

Pain And Suffering

There is no match for the rigour and meaningless destruction that experienced QA testers and real beta testers can wreak on your system. The simple unit tests provided by Test-Driven Development are just too easy to pass. The real test comes when raving masses hit your program with ridiculous input, strange ways of using your software, and malicious attacks. Writing automated tests to ensure that you’re never revealing too much data to the user, or to check if you’re allowing for XSS vulnerabilities- well, that would be unwieldy and incredibly time-consuming.

Getting the full Automated Test Suite to pass means, quite simply, that everything works, in one way, on one system. That’s a very narrow definition of success, one that may not translate well into the real world.

White-Box Testing Required

Some systems just require some white-box testing. Networking protocols, SQL queries, these all handle things outside outside of the purview of the program. In order to make sure these things are working properly, it’s best to take a look at the details of what the system is actually doing behind thes scenes. A class handling SQL queries can be tested, but in order to really know if it’s doing the right thing, I have to check the database itself to make sure that the data looks correct and nothing silly is happening.

You Just Can’t Test Some Things

Finally, it’s incredibly difficult to test some things. User Interfaces and Design are two examples of things that cannot be tested without some sort of test framework olympics in place- and those are things that can either be wrong or right. Usability, consistency, and visual appeal are only testable in aggregate, and even then they’re slippery slopes.

These things can be much more adequately tested with 5-Minute-Random-User-Tests, code reviews, QA testing, beta testing, many other techniques- but they are almost impossible in terms of unit testing.

So What?

Test-Driven development is meant to be paired with other techniques to ensure that the software gets tested every-which-way-but-loose.

My argument is that Test-Driven development puts too strong an emphasis on the “Unit Test” portion of development and not enough on the others.

While unit-testing is an important part of the software process, it shouldn’t edge out any other method of testing. In order for our company to produce high quality software, we need to embrace all of the different methods of testing, as opposed to concentrating heavily on only one element of the process.

Formal Processes Guarantee Only What’s Covered Within The Process

Software is a difficult balance. A good function is well-written. It is unit tested, it checks preconditions, it checks postconditions, it even checks impossible things. It’s well documented. It fits in with the design principles and coding standards that the rest of the system uses. It is tested by hand a little bit, to check for stuff too silly to even write unit tests for. It has personality.

To specifically mandate all of these things about a function in a codified set of processes is certainly the holy grail for some companies, but it comes at the expense of anything that’s not covered in the formal process.

It’s Too Heavyweight

There’s a certain point where the work involved in setting up test frameworks exceeds the benefit of dealing with reams of unit tests and the management involved.

Here’s a quote from Wil Shipley, author of the Del.Icio.Us JavaScript libraries.

You should test. Test and test and test. But I’ve NEVER, EVER seen a structured test program that (a) didn’t take like 100 man-hours of setup time, (b) didn’t suck down a ton of engineering resources, and (c) actually found any particularly relevant bugs. Unit testing is a great way to pay a bunch of engineers to be bored out of their minds and find not much of anything. [I know -- one of my first jobs was writing unit test code for Lighthouse Design, for the now-president of Sun Microsystems.]

When it comes down to it, having some unit testing in place for the purpose of regression testing is a good thing. This doesn’t, however, require a massive unit-testing framework. A bundle of external assert statements to check that the code isn’t doing anything too naughty would be almost as effective, with far less set-up and takedown time.

At some point, the benefits of setting up unit testing are just outweighed by the massive amount of effort that goes into the construction of reams and reams of tests. It would be best just to find a happy medium at some point in the testing- a point where there’s enough testing to catch major bugs and fix-one-introduce-two bugs, but not enough to require a couple of dedicated software engineers to manage.

Finally.

So what should we do?

I believe that Test-Driven Development is too formal, too heavyweight, and not comprehensive enough a strategy. It will eat time and energy that would best go towards a more balanced and comprehensive testing strategy.

I suggest, as an alternative, Ridicule-Driven Development.

Just like in Test-Driven Development, we should individually build one function or process at a time and build it well. When we’re building functions, we write unit tests and documentation at the same time. When we’re finally reasonably sure our functions are ready, it’s time to hand them off to our coworkers, where they will be torn to pieces, viciously mocked, and ridiculed heavily. Coding standards will develop organically and be enforced via ridicule as the project continues.

In order to keep the peer ridicule (er, ‘review’) sharp and pointed, we’ll offer weekly seminars on various important topics- documentation, testing, automated tests, anything that catches our eye that week. A corporate philosophy of constant improvement is certainly nothing to scoff at.

And now.. awaaay!
My mother’s boyfriend, Vinny, is an Italian guy. His name is Vinny, for Pete’s sake. Now, while my mom’s kinda vaguely half-Italian, her father had kind of had a falling out with his family and the Italianness never really shined through. As for me, I have about the same cultural heritage as, say, a pickle.

Not Vinny, though. He still speaks the Italian that floated around his house as a youth- albeit only with his mother and father. His parents are bilingual, but they still watch all of their television in Italian if they can. If there’s any way to put it, they’re Very Italian.

I went to Vinny’s parents’ for dinner on Saturday evening. I look forward to eating dinner with Vinny’s family, because the food is delicious. I didn’t eat all day leading up to it- no, no, if an Italian mother is involved and you don’t come prepared with your appetite, you might leave dead or at least in some sort of stupor. (Heck, even if you do come with your appetite this might happen.)

The first time I had been to Rosa’s for dinner, I had been unaware of the concept of a dinner with more than one course. Oh, you know, I was familiar with the concept in a nebulous ‘yeah, maybe in a fancy restaurant’ fashion, but it had never actually been applied to a meal that I’d eaten in more than a perfunctory appetizers-salad-meal-dessert sense. So the first time I went, I had a big plate of pasta to start off with, a big saucy heap of noodles. I was just finishing that, feeling just the right amount of full and happy when the family started suggesting that more food would be coming. I was flabbergasted- how could more food possibly exist? But no, there was more food, and I was expected to eat it. That was bad times right there.

Vinny’s mother, Rosa, came out with a huge lasagna. She started slicing it up and doling it out to people. I had been prepared to eat a smaller, more appetizer-sized first dish when a plate of lasagna that could be described only as gargantuan appeared in front of me. It was a continent with cheese. “Who do I pass this to?” “Oh, that’s for you!”. Ah, well, I was consigned to a huge first course again.

The lasagna was simple and delicious. Noodles, cheese, sauce, and shredded pork. The tomato sauce was spectacular.

Around the table there was a bottle of Pepsi and a huge old glass bottle of 7-up containing wine. I made the mistake of having a little bit of that wine- perhaps the recycled container was insufficient warning.

Italians don’t dick about with wine. Refined, light flavours are expensive, and if you’re going to serve a lot of wine, you’re going to want to look a little bit more towards economy. This was a harsh, strong wine, a lot more like a punch to the cojones than the lighter wines that I’m used to drinking. Hoo, boy.

Halfway through my lasagna, out came some bread and meatballs in sauce. No butter or margarine for that bread- it’s for soaking up sauce! I downed a few of the meatballs and soaked the bread in saucy goodness. This wasn’t a soft bread, either- it was a hefty roll, something that could stand up to the saucy onslaught.

I finished the lasagna, the meatballs, the bread, and the wine. I felt like ringing a bell- Round One was done, I could retreat to my corner and catch my breath a little bit. Avoiding a second helping of lasagna took some emphatic hand waving at Rosa, though. She’s legendary for her ability to get people to eat. One time, my mother was talking with Vinny, fork-in-hand, and Rosa whisked the fork out of mom’s hand, stuck a cutlet on there, and put it back, all in one smooth motion.

That certainly wasn’t it, though. It was time for the second course. Out came breaded pork cutlets, breaded and fried zucchini slices, more meatballs, pickled peppers, a tomato-and-cucumber salad and a more traditional leafy-green salad- and not in small quantities, either. Vinny’s father pointed at the salad and proudly exclaimed that it was from their own garden.

I happily loaded up a full plate. Everything was delicious.

As my plate was finished, the process of clearing the table commenced- this wasn’t actually clearing the table so much as Vinny was inspecting the various plates of food and trying to find takers. “Hey, Curtis, one more cutlet?” “How about you, John?” “Hailey? Another cutlet?”

Once it was concluded that nobody could possibly eat any more, Rosa brought out a melon cut into very large wedges. Dessert! I downed a wedge- I’m not usually a melon fan, but it’s nice after a big meal like that.

After everybody had eaten a wedge or two… Rosa brought out more wedges. The other half of the melon needed to be eaten, too!

At this point, we’ve all been eating and talking for a couple of hours, now. As a cap on the evening’s meal, there was espresso and Rosa’s home-made ladyfingers. One dunked in the other makes for some serious awesomeness.

Thus concluded the meal. I sat on the couch and finished off the rest of my 363 marking.

So, now we come to the other meal that I had just last night. It was my dad’s birthday, and we wanted to go somewhere nice- so out to the Olive Garden.

The Olive Garden is a bit of an anomaly- a new class of restaurant that’s sprung up fairly recently- the higher-grade chain restaurant. Despite the fact that Olive Garden is a enormous continent-spanning chain, somehow they manage to make every restaurant worthy of a star or two. Somehow they’ve managed to find the elements that make a one or two-star restaurant successful and institutionalize them.

The place was ostensibly ‘Italian’, although after my Saturday experience, the whole place had a sort of Disneyland-veneer to it. “This is what you think Italian restaurants are like”.

The service was quick and responsive. Dad and Tracy tried a couple of wines and eventually ordered a nice Zinfandel. I had my trademark iced tea. Off wine for a bit (remembering Saturday), I had a sip of wine and it was pleasant, layered, and light. I was a bit perplexed that they had ordered wine before even deciding what to eat, but Dad and Tracy love their reds and it wouldn’t have made much of a difference anyway.

We had an appetizer before dinner- deep fried zucchini and stuffed mushroom caps. Then, salad and bread sticks- the sticks fresh out of the oven, buttered and garlic salted.

For dinner, I had braised short-ribs with asiago-stuffed tortelloni. Dad had something-something-shrimp-something, and Tracy had a garlic-herb-grilled chicken with alfredo .

My meal was delicious- I had read Bill Buford’s “Heat” earlier, and I had been jonesing to try some braised short ribs. The asiago tortelloni complemented it perfectly, and after cross-sampling, we all agreed that I had picked the best thing on the menu out of the three of us.

We finished up and went home.

Now here’s the thing that’s bothering me- the Olive Garden had food that was every bit as delicious as Rosa’s- but it just wasn’t the same, not even close. The Olive Garden chefs are precise and have managed to really get a handle on that fusion of French and Italian culinary technique that so defines the “Italian” food genre. There wasn’t any sort of personality or genius to the food- I’m sure the recipe that I ate was the same thing that I could get at any Olive Garden across the country- but the execution of the mass-produced meal that I ate was perfect.

The Olive Garden meal was complex, well-orchestrated, precise, and soulless. Rosa’s meal was simple, traditional, and delicious. It was loud, and a Canucks game was playing the whole time in the background.

Olive Garden has managed, it seems, to completely divorce Italian food from Italian culture. Not that I don’t think the meal was delicious- I’d recommend it to anyone. I’m just a little nervous at calling it “Italian” food- it’s really more “Italian-themed” food, like Canadianized Chinese food or the Tex-Mex we call Mexican.

To get the full experience, you really need to find a little old Italian mother in Vancouver. I’d give her four stars if I could.

Bon Appetit!

I’ve been with Dreamhost for about a year now, and soon I’m going to be with them for a second year. I think, though, it might be time for me to move to a new host, soon. Maybe 8 months from now. Not that I haven’t been happy with DreamHost, but there are a few things that I want to fix.

1. Occasional Bouts Of Slow 
When it comes down to it, sometimes my blog is just slow. REEAL slow. It’s unprofessional, darn it.

2. Everything Is Automatic 
The “One-Click Installs” make me feel like a retarded person. I like being able to install new instances of Wordpress in One-Click, and the One-Click upgrades are nice, too, but they still feel too easy. I want some difficulty. I can handle software installation on my own, and it makes me feel more like I can control my destiny.

3. The High-Capacity Is Useless 
Yay, I have tonnes of bandwidth and disk space. With the speed and thin-pipe that I seem to be stuck with, though, filling that disk-space is a non-issue and using that bandwith doesn’t seem too much of a problem either. What’s the point of ridiculous amounts of storage and bandwidth if you can’t even come close to using it all?

4. More Control. 
When it comes down to it, I want to experiment with Ruby On Rails, with Django and Python, with Lisp and whatever the hell framework works with Lisp, and everything else out there. I’m young and promiscuous (at least when it comes to new technologies) and DreamHost is just holding me back. I want to run my own server! Oh, I know, if *I’m* in charge of my own server it’s going to break way more often and be filled with security holes like some sort of swissed-cheese, but it’s worth it for the freedom and knowledge I’d gain.

So, that’s three reasons. And then one more, fourth, reason.

I’ve been recommended slicehost for a good solid VPS, so I’ll be taking a look at that. Later.

Thing is, though, I could just run a dev-server on my home computer, and anything I want on there. I don’t have anything yet that needs to be deployed on a better server. It can wait.

About 2 months ago, I was curious about how much money could be made using Google Ads, so I installed it.

Now, let’s quickly take a look at my site’s audience. I get about 30 people a day arriving at my site the traditional way. As for RSS, well, I haven’t installed Feedburner and thus have no information whatsoever about who reads my RSS feed, but I’ll assume it’s a million bajillion people for the sake of my own ego. I also, occasionally, get moderately high on programming.reddit.com, if anything because tonnes of people disagree with everything that I’ve ever said. Over the last 2 months, I’ve had about 6000 hits to my site. In that same period of time, I’ve had exactly 2 people click on the Google Ads. Both of those people were (unfortunately) me, curious about something that appeared on one of my own ads. “What? An awesome garlic bread? Hells yeah I’m interested in that!”

This has earned me exactly $0.26. At this rate, I would need over 200,000 visitors per month to my website in order to pay for the basic web-hosting package that I use.

This is, of course, an entirely unsupportable business model. Fortunately, it’s not a business for me, it’s a hobby- but if I were planning on an ad-supported project, I’d clearly have to re-evaluate my strategy. Let’s look at some of the reasons my Google ads aren’t making any money.

1. Nobody Pays Attention To Google Ads

Google Ads are the most ignored things on the internet. When I was applying for a job at Research In Motion, I couldn’t find some critical aspects of their job-application GUI because they were in a box, in big blue text, with smaller gray text underneath. They looked just like Google Ads and I didn’t see them because I’ve trained my mind to studiously ignore anything that looks even remotely like a Google ad. Most experienced internet users either have a service blocking out the advertisements or just pay zero attention to them.

2. Google Ads Don’t Pay That Well

When it comes down to it, Google Ads are an easy-way-out, an automatic advertising system. A better alternative might be, say, Project Wonderful, a boon to the Web-comic world. Perhaps some sort of affiliate program with one of the many T-Shirt vendors, or heck, even hawking DreamHost accounts. I know I’ve recommended a few people get DreamHost accounts- I could be making money from you guys!

A much more profitable system is where you individually interface with advertisers to offer more specialized content that might actually be of interest to people on your website- Penny Arcade is able to make a lot of money just by being very selective about their advertising, to the point where getting an ad on their site is a huge recommendation that a lot of people will take very seriously. JoelOnSoftware and TheDailyWTF both sell advertising space to companies looking for qualified tech staff. Specialized advertising requires, however, a large and very focused audience.

3. The Ads On My Site Don’t Stand Out 
I’m more concerned with not irritating people and maintaining unity-of-design than I am of, say, ad revenues. I don’t think this is too much of a problem, though- thanks to Item 1 up there, my whole site could be Google Ad and few would notice.

4. Redditors and Diggers don’t click on ads. 
People arriving from link-aggregators are not exactly model netizens. They come in to your website, make a big mess, use up all of your bandwidth, then leave. They don’t stick around long enough to get to know the site, they don’t post comments, and they never click on ads. The only way to keep people from Reddit or Digg at your site is to consistently offer interesting articles - Coding Horror and XKCD make it to the front page of Reddit on a regular basis just because of their name brands and consistently high quality. Of my 6000 hits, 5000 of them stopped by, maybe read half of the article that I posted, and then disappeared, looking for a something new and interesting somewhere else.

This all leads me to my conclusion: In order to make any sort of money from a website, you need a large, tightly-focused audience, and well-thought-out advertising. Otherwise you’ll end up with exactly 26 cents.

Well, Apple has done it again. They’ve released something new and amazing. Something that is a triumph of engineering. Something beautiful and perfect in it’s own little way. Something that I do not want.

Yes, if you’re an internet denizen, you’ve heard about the MacBook Air seventeen times over already by now. For those of you who’ve not heard of it, it’s Apple’s new contender in the ultraportable arena. The MacBook Air is ridiculously thin and light (a mere 3 pounds, and thinner than a finger), as powerful as a traditional ‘heavy-as-shit’ laptop, and pretty inexpensive for an ultraportable. Cool. I’m drooling over it right now.

They didn’t have room for a replaceable battery or an optical media drive. Or a firewire port. Or an ethernet port. Or more than one USB port. But being that it’s an ultraportable, it’s not the sort of thing that really is supposed to stand alone- it’s a supplementary computer, meant to travel with you and then sync with your home computer. It’s for the type of Apple consumer that doesn’t worry about money- the ultraportable market, really.

The thing is, though, the ultraportable market has just recently been turned completely on it’s head by the Asus Eee PC. For 1/6th of the price of the $1800 Macbook, you can get a tiny Eee PC. It has a small keyboard and a small screen, but thanks to it’s portability and low pricing point, thousands of people are making it their mobile PC. It’s widely considered to be a well-designed little fellow.

The big selling point of the Eee, though, is the price tag. Most of us cheap CS types are used to having just enough money for one computer- so we get a hefty-bag low-end Dell laptop, enough to fill our portable desires while still functioning acceptably as a home computer unit.

Case-in-point, my current layout, a Compaq Presario V6000. It was on sale last Christmas for Boxing Day, a steal at $599- for a 1.7Ghz Celeron with 512Mb of RAM and 100Gb of hard drive space. At the time, computers with similar specs were going for $899+. Currently, 100% of my computing tasks are accomplished on said laptop, even though it’s a hefty 7lbs to lug around with an abysmal battery life (it’s down to about 10 minutes) and little upgradeability (okay, now it’s 2Gb of RAM, but that’s about it.)

Now, thanks to the Eee and the low price of most towers, we can rock a powerful home system and a highly portable scaled-down system, all for under $1000.

Recently, I’m involved in a new project. I’m calling it “Project Don’t Die Before I Reach The Age Of 28?, or “PDDBIRTAO28? for short.

The real purpose of the project is to try to kill some of my more egregiously unhealthy habits. Convenience-store corn-dogs? Yeah, that’s one of them. This project isn’t out of any real desire to be more attractive or fit- like I said before, it’s out of a desire to outlive most household pets.

The first phase of my project has been the consumption of vegetables. This isn’t like some sort of serious mostly-vegetarianism where I consume a little bit of chicken once per week and abstain the rest of the time. No, this phase is merely “eat vegetables”. Shockingly enough, I’ve discovered that my diet is almost completely dominated by meat, fat, and starch. Spending time at Kristen’s house doesn’t help, either- Kristen’s mom is a cook in the good old-fashioned “Meat and potatoes” sense. SFU is no better, being that my two biggest lunch orders are capicolo panini and sushi.

This has involved eating vegetables at home- the sort of vegetables one finds in the fridge, celery, carrots, cucumber, tomatoes, that sort of thing. Often with dip, or tzatziki, or salt and pepper, just to keep them from being healthy. They’re more delicious that way. Quiet, you! Also, occasionally, packing vegetables with me and snacking on them at school.

The thing about it, though, is that while vegetarians often comment about experiencing gastrointestinal distress when faced with a sudden influx of greasy meatiness, I’ve experienced a similar set of recent problems with the vegetables. I mean, I’ve felt better than usual, but I need to eat three times as many vegetables to feel full- and then way more often. On top of that, all of this sudden foliage is messin’ with my stomach. Ah well, I’m sure it’ll be good for me.

I know at least two of the people who read this blog are vegetarians-or-close - and I’m sure 100% of the people who read this blog eat healthier than I do. So.. how do you work more vegetables into your day-to-day schedule? How do you make them taste less like watery fibrous chunks or bitter roots?

I was having a chat with Angelina yesterday, and she’s got a new project in the works- she calls it “Bacon Breath”, and it is a fantastic thing that makes me happy.

For Christmas, Angelina was signed up by her fiancé for the “Bacon Of The Month” club. She also got robot-parts, which makes that the most kick-ass Christmas gift anybody has ever given or received, bar none.

Now she resolves to fry and eat her monthly bacon, then describe it to us in glittering prose. On top of that, she promises that she will hunt down and consume other baconly treats for our amusement. She’s on the lookout for talented bacon correspondents, too, so if you’re in the mood for getting your bacon on and writing about it, she’d be glad to edit and aggregate it on her site.

It’s a bacon bacon revolution! Catch bacon fever! You’ll pay for the whole seat but you’ll only need the edge!

I wish Angelina the best of luck in her endeavor. Godspeed, Angelina, godspeed.

Though my time spent fiddling with assorted web technomologies, the three most common things anybody has ever wanted to put up have been blogs, e-commerce, and content-management-systems. It’s always been those three things, again and again, ad infinitum.

Now, I’ve spent enough time fiddling with Wordpress to really know my way around it- I’m comfortable with it, and at least familiar enough not to step on my own toes. It’s a good, extensible blogging package. If I were to want to do some major work around it, I might want to start with a more sparse package, but for what it’s for, Wordpress does nicely.

As for commerce and CMS, though, I’ve never really encountered anything that I’ve liked. In the e-commerce packages that I’m familiar with, OsCommerce is a mess, ZenCart is little better, and there are companies upon companies selling crappy midmarket solutions for commerce that I don’t even want to touch.

For CMS software, I’ve encountered Drupal and Plone, both of which are not great fun to work with but not too terrible either. I haven’t had a lot of experience with either, though, really.

To here’s my question to you- what the hell does one use for commerce and CMS that doesn’t suck? Flexibility and skinnability are big ‘yes-yes’ factors for this sort of thing, as well as security and some amount of ease-of-use.

Dom? Rob? Anyone?

I woke up at 7:20, to the harsh ring-tones of my cel-phone’s built in alarm clock. The room I sleep in at Kristen’s house has no windows, nor any real connection to the outside at all, so it was pitch dark. I suspected that I might be eaten by a grue, so I felt around for my glasses and staggered outside to hit the inconveniently located light-switch.

A mere 4 hours of sleep was by no means enough, but at least I had 2 new blog posts- a Monday and a Tuesday- boxed up and ready. While I hadn’t gone out of my way to tell anybody about it, Monday was my ‘tutorial’ day, and this time, I had written a tutorial about pasta sauce.

Having donned my excessively large watch, man-ring, necklace, and four-day-old clothing, I wandered upstairs. I woke Kristen up just long enough to give her a kiss goodbye, and then came downstairs and started packing up to go. Laptop? Check. Various cords? Check. Spare clothing? Check. A couple of scraps of paper and a pencil? Check.

The bus-trip to SFU from Kristen’s place was seamless- a big difference from my daily Cloverdale-to-SFU exodus. I actually arrived early, for once, and decided to check to see if the Common Room was open.

The Common Room is a little room located in-between the CS Labs and the Renaissance Mini-Coffee shop in the Applied Science building. Managed by the Computing Science Student Society, the room has the cheapest pop and photocopies on campus, as well as a big group of cheap, oft-vandalized couches and usually a crowd of CS students occupying said couches. The wave of recent vandalisms has forced the doors to close over the winter, so I wasn’t sure if I had arrived too early on Monday to actually venture inside.

It was open- oh, and hey, Phil! We chatted a bit about the course we were about to take, Intro to Probability and Statistics, and went on a short quest for supplies. Then, to class!

Robin Insley is an older fellow with wispy whitish hair- if you’ve been at SFU for any length of time, you have had at least three professors who look just like him. Because STAT 270 is one of those low level math courses that everybody and his grandmother has to take, he had the usual math-teacher “We will take no shit from you, these are the rules and regulations” spiel to give out in class. This was a 45-minute-long litany that I had already heard a thousand times before. I broke out my novel and read a chapter or so- at this point Bill Buford was still apprenticed to the Tuscan butcher, and hadn’t returned to New York, yet- and handily ignored the bulk of the lesson. The only part that really stood out as ‘important’ was that Prof. Insley wanted a typed cover letter on any assignments.

Having maybe 10 minutes left to cover any actual information, we started on a quick overview of terminology. Statistics estimate parameters. The mean of the sample estimates the mean of the population. The standard deviation of the sample estimates the standard deviation of the population. Here are some greek letters.

Okay, finally that’s over. Leave the course and SWEET MERCIFUL BAGUETTE WHAT THE HELL? The AQ was as busy as a fall afternoon and it’s only 10:30 in the morning! Elbowing my way through the crowd, I made it to the Common Room in one piece. Ahh. Some people I know were there. I went with my standard greeting of holding my arms in the air and bellowing names. JEN! BENTON!

Some socializing occurred. “Are you in 376? -Everybody- is in 376.” There were way more new people than I remember seeing in the common room. Most of my friends are graduated or close, and the longer I spend at SFU the fewer familiar faces there are.

I took the opportunity to out and nab a ham panini, some tomato bisque and a fruit salad at the Renaissance. $9. I noticed a new ’sandwich station’ in the back, with a Subway-like menu at slightly higher prices. At some point, I’m going to have to try their meatball sub.

The panini is good- it’s like someone took a ham sandwich and Italianed it up a smidge with some spices and grilling. The tomato bisque was terrible. The fruit salad was the usual huge chunks of cheap melon, spiced up with the occasional tiny bit of kiwi or strawberry for an excessive price. (About $4) I bet I could make a better fruit salad at home, and cheaper, too!

Okay, off to 376, “Tech Writing and Group Dynamics”. This time, I’m with a roving parade of friends who I’m taking the course with. Unlike the earlier STAT course, this is a higher level Computing Science course- which means both that the class is much smaller (me and my compatriots make up about a third of the class) and that we are in the tiniest, most obscure corner of the AQ that we can be fit in.

The professor, Ted Kirkpatrick, was not at all what I was expecting. Jovial, skinny, balding, with a cardigan-sweater and pressed pants, he didn’t actually seem like most of the CS professors I encounter at SFU. He seemed a lot more like my English teacher from high school. Ted was a campus favourite, one of the profs famous for delivering a solid course. I asked him for his autograph. “I only sign pictures”, he responded. A quick thinker- good.

The first 20 minutes of the course was… a writing exercise. I haven’t done actual work in a lecture since grade 12! Once again the high-school English teacher flashback hit me. It was a free form, and faced with the tyranny of the blank page and no ideas I stared off into space a little bit. Maybe I should go into one of my many tirades about how Powerpoint Lectures suck? Nah.. a description of my day thus far? Too boring. Perhaps a couple of paragraphs about not having anything to write about? Not original enough.

A-ha! Inspiration struck me and I started laying the groundwork for the many excuses I planned to use for my lateness/absence/late-homework over the course of the semester. I have many elderly grandparents and several rare diseases, I claimed. My handwriting was messy, and unprofessional - I’m happy I’ll be able to write anything further with a computer.

The rest of the lecture was a lecture in the traditional sense- some set-up for the course and maybe a smidge of lecture material. Tech Writing and Group Dynamics is, it’s made clear, the dumping point for a mishmash of things that the CS professors think should be taught to CS students- but not by *them*- and the bits that are too short to be courses on their own. Prof. Kirkpatrick makes it clear that while that’s the intention of this course, for all intensive purposes this is a technical writing course and the aim is to improve our collective ability to make words go on paper.

We also have to turn in a one-page written ‘thing’ every class, three times a week. For me, being as I have a blog that I’m technically supposed to post in 5-times-per-week, I can just discard two posts that are too long, off-topic, or polemic and hand in the rest. Great.

We dispersed. On the way back to the Common Room, I saw Steve- “Hi, Steve!” I said- and then “Bye, Steve!” as I kept walking towards the Common Room. I was a bit too smelly and tired to want to have a conversation with him at the time. In fact, the thought of a nice nap was beginning to seem like the best possible thing I could do. (Four hours of sleep, remember.)

I returned to the common room and nabbed a spot on the couch, not really talking or doing much for the next hour. A little bit of spacing is always good for the soul.

The next course was CMPT 384, “Symbolic Computing”. Now, in my head, ’symbolic computing’ is synonymous with ‘functional programming’, but the first little bit of the course made it clear that that was not (in fact) what I was learning. Symbolic computing is (however) closely tied to functional programming in that symbolic computing is best expressed through functional programs.

The classroom was located in what could only be described as the University’s basement. The ceiling was low, there were lots of tubes and vents, no windows. The room was very small and warm and painted in the sort of bright beige that institutions use when they no longer care what you think about them.

Here’s the problem- Tony Dixon is a good professor. He delivers a clear, on-topic lecture that’s well organized. Somehow, however, some combination of his monotonic voice, slow presentation, and the dry content of the lectures actually knock me unconscious. My notes for 384 are significantly uglier than those for Stats or Tech Writing because while Dixon was talking I would actually fall asleep *while writing*.

I hoped that it was the warm room and the lack of sleep that did it to me- the last time I took a Dixon course I was taking 2 math courses and chronically low on sleep anyways, and I assume I’ll be able to perform more efficiently this year. If I can’t stay awake through his next few lectures, I’m going to have to switch 384 with 383- an almost-equivalent course with Frank Burton - Who, while verifiably insane, is at least a respectable lecturer. Instead of getting to program in glorious Lisp, however, I’d be using Prolog.

I staggered sleepily out of the class when it was done. I stopped at the Triple O’s, thinking a burger would be a nice way to finish my day, but eventually took off when I noticed that the line wasn’t moving at all and the person working the till at the front seemed to be having a chat with another employee while a third person stood in the back and looked confused. Such efficiency!

On the way back to class, I encountered Dylan Innes, co-cartoonist, film-major and generally funny man. Time for the arms-up signature greeting. DYLAN! He was walking about with his brother, and the three of us went to the SFU pub for a beer and some nachos.

Apparently, the SFU Pub has recently raised prices again, in some sort of clearly business-savvy attempt to keep from ever making any money. Dylan sprung for some $12 nachos, and I bought a $15 pitcher of beer (on special!). Drinking and talking ensued- he wants to start really building a community of cartoonists around his website, and he wants me to.. well, make that possible with his website. Maybe if I have time in-between all of my other stuff…

We then ventured to the bus-system and I bussed home. I was working on a nice buzz with the half-pitcher of beer I drank, (I’m a lightweight, so what!) and very tired. I finally arrived home, let our new puppy Maya out for a pee, and went upstairs for a much needed shower and change of clothes, followed by a nap which ended up lasting about 12 hours.

Just a few days ago, I received an e-mail from my STAT 270 professor, containing course notes. These notes were, painfully, sent in a format only really readable by the dreaded Word.

Now, when I got a new computer, I never bothered to install Word. I’d have to steal it, and that’s a big pain in the ass for the fairly negligible benefit of having Word installed on my computer. While I’m technically the family’s go-to-guy for poached software, I’d prefer to only recommend the sub-legal stuff when the Open-Sourced alternative is a difficult, hacked together nightmare- say, Blender or The GIMP.

Thing is, with Word, there are alternatives that are actually very good. I’d like to direct your attention to OpenOffice. OpenOffice can do just about everything that Word can. It quite notably does not cost a couple of hundred dollars. If you create an OpenOffice document, you can be quite secure in the knowledge that anybody else who owns a computer will be able to open it and view it properly, as long as they have an internet connection and a little bit of guidance.

OpenOffice is one of the heavy-hitter technologies that comes bundled with Ubuntu - for a desktop system, having a complete office package right out of the box is one of the major selling points of our Linuxy pal.

It’s not ugly or difficult, either- in fact, the OpenOffice utilities are quite happily very similar to their Microsoft Office counterparts- in some cases more powerful. For scripting, OpenOffice interfaces quite happily with Python, the best damn programming language ever.

Now, in my understanding, everybody has Word. If you send someone a Word document, they are almost guaranteed to be able to open it. If they have a Mac they might still have Word. If they don’t have Word, at least Wordpad will come to the rescue and deliver a horribly mangled version of the original file. Word is a pretty safe format to send people documents in- they’re almost always likely to have it.

OpenOffice, however, is an even safer choice- anybody can get a copy of OpenOffice for free. It runs on Macs, Windows, Linux, the works. Many governments are actually switching their documents to the ODF format from DOC and RTF- the open nature of the file means both that it’s more accessible to the public, and less likely to become obsolete and impossible to open over time.

So.. uh.. yay OpenOffice.

So, given all of that jerkery over OpenOffice, the real thing I was wondering was.. why weren’t the notes prepared in some sort of TeX? Even LyX! I mean, it’s a math professor, right? Math departments and LaTeX go together like peanut butter and bananas. TeXy documents are just really good for that mathy stuff- and it produces beautiful PDFs.

I’ve come to associate TeX documents with academia, and the lack thereof- especially for the sort of document that looks like it was built with TeX in mind- seems odd. Sections, subsections, formulas upon formulas- if you’re doing that stuff in Word, you’re doing too much work! It’s already been implemented better somewhere else!

Okay, I am full of lies. I advertised ‘the ultimate pasta sauce’, but given that ‘ultimate’ means ‘final’, for it to really be the ultimate pasta sauce it would have to be the last pasta sauce ever. This would cause a notable amount of pain and suffering in the universe and would best be avoided. Instead, I wish to speak to you on the topic of delicious pasta sauces- namely, *MY* delicious pasta sauces, and how you, too, can be a man brandishing a bowl of delicious red goo.

The thing about pasta sauce is that it can be described as ‘free-form’ food. You can toss just all sorts of things in there. Be creative. When I first asked my mom for the recipe, she gave me a kind of loose description of how the sauce would go, and I was baffled- what do you mean? I need a hard, codified recipe, here! With.. measurements, or something!

After getting mom to write down the recipe with some sort of precision, I made it- almost to the letter. Having done so, however, I started to understand why my mom was so vague with the recipe the first time around- it’s so hard to screw up that I was afforded a tremendous amount of leeway with ingredients, cooking time, anything.

Here’s the recipe.

First, you need a big-ass pot. Thicker pots are less likely to burn the sauce and deliver more even heat. That means, you don’t have to worry about stirring as much.

Start with vegetables. Good vegetables include carrots, celery, onions, garlic, diced spinach, peas, and just about anything else that’s green and even remotely vegetable-like. Save the tomatoes for later. Give the veggies a rough dice- nothing should be bigger than about a d6.

Toss some oil in the pan, and on lower-medium heat start cooking the vegetables, starting with the denser-and-larger-ones and gradually moving towards the floppier-and-smaller-ones. “How long should I cook everything for?”- it’s not an exact science, just cook it for.. some time. Like, 5 minutes or something. That seems like a reasonable amount of time. As long as everything isn’t rock hard or burned to a crisp, you’re pretty much in the clear.

When you feel like you’re done, or if something starts to burn and you want it to stop burning, it’s time to move on to the next stage: Meat. Now comes the question: What sort of meat goes in the sauce? Well.. what sort of meat do you have? You’re going to be cooking this thing for a couple of hours, so you could toss just about any ol’ thing in there and it’ll probably do fine. I like to take spicy sausages or chorizo and squeeze out the innards, maybe mix that with some ground beef or something. The process of cooking a big tomato sauce is very close to that of braising, so if you’re looking to leave the pot on for a while you can toss some tough cuts in there and just cook ‘em until they fall apart. This is, quite fortunately, delicious. So, for the meat stage - anything that you feel like putting in there is fine.

If you’ve got a bigger cut of meat, say, some chuck steak, you might want to crank up the heat in a separate pan and sear the outsides before you toss it in. You can cube it up now, or you can fish it out later, shred it, and toss it back in.

Toss your meat in the pot. Wash your hands- you’ve been touching raw meat and food poisoning is no fun for anybody. Heat it up a little, get some brown going on in that meat. There will be sizzling, and joy. The meat’s going to cook in the sauce for a long time anyways, so it’s not imperative that you do a perfect job, here, but a good brown coat makes for added deliciousness. If you’re working with a lean meat, you won’t have to drain the fat, but if you’re working with something fattier, you might consider tipping the pot and ladling out any accumulated greasiness.

After this, you can add all of the rest of the ingredients in any order without worrying. If you put the tomatoes in before the pasta, or the pasta in before the tomatoes, there will be no vile consequences. These operations could even be executed in parallel if that’s what floats your boat.

Now you’ve got a pot with some meaty vegetableness. Nice work! Now, it’s time to add some tomatoes. You can add chopped fresh Roma tomatoes, here, or canned plum tomatoes, or hell, even grape tomatoes if you’re feeling silly. Don’t be stingy, as tomatoes are a prime source of deliciousness. Try not to toss anything in there that’s too much bigger than ‘bite-sized’.

Now is also a good time to toss in ‘the spices’- to call it a ‘pasta sauce’, you need to add, at the minimum, basil and oregano. If you’re using fresh stuff, try not to get too much stem in there- a big chunk of stem in your pasta is bad times. Also, if you’re using fresh herbs, use a *lot*- the flavours aren’t as condensed as they are in the powdered and dried spices. Parsley, sage, rosemary and thyme are great additions, too. Don’t be shy with the spices- big handfuls are appropriate, especially in the case of poor parsley with it’s mild flavor. A couple of heads of roasted garlic, removed from the skin, makes for added deliciousness. While adding spices, you might be overcome by a desire to just throw them in the pot and yell “BAM!”. You can’t resist it and you shouldn’t try.

What’s next? Any leftovers you don’t want to eat? Bright ideas? Clever ideas for last minute additions? Forgotten vegetables from earlier? Now is the time to toss them in. Thai Chili Garlic paste, for example? Good stuff- adds some serious kick to the sauce. Maybe some taco beef from that burrito you made yesterday? A little less appropriate, but still fine. A live kitten? Hairy, maybe, but full of flavor.

Finally, toss in some tomato paste, about one big can’s worth, and.. a whole can of pasta sauce. It may not be the authentic way to go about it, but it’s got about the right consistency to make the pasta sauce seem ’saucy’.

Now, turn the heat way up. You want to see bubbles bubblin’ to the top. Once you’ve got everything to that point, turn the heat down to low, toss a lid on top of the whole process and stir every 10 minutes or so for the next couple of hours. Longer cooking times translate into more delicious sauces, but if you’re in a hurry the whole thing could be done in about an hour or so.

And now, for the important topic of ’sauce thickness management’. After you’ve put all of the ingredients into the sauce, everything is going to be a little on the soupy side. Hours of cooking will thicken the sauce. If you find your sauce getting too thick, it’s time to add some liquid. I recommend Vitamin Wine, preferably something red. If the sauce is too weak and liquidy, cook it longer. This could theoretically take several hours, so fire up some Halo 3 or some good T.V. and stir during commercials or between games. Or not, the sauce isn’t exactly delicate.

There. You’re probably drained, at this point. Instead of the almost ridiculously easy process of pouring sauce out of a can onto some reheated noodles, you’ve blown several hours on a time-consuming-but-not-too-difficult sauce. Was it worth it?

Well, yes. For one thing, the sauce kicks ass. It’s rich and meaty and delicious. For another thing, you can now Tupperware up the sauce, and freeze or refrigerate it. Looking for a meal? Boiling noodles and tossing some microwaved sauce on them is dead easy, and you’ve got enough sauce in the fridge to keep you going for a good long time. You can pick a Sunday, make huge pots of sauce, and be set in the sauce department for months. So, easy, delicious meals. Finally, it is a serious win in the cost effectiveness department. Noodles are dirt cheap, and for maybe $30-40 in ingredients, you now have many delicious, hearty, proteiny, vegetably meals lying ahead of you.

Hello, again, assorted readers!

*crickets*

Readers?

Are any of you still out there?

Damn, leave for a few weeks and the whole internet leaves with you. Well, I’m back! The semester has begun and I’m once again committing to a ridiculous schedule, so as to entertain you with posts, tutorials, clowning about with pies, hilarious links, food and beverages, and the ever-popular ‘etcetera’.

And for the afore-promised hilarious link, we have the Merrill-Howard-Kalin show! Who said that the mentally retarded couldn’t host a wicked awesome cooking show? Automatically, by watching the show and laughing, you become a horrible person- but that’s okay. You only have a few more days to catch this one before it gets taken off the internet (It’s already been cleared off ‘The Tube’) so… take this opportunity to chuckle at those less fortunate than yourself.

Toodly pip, readers, and away!

Okay, I’m getting started on a new project, here- in between my witty (incoherent) ramblings, I’m going to try to toss in the occasional useful tutorial on a variety of topics that have already been covered over and over again on the internet.

Today? Getting started with Python. As a quick intro to what the hell I’m talking about, Python is a very popular and powerful scripting language. Thanks to the fact that Python is a slim, concise language, with a huge community supporting it and a lot of libraries, it’s a great choice for a first programming language.

So, at the beginning of a CS degree, you’re going to get bombarded with a bunch of boring hocus-pocus about algorithms and pseudocode. Now, of course, this is all important stuff… but it’s all boring, so let’s get right into the meat and bones of programming.

Which, of course, requires that you have Python installed on your computer. Let’s get you started. First of all, let’s determine what operating system you’re running. Look at your screen- is it bright blue, with various error messages? You’re using Windows. Look again- Do you suddenly feel like you’re not nearly trendy enough, and that you should probably buy a scarf and beret? You’re using a Mac. Finally, if you’re looking at your screen and you are filled with waves of disdain for the entire human race, you’re probably using some flavor of Linux.

For Mac users, well, I can’t help you. I don’t have a Mac. Should you require a more comprehensive tutorial, please pony up the $1200 required for me to get my grubby hands on a MacBook. Edit: Okay, I bought myself a MacBook. Good news, everyone- Python comes pre-installed on your Mac. To get started, open a Terminal (you’ll find it in /Applications/Utilities) and type in the word “python”.

For Ubuntu Linux users (i.e., Ubuntu users), you’re.. well, you’re all set. Python is automatically part of every Ubuntu installation. Good on you! To get started, open a Terminal and type in the word “python”.

For Other Linux Users .. well, you’re running Linux on your own. I’m going to assume that you’ve got your shit together.

For Windows users, the process is quite simple- go to python.org and grab the Python 2.5.1 Windows Installer. Don’t go to python.net, that’s not what you’re looking for. Especially don’t go to python.com- that’s just porn, the chewy caramel core of the internet. If the Windows Installer has a higher number than 2.5.1 (For example: “2.5.2?), raise your arms in the air and cheer thusly: “Woo”.

Having installed Python, you now have a “Python” group in your Start Menu, with a variety of links- IDLE (Python GUI), Module Docs, Python (Command Line), Python Manuals, and Uninstall Python. The next step is to uninstall Python. (No, it’s not, I’m full of lies.)

What you’re going to be using is IDLE- a lightwieght Integrated Development Environment. An IDE is a tool to make programming a little easier.. and Python was inspired by Monty Python.. one of whom is Eric Idle.. so.. yeah. There you go. I have yet to see anything in the Python world named after John Cleese, but only time will tell.

So, you’ve started IDLE and you’re faced with some version information, some unwanted license information, and a warning about personal firewall software, followed by some more version information and finally the handy command prompt. “>>>”, it goes. “>>>”. Just.. taunting you. Quickly, man, you need to show it who’s boss! Tell it who’s boss!

I found this classy little nugget in the codebase for a tool that I’m maintaining. I laughed, and laughed, and then called my coworkers over, and they laughed, and then got permission to post it on my blog.

It even has a funny punch-line at the end!

My website is getting pounded at CommandShift3.

If you’re a redditor, you’ve probably already seen this. CommandShift3 is like a Hot Or Not for websites- you submit your website title, it takes a picture, and your website is run against others in a series of one-on-one preference tests.

I thought I’d toss in this site and chownow.ca for good measure, to see how my design skills stack up. It came in about as I’d expected- not great, but better than absolutely abysmal. I like to think that I’m improving over time- chownow.ca is more attractive than this site, and my next site (theoryBox.net when it goes up) will be even more attractive still. Or not.

Oh, as a bonus- my site looks much uglier in Safari and Internet Explorer. I can chalk that one up to laziness- whenever faced with a strange IE display bug, it was just easier to make the offending element disappear (no search for you, Internet Explorers!).

Thing is, I don’t want to take the easy way out and just toss lots of gloss, sans-serif, rounded corners, and drop shadows on my site. It’s like decorating your house with stainless steel and dark woods - it’s popular now because it’s faddish, and it looks pretty good even if you don’t know anything about design, but it just seems like a lazy solution. Great designs are the ones that do strange things but still end up being visually balanced, well-laid-out and interesting.

On a side note, CommandShift3 is clearly doing the “Agile Web Company” thing, as evidenced by the fact that the site’s either exhibited bugs or broken bits at least five times since I stumbled upon it.

Here’s something strange I found.

Here’s a video from Livevideo, and one from YouTube. You don’t actually have to watch the videos- they’re just more of the generic inane videos that you’ll find everywhere on internet.

What you’ll notice looking at the two pages is that they’re .. well, almost exactly the same. Now, I’m placing the blame squarely on Livevideo, here. The question is, why?

I mean, how did this get made? Did someone actually go to venture capitalists and angel investors pitching the genius idea, “Let’s just make YouTube”? Were they planning something better, but just failed to put it together right? Did someone actually imagine that just flat-out copying YouTube was a great idea that would make tonnes of money?

I mean, this one’s so painfully obvious, I don’t even think it’s necessary to point out Rule #6 of Ries & Trout’s “22 Laws Of Marketing”.

This is almost a Zango level of stupid.

If companies like this are getting venture capital, I’m curious how long web developers are going to be working in Aeron chairs before we’re back to flipping burgers.

I’m taking Computing Science at Simon Fraser University- it started as basic programming and then slowly became an in-depth look at how computers do the magic that they do, from the microchips to operating systems, and then a lot of more specialized topics, like compilers, graphics, sound, and tonnes of painful, painful math. Last semester, I took courses on User Interface Design (i.e. the parts of the program that you see), Networking, Data Structures & Algorithms, and next semester, I’m taking a course on Statistics, one on Technical Writing, and a third on Symbolic Computing.

Now an important part of all that is - while it helps you understand computers, the internet, how it all works and why - it doesn’t necessarily make you any better at working with those things- it’s just kind of a base to work from.

We’re expected to learn all of the *practical* stuff about computers on our own- how to program, how to develop software, how to do all of the myriad stuff that needs to get done to develop software well, how to set up websites, how to set up networks and keep our computers in pristine condition, everything. BCIT is known for teaching the practical stuff a lot more thoroughly, and sometimes I’m jealous of the BCIT students (but then again, I met Kristen at SFU, so no complaints there.)

The people who don’t amass enough practical knowledge to go into development go to grad school where they are paid peanuts to hyperspecialize in certain inconsequential computing tasks. Some people go to large companies where they are paid good money to hyperspecialize in certain less-inconsequential computing tasks - For example, I’m pretty sure there’s a person at Electronic Arts, whose entire job, day-in-and-day-out, is to find more efficient ways to render grass. Years of working as faceless, replaceable cogs in exchange for job security tend to melt souls, but on the other hand, it can pay really obscenely well.

Not only are we expected to pick up all of the practical stuff on our own, we are expected to specialize in certain skills and activities- some in C++/C#/VB/.NET/Windows programming, other people in C/C++/Python/Linux, some people become IT Guys or Quality Assurance Testers or System Administrators. Some poor bastards specialize in Java, but because it’s the language that everybody learns by default in University, Java programmers tend to be a very common, poorly-treated bunch. I got my start in Web Programming setting up my own website at curtis.lassam.net - simple, maybe, but the more I learn about web programming, the more it seems like I have a lot of learning ahead of me.

Once you know the basics, learning enough about a domain to get a job with other people in that domain takes merely weeks. Becoming good, though, learning the ins-and-outs of the industry, takes years, and thanks to the ever-marching-field of technology if you don’t stay up-to-date you become obsolete.

Some people go on to design computer-innards, but usually not us CS students- that’s more for electrical engineers and computer engineers. There’s way more math- and engineering degrees reduce people to boring, weeping lumps of humanity.

Through some combination of hookery and crookery, I’ve somehow managed to pick up (on my own time) enough salable skills in the area of web-programming to get a job in the industry, programming things. Right now I’m at Research In Motion, working on software that makes certain boring administrative tasks faster. This is another thing about programming that they don’t tell you- only the best programmers get to work on software that people actually get to use- everybody else ends up working on custom-one-company internal software.

So.. uh.. CS! Constantly changing, constantly challenging, tonnes of options. Some good, some bad.

That’s what I do. (That and write essay-length answers to short questions)

Programming is all about the management of complexity. Once tasks become sufficiently complex, a checklist improves it’s accuracy and speed. If at-all possible, those checklists can then be automated to save even more time- and it’s that second step where programmers come in. What purpose a checklist when a computer can perform every task in the checklist for you automatically? All of the complexity starts to flow out of the original task and into the hands of the coder, where it can be automated away.

Programming in it’s entirety can be seen as a series of checklists- do this, then do this, then do this. Single items in large checklists can be broken up into their own, ever-smaller checklists, which can be broken into ever-smaller tasks until the things being checked off are single lines of code- and then single chipset instructions. It’s turtles all the way down!

Modular programming erupted when people realized that some checklists can be generalized and used again and again. Object-oriented programming, when people noticed that the checklists and the data that the checklists were working on made more sense when paired up. Design-patterns because the very act of programming has become complex enough that certain parts of it can be accomplished by common well-known checklists- ‘patterns’.

People will spend years studying ways to make single checklists- for, say, sorting, or matching, or searching- more efficient. These checklists are used so often that advances in their implementation can improve the speed of thousands of other checklists that depend on them. There are checklists for making it seem like you can run more than one checklist at once, checklists for managing the difficulties that arise when all of a sudden you can run more than one checklist at once, checklists for converting checklists into different sorts of checklists, and checklists for services that other checklists require to provide valuable services to other checklists.

This is all tremendously complex, but because it’s all handled by automated checklists upon automated checklists, each one reducing the complexity of the last, all of the complexity is eventually reduced to the point where people who can’t tell a bit from a cool, frosty Mr. Pibb can harness the incredibly powerful power of checklists-upon-checklists to view thousands of pixels on a screen, painstaking organized to display articles transmitted from thousands of miles away about how complex Intensive-Care can be.

This article was in the ‘programming’ section of Reddit because- even though it didn’t mention computers even once, it reminded us of a deep and fundamental unit of programming- the checklist- and reminded us that even in it’s most elementary form, it’s a powerful tool that can find all sorts of clever uses.

So, it seems that Vancouver has become a sort-of hub for the web development crowd. Blast Radius, IceSoft, Bryght, RainCity Studios, inVancouver Design, and countless others, including lots of lesser-known startups like Steve Hannah’s Web-Lite Solutions and the indomitable MovieSet.com. Heck, I might even start my own web company, once I’ve classed up my web skills a bit- and why not in Vancouver?

A web conference has appeared! Curtis used ‘register’! The attack was super effective! Curtis has defeated web conference! Curtis has reached lvl. 2!

The “Web Directions North” conference will be held in late January. It’s two days of expensive workshops that I’m not going to attend (They sound awesome, but a day of knowledge for $400? That’s as much as 4 months of knowledge from the SFU), followed by two days of lectures from assorted Vancouver websy types and assorted non-Vancouver websy types. There are topics that I’m actually interested in - from “Five Essential Composition Tools for Web Typography” to “Design As A Business” to “What Makes a Design Seem Intuitive.”

Of course, there are also the obligatory talks where people jerk off to the words “Web 2.0? and talk about how the internet is going to change everybody’s life. But then, you can’t get a group of forward thinking people in a room without someone starting to run off at the mouth about how the internet’s new buzzword is going to change the universe, so really your best recourse is to just ignore them and take the opportunity to get yourself a good sammitch.

After the conference, there will be a day of skiing at Whistler- either on the Friday, or the Saturday- I guess, depending on whether you’re a Vancouver native who probably plans to work Friday and ski Saturday or a tourist who plans to go home as soon as the conference is over. (For me, it’s skiing on the Saturday.)

The cost for the conference is a wallet-busting $795, not including the skiing (an additional $120) or the conferences (an additional $400, each)- and that’s the early-bird pricing. A dubious value, at best- I mean, going to conferences like this is a great way to network with professionals, increase your skills (Girls only want boyfriends who have great skills) , and show potential employers that you’re the type of guy who constantly seeks self-improvement. But $920? Fortunately, if you’re a student you can take advantage of the “Student Discount”, bringing the conference price to a much-more-pleasant $195. It’ll still be another $120 for the skiing, but.. hey! Skiing!

So, the question is.. am I going to see you there? Learning about the web, drinking ‘the booze’, and skiing all over the place, taking the time to distribute your cleverly designed business cards to everybody and his mother?

Oh, crap! I have to design some clever business cards!

While this was super cool, clearly a mistake was made somewhere along the line. While I did put CMPT 475 on the TA form that I filled out (along with CMPT 476), I did it because I had run out of undergraduate courses that I would feel confident TAing for- and the form requires Exactly Ten Choices, No More, No Less, No Duplicates. I filled in some courses that no sane bureaucracy could ever give to an undergrad student and hoped that it wouldn’t be a problem.

Then, a big ol’ computer went through all of the TA options, checked that I had CMPT 475 checked on my form (what sane grad student would want anything to do with Software Engineering?) and offered me the position. Yay!

I’m definitely taking CMPT 475 next semester now! Guaranteed A for me and my friends!

.. Okay, okay, I’ve already explained what happened to the CS department and the offer has been retracted. Nuts.

You know how, assorted family members, whenever I write a technology-related post you all zonk out and start thinking of flowers and/or muffins? This one’s for you.

When working with graphics files- photos of your family, or funny pictures of cats with captions that you’ve downloaded from the internet, you’ll find that each file is associated with a certain ‘type’. You might not be able to see it- Windows hides this convenient fact for you in a sort of behind-the-scenes ‘this is beyond what you need to know’ sense.

Your first step is making sure Windows agrees with you when you say, “I am in control of my own destiny and wish to know what type of file I’m using at any given time.” Open any folder on your computer, then select “Tools” from the menu at the top of the window. (”File”, “Edit”, “View”, Favourites”, “Tools”)- then, “Folder Options“. There are four tabs at the top (”General”, “View”, “File Types”, “Offline Files”). Select “View“, then look at the options- you want to make sure “Hide extensions for known file types” is unchecked. While you’re here, there are a lot of other neat options that you can fiddle with.

Okay, so, now, file extensions are turned on. All of a sudden, every file on your computer is accompanied by a dot and a three-letter code- .exe, .rtf, .doc, .kif, .etc

This code indicates to Windows what sort of file this is- there are entire sites on the internet dedicated to cataloging which extensions mean what- and you’ll even see these extensions on the internet!

Here’s a quick run-down of some the most common extensions and their types- there are lots more, and as you spend more time with your computer, you’ll get to know which is which.

.txt - Notepad
.doc, .rtf - Word
.exe, .bat, .com - A program of some sort. (Never download or run one of these!)
.ppt - Powerpoint Presentation
.xls - Excel Spreadsheet
.mp3 - mp3
.zip - Zipped up file (Containing lots of smaller files)
.bmp, .jpg, .png, .tif, .pdf, .gif, .ai - Images
Now, while extensions are a fun little bit of computer trivia, what we’re going for here is a quick introduction to the different types of image files and when to use them.

Let’s start with .bmp. .bmp stands for “Bitmap”, and it’s the default sort of file generated by good ol’ MSPaint. A bitmap is a hideously inefficient way to store an image, and you should simply never use a bitmap.

Oh, as a side note- When I say ‘use a bitmap’, what I mean is that in whatever image processing program you use, when you go “Save As”, you can usually choose what “Type” of file to save your image as. Never save your image as a bitmap.

Okay, on to .gif- The “Graphics Interchange Format”- they’re good for clear images without a lot of colours and can handle basic transparency- for layouts with clearly defined breaks in colour, like logos, .gifs are highly efficient. Their most common appearance is on websites. If you have a choice, you probably don’t want to use this format, either.

Next, the hearty .jpg or .jpeg , for Joint Photographic Experts Group (the group that created the format). The JPEG format is a highly efficient way to send photographic images- it compresses them to a much more reasonable size, without sacrificing too much in the way of colour or quality. Chances are, if you’re sending something to someone to look at, you should use a .jpg file. When it comes to sharp corners or text, though, .jpegs can seem a bit fuzzy- you’ll see this on amateurish websites, sometimes.

The sexy .png file, for “Portable Network Graphics”, is designed to work as an improved .gif file. Although file sizes tend to be a little bigger, .png files have much better transparency and quality. Thanks to the fact that .png files are supported by Internet Explorer 7, Firefox, and pretty much every other modern web browser, you’ll be seeing a lot more of these in the future. If you’re showing someone a sample design or a logo, a .png file is the way to go.

On to the proprietary and special stuff:

A .psd, or “Photoshop Document”, is a file that can be used within the popular graphics program Photoshop. .PSD’s keep all information related to an image in full quality, as well as layering information and all sorts of other neat stuff. Adobe Photoshop is the most expensive graphics package currently in use, and through some devil magic it also happens to be the industry standard- graphics designers, web designers, printers, everybody has a copy of Photoshop (pirated or no). It’s noticeably more difficult to use than any other graphics package, too. If you go to a Kinkos or Staples or other professonal print shop, they’ll have Photoshop installed on their computers- so they can use these files, too. If you want to make changes to an image, then you pretty much must have a .psd file somewhere with all of your data saved in it- and if you want to print your image, it’s best to print directly from the .psd instead of compressing it to one of the other formats first.

A .tiff file (”Tagged Image File Format”) is sort of a cheap Photoshop file. It doesn’t do quite as much as a .psd file, but other, non-PhotoShop software can open it. If you’re not using Photoshop or giving the file to someone who doesn’t have Photoshop, but you still want to send a full-quality editable file, use a .tiff.

A .ai is an “Adobe Illustrator” file. All of the Photoshop rules above apply for the Illustrator file- the difference is that the Illustrator deals with “Vector Images”- images that are composed of lines instead of dots. Vector images can be infinitely resized, and are great for logos- you can make the logo as large or as small as you want without affecting the image quality! Vector images are also great for printing. Once again, any print-shop you go to should have Illustrator installed for you to print these files with.

A .svg is a “Scalable Vector Graphics” file- like an .ai, but free. If you’re sending an Illustrator file to someone who doesn’t have Illustrator, use .svg.

An .indd is an “InDesign Document”. Adobe InDesign is a powerful page layout package - when I was an editor for The Peak I used it to lay-out pages. (And then Amanda would mock me terribly and point out off-by-one-pixel errors with her hawk-like eyes.) InDesign can (and is) often used to produce .pdf files.

Finally, .pdf - the “Portable Document File”, is a combination image and text file, largely considered one of the better ways to transport books, menus, or other printed materials across the internet.

Of course, all of my friends are now screaming to themselves. “What about lossless vs. lossy graphics? Isn’t that important?”.. well, yeah, but it’s too much unwanted detail, for now, I think. “What about free, open-source editors like The Gimp, or Inktomi?” - well, while I love free, open sourced software, you aren’t going to see these files nearly as often as the Adobe stuff.

So, now that I’ve pounded you with all of this unnecessary information, here’s the summary.
For pictures, use .jpg, for designs and logos, use .png, and for printing and unfinished work, use the Adobe tools and get someone to help.

I want a Mac. They’re sleek, sexy, and their operating system is.. neat.

Mac Os X Leopard has neat new features. I still don’t feel comfortable with the Mac window-management paradigm, but I’m sure I could get the hang of it eventually. Most of those features that they advertise on the site, I don’t even care about. Better dock? Meh. Cover flow? I don’t even use Cover Flow in iTunes. Fancy stationary mail? I don’t want my friends to punch my kidneys, so no thank you. Safari? Well, I’m a FireFox man, myself- but hey, they’re actively developing it. (Ahem, ahem, Internet Explorer. ) iChat? iCan’t chat with people who don’t have the software, yet, so you’re really not that useful. Spaces? I don’t use them in Ubuntu, I won’t use them in Leopard.

I’ll admit that some of the features in “Stacks” look cool, but the online jury is still out on that one.

Time Machine? I prefer my (admittedly ad-hoc) backup scheme- identifying very-important-files and putting them in SubVersion repositories and/or saving them on my array of burnable media, portable hard drives, or ridiculously oversized DreamHost account. 99% of the files on my computer are not important files. I’d love to see if they included the Time-Machine graphical bits in the API, though- wouldn’t the Time Machine interface be a neat add-on for SubVersion?

Mac Os’s ‘Font’ support really blows poor Windows out of the water. Live Partition Resizing is pretty cool, too.

I know I’ve had some problems with the way Apple has done things in the past..

The Mac development platform is sharp and snazzy, (Cocoa) and I want to play with it. Python as a first-class development language? That’s just a dream! On top of that, somehow, the Mac’s managed to find itself a special niche- people who are willing to pay money for software. There’s a growing Mac development community, and they all seem to be charging money for their software. This is great for developers like me… and terrible for cheap bastards like me. (There’s the “Love-Hate” bit.) I guess I’ll just have to either find a good source of haX0red Mac software, start giving in and paying for $30 chunks of software (And $30 is a reasonable-enough price for something good), build it myself, or use free alternatives wherever possible. I’ll probably adapt some odd combination of those four.

The price is high. I have a laptop that already does everything I want it to, and I bought it for $600. I have been in the market for a new Desktop computer though.. my existing desktop is so cheap and slow and short on memory that it’s been relegated to a position as Ubuntu Samba-file-server. Maybe a Mac Mini? I’d need to supplement the rather insufficient hard-drive space with a file-server, but as I established, I have one already. Toss in a big cheap LCD monitor for increased joy, and we almost have a good desktop setup. It feels like I’m paying a lot of money for ’small’ that I don’t need, though. It could be the size of a truck for all I care. Thing is, though, the Mini doesn’t ship with Leopard just yet. Let’s give it some time, wait and see what we come up with.

Finally, I’m a bit disappointed with the way that Apple supports it’s older hardware. It.. doesn’t. I recently acquired a Mac Powerbook G4 Titanium “Mercury“- the oldest G4 Powerbook, released in 2001.

This was the original iteration, featuring a 400 or 500 MHz PowerPC 7410 processor. It featured a 100 MHz FSB, 2 RAM slots (that took up to 512 MiB modules, allowing for a maximum of 1 GiB), and an ATI RAGE 128 Mobility graphics card (with 8 MiB of VRAM; running at 2x AGP). Discontinued in October of 2001.

Now, this beast is a venerable 6-year-old- practically an eternity in laptop time. Nevertheless, it’s still useful for a number of potential purposes- portable web-browser and mail-checker and text-editor and DIVX watcher. Hey, that’s almost all I do with computers anyways. The only problem is, it’s battery is kaput, and it’s CD/DVD drive is dead as a doornail. Asking an Apple Store representative how much it would cost to find a replacement battery, he politely informed me that Apple no longer supports anything so old. How disappointing.

I guess to resurrect the Powerbook, I’m going to need a bootable external CD-drive (so as to install Mac Os X Tiger) and some E-Bay-style battery hunting. Anybody out there interested the dark arts of Powerbook resurrection?

So.. there are things I like and dislike about Apple and their softwares. I’ll put some thought into that Mac Mini - I have time, while they decide to install Leopard on it, and maybe wait for the difference in Canadian and American prices to even out a bit (yeah, right.)

For now, though, I’m a Windows man. Maybe an Ubuntu man a bit, too.

Dear ADV Films:

I’m having trouble with your website.

I’m just quickly going to outline the process of placing an order, from my standpoint.

Finding collections on your site was a difficult process at best. Searching for the word ‘collection’ didn’t produce very good results. I eventually made do by searching for the word ‘complete’- being that that word seems to appear in most of your collections.

Your ‘add to cart’ button is a tiny shopping cart. Clever move.

Having added something to my cart, getting back to search results is a chore.

Checkout started out with the customary ‘giving you every possible piece of information about me’, just shy of my blood type and obscure sexual preferences.

Clicking ’same as billing address’ for the shipping address reloads the page. Fun. Selecting a payment method accomplishes nothing- all I get is a Javascript error.

Classy. Classy.

It also kept needlessly insisting that my credit-card number have no spaces or dashes. Of course I had (in fact) entered my credit-card number without any spaces or dashes- but even so, why bother me with such a request when a single line of code on your end could remove the dashes and the spaces from my credit card number?

Nevertheless, I’m stuck here. I can’t order what I want to order, because your form won’t let me. Even clicking on the ‘Continue Shopping’ button returns me to the same broken billing page.

Okay, let’s try placing the entire order again from scratch in Internet Explorer. (I use FireFox as my primary browser, alongside 40% of internet browsers.)

Re-purchasing every item was fun. It gave me valuable time to reconsider some of my more impulsive purchases and pare down my order a bit. This whole process was made more entertaining by the glacial slowness of the website.

Okay, and, checking out again. Except this time, my e-mail address is already within the system. So I guess I didn’t have to re-find all of my purchases after all- except now I have to go back and check to make sure that my cart doesn’t have double-the-items in it. Okay, I click the “Continue Shopping” button, and it takes me to a page saying “Server Error in / Application” in bright red letters. Nice.

Through some crookery, I find my way back to the main page and -lo and behold-, I have a double-sized order sitting in my cart. Delete delete delete.

Okay, once again, let’s try “Checkout Now”. Okay, good, you’ve saved my shipping information. Thank you.

Okay, and.. “Visa”. Nothing. I’m using Internet Explorer 7, so it doesn’t have the common courtesy to tell me when something has failed.

I want to give you money in exchange for goods and services. Please don’t make this process any harder than is has to be.

So, Google’s released a new feature in AdSense- Google Video Ads. In fact, according to this introductory blog post from Google, it’s apparently been around for almost a full year. It’s built around their acquired YouTube technology, and advertisers can pay to have their video commercials featured on websites with similar content. Hooray!

The thing is, I haven’t actually seen this appear on a lot of websites. I think it’s pretty cool- and although I usually find video ads on websites incredibly irritating and intrusive, these are opt-in YouTube-style video ads that are potentially, theoretically related to the content on the site. So why haven’t I seen more of these on the interwebs? Do they have a poor track record of payments? Are they incredibly intrusive and irritating? What’s the deal?

I thought it would be worth a try to get them up and running on my website- a process that was pretty easy, overall. I gave it a few initial hints as to the content of my site, and a few false positives that would make for entertaining commercials (’web’, ’software’, ‘cooking’, ’sushi’, ‘development’…) and popped the ads at the permanent location of ‘between the first and second post’. Then, I watched a few of the ads myself to see what came up- nothing really ‘ad-like’- they’re more like standard you-tube clips. I guess I’m not getting paid for those- Google AdSense made it clear that some unknown percentage of the content is not advertising.

I thought “Cooking With Dave” was pretty hilarious, actually- and there was a barbeque show that was funny just because of it’s country-western-rustic-Ford-truck-steak-potatoes-and-axle-grease twang. I didn’t watch the whole thing, because it was long, but I was seriously expecting a gunfight to break out at any moment. “Now that’s a good rib-eye”.

As one complaint, it seems to think I have something to do with cars. Clearly they don’t know me very well- Curtis Lassam: Not A Car Guy At All. I wonder if I can change that in the settings somewhere.

Yeah, it’s time to turn my meagre 20 hits a day into pennies, nay, nickels a month! Soon, I shall control the internet, and all within it!

There is nothing in my life quite so exquisitely frustrating as trying to install Oracle support for PHP, under Windows.

Here’s the canonical process that you have to follow- the long form is available here- and boy, do I wish I had found that website earlier.

1. Download the Oracle Instant Client Basic package for Windows from the Oracle Developer’s Network.
2. Unzip and place somewhere.
3. Edit the Windows Environment variable, and add “c:\-LOCATION-OF-INSTANT-CLIENT-” to the System path.
4. Uncomment ‘extension=php_oci8.dll’
5. Restart Apache.

Now, first of all, installing this on my local instance of Windows was a chore. For some reason, Oracle.com wouldn’t load on my computer. Nothing would make it load. I assumed it was down, and went about other business for a couple of days. Eventually, I had reached the point where I couldn’t take it any longer and tried Internet Explorer instead of Firefox- and lo and behold, the site appeared. Odd.

I eventually downloaded the Instant Client and tossed it into a generic folder, somewhere. Having not read the all-important step three of the above 5-step process (unaware, even, of it’s existence), I spent a great deal of time playing with the PHP configuration at php.ini, trying to tell PHP that “THE INSTANT CLIENT FILES ARE RIGHT HERE, PLEASE NOTICE THEM”.

Hunting about for instructions online did nothing to ease my pain. I had yet to find the guide that I linked to at the top of this page- the guide that would have explained this process to me.

Eventually, through some combination of hook and crook, I discovered the guide and successfully installed Oracle support into my local instance of PHP. Great, I can develop the thing I was working on! (FYI: A quick-admin web interface for Quality Center, because, as terrible software, adding users and groups from within the software is a painful and slow process, and the COM API they provide is useless at best.)

So now, it’s time to roll everything out to the Test Server, ye grand repository of half-baked program bits. I went through the entire process as last time.. and .. nothing happened. What? I don’t understand! Okay, so, clearly, I’m doing something wrong here. More fiddling occurred with the php.ini file, and more, and eventually (give this a couple of hours, mind you), I came to the conclusion that *nothing* that I was doing to the php.ini file was recognized at all by PHP. Okay, that’s a little strange- some searching revealed that there were 5 separate php.ini files on the computer. Some further individual experimentation showed that not a single one of those php.ini files actually controlled PHP’s configuration in any way, shape or form- it was just using it’s default out-of-the-box settings. In fact, this instance of PHP wasn’t running as an Apache module at all- but as a CGI. What the hell?

A fresh installation of PHP as an Apache Module resolved this problem for me, and the PHP CGI was killed.

I then changed a few settings in the php.ini file. The last person to develop in my position clearly thought that “Register Globals” was a good idea, and had this beautiful tendency to pass session global variables all throughout the program- skipping, even, such PHP classics as $_SESSION, $_POST, or even $_GET. While any bit of code that *I* touch had to be reworked to .. eschew such poor practices, I’m only one man- one lazy man- and I’m not going to rewrite the entire codebase from scratch just because of one or two displays of egregious ass-hattery. (Plus, I’m young. I’m sure my code is riddled with stupidity.)

The next step in the chain would be to enact the same change on the production server. Now, being as the production server is a moderately sensitive environment that real people (well, other developers) actually use for things, I was less inclined to tool about in a silly fashion. I did what any responsible human being would do, and tried to push the problem on my boss. “This change could clearly effect some other tools! Could you find out what other tools are running on the server and get back to me?”

Now, this is one of my favourite techniques for avoiding work- putting external requirements in the hands of people who are lazy, busy, forgetful, or some combination of the three. The whole debacle could wait until I had finished development on the tool and needed Oracle on the production server. Weeks passed.

Just recently, my boss needed the Oracle module installed in PHP, on the production server, for some new tool that’s being developed- and since I’ve been the poor bastard installing it on everything, it should fall to me to install it on the production server. (Shouldn’t it fall to IT? No.) And, in response to my question of a few weeks ago, we’re the only team running any PHP on the server, so we can fiddle as much as we want and not cause anybody any grief.

So, this time, everything came off without a hitch… except that PHP refused to acknowledge the change in the windows PATH environment variable. I restarted Apache a few times, poked at the php.ini file, and did everything short of restarting the server- which, of course, would require the permission of three teams and a signed affidavit from the Pope himself.

After puzzling for a few minutes, I eventually just gave up and popped the entire set of Oracle files into a directory that was already on the path- C:/Program Files/PHP. It’s an ugly win, but I’ll take it.

As a final note, children, when you grow up, never, EVER, EVER run a Windows web server. (Or Oracle, for that matter. Quality Center is out, too.)
This weekend, I tried a new project.

Having access to a Wii, a Playstation 2, and an Xbox 360 at my house- yay, roommates, I’ve made it a personal goal to play Super Mario Galaxy and Final Fantasy 12 while I have the chance.

I finished Super Mario Galaxy on Saturday, over the course of about 12 hours. Let me tell you, everything people have been saying about the game is true. It is, without any doubt, the best platformer. Not the best platformer for the Wii, or the best 3d platformer, or the best platformer game that I’ve played. It is the best platform game, 2d or 3d, for any system, ever. That applies into the future, too- it is the best platformer that ever will be, at least until Nintendo releases the next solid Mario game, 8 years from now. The controls feel comfortable, the camera is always where you want it to be, and the game is bursting with novel concepts and gameplay.

On Sunday, after doing some laundry, I started on Final Fantasy 12. Now, after playing a game of such high quality as Super Mario Galaxy, the slow gameplay of Final Fantasy was a bit of a stick at first, but I powered through it. It’s really not so much a ‘game’ as it is a long animated serial with occasional breaks where you can kill monsters or buy weapons. No complaints here, though- the story is peppy and fun, the characters are interesting, and any game with British accents is okay by my books.

It’s been a long time since I’ve played games- any games, really, and these are some of the best of the bunch. I’m having a blast.

Just a few days ago, I thought I’d perform a test to determine the best burger in the vicinity of my office.

I set out to the University Plaza, and duly purchased a Chill n’ Grill ‘Big Juicy Burger’, an iced-tea beverage, a Harvey’s ‘Angus Burger’, and some onion rings. I thought I’d also toss the Kelsey’s “Peppercorn burger” that I had a while ago into the ring.

Here are the results:

The Harvey’s Angus Burger

Layout: 
One Harvey’s Angus burger with bacon and cheese, lettuce, tomatoes, onions, mayonnaise, mustard, ketchup, and barbeque sauce. Onion rings.

The Bun: 
An impregnable glutenous mass- a fairly generic burger bun, solid and ready to hold up it’s side of the burger bargain- but very dense.

The Meat: 
Rubbery and flavourless. A very bland offering, patty-wise. Probably the worst of the lot.

The Toppins: 
They put everything on my burger that I asked for. No problems here, a good selection of toppings. The bacon was (like the meat) a little flavourless. Ah, well.

The Side: 
Delicious, delicious onion rings. Crispy, oniony, all-in-all a good offering.

The Price: 
Without the rings? Just under $6.00 for the burger.

The Chill N’ Grill ‘Big Juicy’ Burger.

Layout: 
One BJ burger with cheese, lettuce, fried mushrooms, tomatoes, onions, mayonnaise, mustard, ketchup, and barbeque sauce. One cheap canned beverage. (They’re only like 40 cents on top of the price of the burger.)

The Bun: 
A soft, wishy-washy offering. The bun is quite possibly the worst part of the Chill N’ Grill layout. They take a soft, crusty roll and try to toast it to harden it a bit. It makes for a good eat-in burger, but if this bun travels more than 10 feet it’s going to soak up the burger juices and fall apart.

The Meat: 
A smidge burned, but good stuff. The burger was a bit charred, but still meaty and juicy. While probably the thinnest burger of the bunch, it takes the ‘not sucking’ cake.

The Toppins: 
On top of my normal burger-deck of toppings, I managed to get some fried mushrooms. Fried mushrooms on a burger are delicious. Other options included fried onions, which are also delicious. High marks for the cool options!

The Side: 
While it was nice getting a cheapo can of pop with the meal, I’ve had Chill N’ Grill fries before. So have you, probably, if you’ve ever eaten at a Fish And Chips sort of eatery- for about $2.50, you get a big greasy basket full of thick, fried potato chunks. While it may win for it’s economy value, I’ve never been a fan of those big chunky fries and tend to avoid them whenever possible.

The Price: 
Burger and drink for about $6.00

The Kelsey’s Peppercorn Burger

Layout: 
Apparently a ’signature’ Kelsey’s burger. A largeish patty with cheese, lettuce, tomatoes, and mayonnaise. A small Caesar salad and an iced-tea on the side.

The Bun: 
Hey, restaurants have the bun thing down pat- A pretty standard ‘restaurant burger bun’, but it holds the burger together better than the Chill and Grill, without being as comically dense as the Harvey’s offering.

The Meat: 
Fairly juicy, and covered in cracked peppercorns. When it comes down to it, the excessive pepperiness of the meat really overpowers the flavor of the meat and the rest of the burger. Okay, but not great.

The Toppins: 
Disappointing at best. Restaurant burgers never really offer the full plethora of cool burger options unless you want to pay out the nose for all of the extras. Who wants to pay another buck-fifty for bacon or mushrooms?

The Side: 
Boo! The Caesar salad was dry and tasteless. Barely worthy of the name ‘Caesar salad’, it was more a slab of romaine with some Parmesan cheese sprinkled over it.

The Price: 
Clearly the loser, here. The burger, salad, and drink, plus tax and tip, came to about $16.00.

THE WINNER: 
The local Chill n’ Grill wins for having the best meat, the most local flava’, the best toppings, and the best price of the lot. Not to mention, supporting the local guys is always a cool option.

One of my co-workers has turned me on to a whole new world of beverage deliciousness.

He said, “Drop a peppermint teabag into a hot chocolate. It’s good!”

So, I tried it, and it was delicious.

We have a free hot-chocolate/coffee machine at work, which makes average-ish hot chocolate and acceptable coffee. I took my mug and filled it with a concoction of 50% hot chocolate, 50% coffee, 2 creamers and a peppermint tea bag, then let it sit a little while. What ensued was a delicious, chocolatey, minty, caffeiney beverage almost worthy of being a $5 Starbucks Concoction.

Okay, we’ve settled on a new morning beverage, we have.
Some lecturers are just better than others. They tend to be older, more experienced lecturers who have been teaching the same course for some time. And almost all of them write their notes directly on the whiteboard, blackboard, or overhead projector.

In fact, one thing that students (at least in my group of friends) studiously avoid are professors who lean too heavily on PowerPoint. But why? Why do written notes outperform PowerPoint lectures so often?

1. Writing Is Hard, Slow, and Boring

Laboriously hand-copying down every word of the lecture is quite possibly the most mind-numbing thing in the universe.

What’s the benefit to that? If anything, it should slow the class down, right?

Wrong! Professors who write down their content tend to deliver their notes in a highly streamlined manner. Thanks to the difficulty of writing everything down, a couple of paragraphs on a topic might be condensed down to a few words on that same topic- or maybe just some headlines and definitions.

What this means is that, as a note-taker, you’re copying down a simple, concise summary of the most important points of the lecture, occasionally scribbling down something important or difficult along the edges.

Now here’s the part where the cleverer elements of our audience might point out that an effective Powerpoint presentation
is exactly the same thing- a simple, concise summary of the lecture, just without the added ‘writing it down on the board’
time. And that’s true, ideally. Powerpoint, however, like Communism or the GOTO statement, is good in theory but tends to be misused in practice. It’s very easy to add words to a Powerpoint slide, and it doesn’t add any extra time to the lecture- in fact, the more information on a slide, the less that the poor presenter has to commit to memory.

As time passes, a Powerpoint Presentation will grow- more information will creep in along the edges and the slides will
bloat in size and complexity. Written presentations, however, tend to become more minimal and concise over time, as in the name of efficiency the parts that are written on the board become the smallest nuggets of information that the professor can justify writing down.

2. Students Want A Copy Of The Slides

What? You’re giving the slides to students? This’ll save us some writing time, but at what cost?

Okay, I’ll admit- a lot of students aren’t verbal learners. It’s tough for them to process the information as the professor goes on and on about this that and the other thing- and in those cases, a written copy of the lecture can be a godsend.

But in order for the slides to be useful for that purpose, the slides have to contain the entire lecture in a detailed fashion- which renders them almost entirely useless for their main purpose as a lecture aid.

Even if the slides are concise, well-prepared point-form documents, students tend to listen less when they have the safety net of a ‘pre-prepared’ set of notes. For me, the very act of writing down a note further cements it in my memory.

Extra-long slides are all but impossible to copy down. There’s a reason we take notes in class, and it’s not simply because we need further reading materials for later.

3. It’s Read OR Listen, Not Both

So, my first two points mostly revolved around how Powerpoint slides increase the bloat of the notes that you see while you’re in the lecture. Why is it important that the notes stay streamlined?

Well, first of all, when a professor speaks and presents a PowerPoint slide, you are presented with two different sources of input. Should you be listening to the professor, or reading what’s on the slide? It’s not possible to do both. Sometimes, the professor will read exactly what’s on the slide, word for word, which is monotonous for the fast readers in the class, who will then spend most of their class nervously tapping their pencils, waiting for the next slide.

An important part of the lecture is summarizing- selectively determining what the important bits of information are for later recall. While it’s possible to do this when presented with a solid wall of information, it’s much easier when the professor outlines what the important bits are.

4. Professors Aren’t Designers

A big portion of my stepmother’s job is to prepare PowerPoint slides. Smart co-workers know to offload the task of preparing slides to her because she knows how to make them look professional and smooth, and keep the slides concise and effective.

Many professors ignore even the most simple laws of PowerPoint design- Slides absolutely MUST have high contrast, and big, easy to read words. I’ve seen lots of slides with tiny letters on a background that’s almost the same colour- so the slides are almost impossible to read.

When it comes down to it, the amount of visual flair that’s required for a lecture is quite easily “Zero”. Big black letters on a big white background are all you need.

5. Professors Can’t Write As Fast As They Can Talk

I don’t know about you, but I’ve had a number of professors who’ve gone either much too fast or interrupted the lecture to go on a 20-minute segue about how they are smarter than everybody in the known universe, then complained about not being able to smoke in class.

Okay, written notes may not be able to guard a class against the sudden-offshoot-off-topic-lecture, but it can pace a professor who is just going too fast. There’s quite fortunately a natural limit to how fast one can write notes down.

6. Memorization

Professors who are tossing written notes out there almost always have their lectures memorized. I mean, while they have to have the lectures at least a bit memorized to be able to lecture at all, these professors have their lectures down pat- perhaps one of the biggest arguments I’ve been able to find for professors writing their notes down while they lecture is that even the professors themselves seem to have an easier time remembering the content of the lectures.

And memorized lectures? Well, they’re smoother, clearer, more practiced, and they have better pace. Glory.

7. On-The-Fly Diagrams

Diagrams in PowerPoint suffer the same problems as the notes in PowerPoint do- they are too complex, too fast. While hand-drawn diagrams tend to be much simpler and more cursory, that also means that identifying the important concept in said diagrams is much, much easier. A fantastic way to direct attention around a diagram is simply not to present the information that you want to show until you need to.

Oh, this is possible with PowerPoint- it’s just more difficult and time-consuming.

The other big benefit of the written approach here is that when a professor wants to illustrate a difficult point- even if she didn’t have a prepared slide- creating an impromptu diagram is as easy as pie. She can even dynamically generate diagrams on-the-fly in response to the questions of students! Cool, huh?

Objection!

A good PowerPoint lecture can still beat the pants off of a rambling, off-the-cuff impromptu lecture without notes. In fact, a good PowerPoint lecture can beat the pants off of a lecture with written notes, especially if the professor writing the notes has a tendency to scrawl whole paragraphs in a language that (despite the professor’s claims otherwise) looks like some obscure admixture of Cyrillic and Kanji.

A good professor can make just about any lecturing style work. What I’m saying that professors who write their notes down are more likely to deliver a strong lecture.

And Now For Something Completely Different

Just because written notes are a strong option, doesn’t mean you can’t use a laptop in your presentations. There are still quite a few uses for laptops in a lecture environment.

1. Media

First and foremost, pictures, videos, and music are nary impossible to deliver in a written lecture, unless you’re a spectacularly talented live performer or an exceptionally fast artist.

Just.. please be able to find it when you need it.

Please.

Maybe keep a folder open, with a clearly marked name (”CMPT 999?) in a place where you can easily find it (On your Desktop) and a backup online if necessary. Mark your media, in order of presentation and by name. (” 1 - Picture Of Tom Sellack.png, 2 - Beethoven’s Tenth.mp3…”).

2. The Word

A really effective way to write things down for the class is available as one of Windows’ least used utilities- good ol’ Notepad. Open it up, find the “Format” bar and set your text size to “Enormous” (That’s 48pt or higher). Maximize the window and you have a way to toss your written notes up on a very big screen.

As an aside, when I was a Teacher’s Assistant for an intro-level ‘Teamwork And Communications’ course, I would occasionally toss up Notepad in big-letter-mode behind the professor’s head as she lectured, featuring snarky comments a-la Stephen Colbert’s “The Word” while she talked. Between that and my attempts to fail every student who couldn’t write English at a Grade 12 level, I didn’t get the job again next semester. (In the market for an Undergrad TA for a lower level CMPT course? Call me!)

3. Print Out All Of Your PowerPoint Slides Onto Transparencies, Then Write On Them

I’m just joking. Never, ever do this. Just take my word for it, it’s awkward.

Here’s a question for you- as a tech worker or CS Student, how do you explain what you do to friends, neighbors or loved ones who clearly don’t understand the TLA’s (Three-Letter-Acronyms) that you’re tossing out? Do you even try at all? Do you simplify what you do? Do you just toss everything you’ve got at them and wait for a sympathetic nod?

From time to time, I receive an e-mail from Helium.com- some sort of automated message to let me know that some new feature or contest is available to me.

What is Helium? Well, it’s difficult to describe. It’s an online ‘magazine’ of sorts, with preset article topics that people can write articles for. Topics exist across a number of categories- from “What is the best way to protect my computer”, to “Pros and Cons of Online Pharmacies”. Writers then read through articles and rank them- this article is better than that article, this article is better than that article, etcetera. The higher-ranked articles are then the most likely to ‘make money’, appear on the front page, or win the user points towards contests (where the top prize can be as much as $75!).

Now, at first, it seems like a great scam because they’re getting tonnes of people writing for them for some very low costs. They can generate all of the content that they want for free and then profit off of ads and such. The writers, at least, can make a little bit of money and maybe get their writings viewed by more people than usual.

But after a short while you realize that that’s not Helium’s business model at all. In fact, the only audience that Helium has at all.. are the writers themselves. The articles at Helium are largely and overwhelmingly of poor quality. The pre-approved, limited range of topics means that articles are largely boring and samey, and that writers are constantly writing the same things over and over again. If you go to Helium’s front page, or sign up with Helium, the entire brunt of the site’s dynamic seems to be “Hey! Write for us!”.

So, the entire Helium community is comprised of writers all-but jerking off to their own words, and competing for small prizes based on said writings. Which, when it comes down to it, is a decent enough community- at least enough to bring in some ad revenue for lucky Helium. Is it enough, though, to justify the lavish contests and apparently expensive development of the site? It looks like VC is being blown at an astonishing rate on this project, and I find myself wondering if their business model is going to hack it.

Well, it worked for thisisby.us … it could work for Helium. Let’s wait and see!

Well, maybe not “NEW”.

I have aquired a G4 Powerbook ( 500Mhz, 256Mb RAM, 20Gb HDD ) in a game of chance involving a stack of elephants and 27 pennies, and now I need to make it into a beast of burden to call my own.

Despite the fact that I have a much better laptop.

That’s not held together largely by tape and dreams.

One that doesn’t need a replacement power-supply.

It has Mac Os X running on it, but I can’t actually *use* it because the whole thing is locked down with user names and passwords. Plus, wouldn’t Mac Os X be slow on such an old machine? I’d like to give the X a try, but I don’t know how to break in and start fiddling without a clean install- and I don’t have the resources for a clean installation of an old version of Mac Os X. (I’m sure NEWER versions will break the hell out of it.)

I’ve decided that the best course of action will be to install Xubuntu on it and see how that runs. Ubuntu is a pretty heavyweight beast, though- I might end up experimenting with some other alternatives for Mac Reanimation.. like Slackware.

So.. do any of you know a way to acquire old Mac OS X softwares? Or a way to tell the Mac “I am not one of these people, they are all gone, please make me the new Root”?

Or, failing that, what would you be running on the ol’ box?

Okay, so, yesterday, after work, I tossed off to the supermarket and brought home a barbequed chicken, a package of chicken gravy, and some tomatoes.

When I arrived home, I set upon the barbequed chicken with a knife, separating it into it’s constituent parts. It’s really very easy- the chicken just pulls apart. While I was working on that, I had the gravy on the stove.

It all came together- toast, some mayonnaise, slices of tomato, some pepper, chicken, shredded cheese, and gravy, all together, formed a sandwich that was quite possibly the perfect embodiment of the sandwich Tao. The Alpha and the Omega. The One True Sandwich.

I still have some chicken in the fridge, and some gravy, just waiting to once-again form the cornerstone of an earth-shaking sandwich.

A short while ago, my roommate Mike introduced me to the best B-movie I’ve ever seen in my life - Commando.

Commando was the movie that inspired the first Die Hard. Here’s a quick synopsis: Arnold Schwarzenegger plays “John Matrix”, an ex-commando who lives in obscurity with his daughter. His wholesomeness is driven home by a montage of activities with his daughter, which include eating ice cream, laughing, and feeding a wild fawn . His daughter is kidnapped by a group of rebels who want to use John Matrix to assassinate the head of state of a nonexistent Latin-American country (It was “Baldevia” or something like that). They pack him on a plane, set to land in Baldevia in 11 hours. So, in order to save his daughter, within 11 hours, John Matrix kills every single person in the entire rebellion. The movie is a non-stop, action-packed killing spree marked with occasional breaks for John Matrix to spout off a snappy one-liner or rip a phone-booth out of it’s moors.

Matrix: Remember, Sully, when I promised to kill you last?
Sully: That’s right, Matrix. You did.
Matrix: I lied.

Just watching this movie, I grew a full moustache and beard. Sound like an awesome time? Mike has two copies, so I’m going to try to buy one of them and bring it home with me. Perhaps I will use the awesome power of science to distill pure, uncut manliness from the DVD itself.

The only problem with plundering the United States for phat lewt is that Canadian Customs is on the way, making things difficult… and the Customs guidelines are not exactly laid out in an easy-to-understand manner. (Yay beaurocracy!)

(I suspect looting the United States for books and electronics would be easier with Kristen & her American mom, with her American passport. We’re ever so un-suspicious. Just travellin’ through to mail some packages and buy some delicious dairy products!)

The comic Dresden Codak is now updating weekly. This is a Very Good Thing. The art is lush, the characters are compelling, and this comic is the best thing ever. (And don’t think I haven’t had that same Ray Kurzweil fantasy myself, airship and all.)

Also? Tiny Carl Jung.

Today had weather that makes me very unhappy, very unhappy indeed.

It was cold in the morning, and a strong wind blew nasty frosty chunks right in to the ol’ face.

Then, at about lunch time, there was a sudden ’snowstorm’- and I mean something that would qualify as a snowstorm in Vancouver, but is barely a sprinkling for Ontarians. It melted as soon as it hit the ground.

On the way home? More cold.

I miss you, Vancouver!

Have you heard of Portal? It’s a cleverly written, cleverly executed game where an AI that combines bureaucratic efficiency and utter disregard for human life leads the player through a series of deadly mazes that can only be navigated with the use of a ‘portal’ gun that allows players to create portals from place to place.

Some clever DigiPen students (DigiPen is the premier game development school in North America) produced “Narbacular Drop” as a final project, some time ago. It was a cleverly written, cleverly executed game where an AI that combined bureaucratic efficiency and utter disregard for human life led the player through a series of deadly mazes that could only be navigated with the use of a ‘portal’ gun that would allow players to create portals from place to place. They were hired by Valve to turn Narbacular Drop into a full-fledged game, and Portal certainly has all of it’s fledges.

The best part of the game, however, is the clever, clever writing. Curious? Here’s the entire script to the game. It’s good reading. (Oh, and the song at the end was great, too)

When I was browsing my “Bookmarks” folder, I found one of my favourite bits of reading, the “True Porn Clerk Stories“. As per the name, it’s the journal of a clerk at an anonymous movie store with a larger-than-average porn collection (the movie store, not the clerk), and her assorted musings vis-a-vis the irritating customers.

It’s frequently insightful, and often hilarious. Sometimes both:

So, I’m browsing Reddit at work like any well-motivated employee might be doing.. when I happen across this article about corporate team building. Now, I don’t know why, but I always enjoy this kind of thing- and before I knew it, I’d read about 4 articles on the site and had bookmarked the whole thing.

Aside from the well-written articles straight out of the pages of Peopleware, what was the trick that got me clicking? At the bottom of every post is a set of ‘related articles’ from the site- 3 articles that might also catch my eye if I liked the article that I just read.

I thought about it- wait a minute- every time I’ve been on a site where I’ve enjoyed an article and found the “Related Posts” or “Related Articles” under it.. I’ve usually clicked on one of those articles. Heck, McSweeney’s is a site whose entire navigational system seems to be based on the “Related Articles”.. and McSweeney’s has used that selfsame tactic to trap me on their site for hours- days, even.

In order for this to work, posts need eye-catching, descriptive titles, and you have to do the research to put those three posts together.. or maybe write a quick blog plug-in to handle it for you - but it seems like a good strategy. (Categories might be the way to go- categorize all of the content, hide the Categories bar, and then fetch the last 3 from the same category to go under each post.)

So, yesterday, my home internet was disconnected for a day by Rogers. The reason? Apparently, one of our computers has an IRC bot virus.

Now, I can’t help but think that perhaps our account was flagged thanks to the fact that both me and Tim are nar’ constantly connected to IRC in the background- and me with Ubuntu, no less!

Now, while I understand that for the average-joe user, the likelihood that they’ll actually be using IRC is much, much lower than the likelihood that they have contracted some form of IRC-related virus. By giving users with suspicious levels of IRC activity an internet suspension and getting them to clean up their computers (or pay someone else to), Rogers is putting the responsibility for security in the hands of the internet users, which isn’t necessarily a bad idea. If they do raise a false positive, chances are they’ve flagged a nerd- and we’re more trouble than we’re worth anyways, always trying to use our paltry internet services to run servers and open SSH ports, and all sorts of other stuff that they don’t want to have to deal with.

When it comes down to it, security is far more important for average users than, say, the ability to do wild and wacky things with their internet. Open up HTTP, POP, and SMTP and most internet users have all the functionality they could ever hope for. (This, coincidentally, was one of the reasons AOL’s business model was a good idea: “People do not want to devote time towards learning how to use the internet” was as true then as it is now)

Our household has a software developer, software tester, graphic designer and game-freak math student. We’ve got maybe 30 years of internet experience between us. We have 4 computers, a fileserver, and 3 internet-connected consoles in our house, and we depend on the internet for phone service, entertainment, information, the works.

Rogers can promise these great super-fast high-end personal plans, they’re always going to pair them up with idiot-friendly nerd-punishing policies. So.. how much do I have to pay to be treated like an adult? Maybe the “Small Business” Internet service? It’s maybe $20 more, per month, for what amounts to exactly the same service- but would that extra $20 buy us, say, a certain level of respect for the sanctity of our holy connection? The ability to do weird and esoteric shit with our internet without losing internet service? As a “Small Business”, is it more reasonable for us to raise holy hell if our internet goes down for *any* reason?

The next “infraction” will buy us a week’s suspension. I’d drop the provider immediately and move to a more nerd-friendly enterprise if such a thing were to happen to me.. but our internet is managed by our landlord, and I’m only going to be in Waterloo for another 2 months. Humbug.

The following words may be the most ominous in the human language:

“Hey, Curtis- you can play BioShock on my computer if you want.”

I can’t help it- BioShock is awesome. Just walking around and looking at things, and listening to things, is awesome. The game is beautifully executed.

I’ve been moved to a new project at work:

“Management Overview Testing Of Recursive Binomial O( n ) Algorithms Tying Information to Non-Government Monetary Yearly Balance And Liabilities/Lawsuits Systems.”

They couldn’t fit the whole thing on my new business cards, so they just tossed in the project acronym.

So far, my Django experience has been bumpy at best.

I’ll admit it- I would much, much rather program in Python than in PHP. Python is just a better language. I like templating languages, and while I have an inherent distrust for Object Relational Models, I like that Django apps can swap in more robust SQL code if necessary. For small sites, ORM’s are a big time saver- and most sites are small sites. On paper, Django is clearly the winner.

So why is it when I’m fiddling with Django, I get frustrated so easily?

First of all, there’s a learning curve, and in order to build a minimally acceptable site, one needs to cross a major learning curve. In order to get your first ‘non-tutorial’ Django site up, you need to learn Python, Django’s Template System, Django’s Model System, Django’s URLConf system, and a few other niggling little things. As a PHP developer, you need to learn.. PHP. As a Django developer, you need to learn Python, Django, Django’s Database Shorthand and a Templating Language.

Second of all, PHP’s documentation is pretty awesome. Once you’ve read the obligatory “Introduction to PHP & SQL Development” book that comes in many differents forms from many different authors, all you need for documentation is the exhaustive search-function at PHP.net. If you’re using Firefox, you can toss a PHP search bar where your Google search bar usually sits. (I usually have Wikipedia up there, actually). Django’s documentation is.. not quite as complete. The Django Book is in a constant state of semi-completion, and the rest of the documentation is scattered, disorganized, and searchable through a Google bar.

Thirdly, the Django documentation is not for the ‘release version’ of Django. The documentation is for a sort of ‘meta-composition’ of the most recent SubVersion revision at the time that page of the documentation was released. In fact, the only version of Django really supported by the Django community is the most recent SubVersion copy of the code. Now, for a developer, this sounds pretty neat- but it’s also a little on the scary side. Everybody is writing documentation and handling support for *their version* of Django. While I may love working on the cutting edge of technology, if I release some sort of product, I want the underlying technologies to be fairly constant and long-term-supportable- which means I want to develop against the newest available release candidate, not some miscellaneous SubVersion checkout.

Fourthly, Django’s framework introduces a certain level of ‘magic’ into the system. Some of the stuff that Django handles is just too easy, and that bothers me.

The thing is, though, while I might have a lot of issues with Django, I keep sticking it out and fiddling with it. It is *great* on paper, remember. It was designed primarily to deal with a lot of the issues that people have with coding in PHP, and I support that wholeheartedly. Keep in mind, too, that Django’s pretty new - it’s not even at “Version 1? yet!

Django’s off to a good start. With community support, some thorough documentation, sensible release management, and the thousand other important things that tend to form around good open-source technologies, it could be a real winner.

Thing is, though, I don’t want to build it- I just want to use it!

Okay, here’s the thing. Sometimes, I’ll use words in sentences without knowing what they mean. I’ve heard them in similar sentences before, and the usage feels right, and I have an idea what those words mean.. but I’m not sure.

Then, I’ll look those words up in a dictionary, and find out that I was right.

Then, I feel good and start using that word again and again and again.

So.. “Ostensibly”. “Ostensibly ostensibly ostensibly.” “Ostensibly”.

Thank you.

Self described as “electronica with a fist” (And labeled ‘electroclash’, even though they refuse to believe it), Ladytron rock a darker side of electronic music. This isn’t bubblegum pop by any means- in fact, they have a multilayered, detailed, slower approach to their music that ends up sounding haunting and artificial. It’s that detail that makes Ladytron one of my favourite bands- with a good set of headphones and sufficient volume, it’s easy enough to lose yourself in their pulsating, complex rhythms.

A few remixes (James Iha and Soulwax) toss a solid guitar-powered backbone into the electronic groove, which works beautifully.

On the complete opposite end of the electronica spectrum exist Freezepop. The three person band’s entire musical repertoire is put together with a Yamaha qy70, a vocoder, and the voice of either Liz Enthusiasm or The Other Sean T. Drinkwater (ostensibly a robotic clone of the Original Sean T. Drinkwater).

The band’s third member, the Duke of Pannekoeken, has the best name in all of history, narrowly beating out Electric Six’s ‘Dick Valentine’ and Napoleon Bonaparte.

Freezepop’s sound is (especially compared, to, say, Ladytron) very sparse, and simple, and fun. They describe their sound as ’sweet and cold and fruity and plastic-y’, like a Freezepop, which sounds appropriate enough. Subject matter includes an entire song about a Wang computer (double entendres abound!) and a girl producing clones to fill out the rest of her band.

Freezepop has worked with companies like Harmonix to get their tunes into popular video games, which is how they’ve found the public eye. (I first discovered them thanks to a mix of “Science Genius Girl” in DDR )

Old-school extra-cheesy rock. Some might like the band because of the silly, ironic undertones of excessive amounts of rock. Some might like the band because they’re just plain fun. Currently, the band is composed of Dick Valentine, Rock & Roll Indian, Surge Joebot, Disco, and Percussion World, but the lineup changes pretty frequently.

Allen is a Mac Os X Fanboy user. He’s been to the WWDC, he’s using a sexy little MacBook. He posts in his blog about neat features in the upcoming Leopard release.

Well, I say, boo!

Why boo?

I don’t want to jump into the OS Holy War- I don’t like Mac Os X because I’m a poor student, and I can’t afford The Mac Tax.

Compare the MacBook with the Dell Inspiron 1501 .

Spec for spec, the loosely-affiliated bucket of assorted bargain-bin Dell parts match the MacBook.

The Inspiron is also a bulkier contender, not as slick or stylish, with a lower battery life. It’s just not the same all-in-one package that you’ll get with a MacBook. But it’s also $500 cheaper. The “Mac Experience” is, in this case, a 46% tax.

Somewhere, someone’s come to the decision that “The Mac Experience”- an ethereal combination of Mac Os X and shiny hardware design, is worth about $400.

Comparatively, an OEM Microsoft Windows usually adds about $80 to the cost of the rig, and a Ubuntu 7.10 (”Gutsy Gibbon”) installation costs approximately the price of one CD-R ($.20). In fact, every CS Student at SFU gets a free copy of Windows XP Professional and Ubuntu 7.10 just for taking a CS course.

I don’t know about you, but I’d say a properly configured Ubuntu+Windows configuration can at least hold it’s ground on the development battlefield. (Not to mention, you have the opportunity to spend a weekend custom-building a Homebrew Monster . Sweet.)

So, while Mac Os X is clearly a pretty sexy contender, it’s going to be a long time before I’m willing to voluntarily pony up $400 for an operating system - especially when sexy contenders like Ubuntu 7.10 are around. Maybe I’ll pay the Mac Tax when I’m making a little bit more money.

They’re everywhere. They exist among us. I try to escape it, but I am also one of them.

They have nice offices. They have Aeron chairs. They make lots of money and they are usually quirky and fun. They’re all-but-impossible to differentiate from good programmers, except that they’re far more common.

They build the software that you use in your day-to-day life.

Not the software that you enjoy. The software that you hate. The bank software that asks you too many questions and the custom-built company-wide applications that never seem to work properly.

They built the firmware for your router. They built Zango. They built Windows Vista. They built thousands of little companies and products. They wrote the instructions for your portable hard-drive and they wrote that crappy point-of-sale system. They’ve built just about every piece of software that you’ve ever encountered.

They didn’t build Microsoft Excel or Microsoft Word.. but they did build Clippy. They didn’t build Google but they will shape a new generation of Google products.

They don’t have a solid grasp of English (or they’re just lazy), so they don’t comment. They use variable names that have nothing to do with the variables, or variable names that are acronyms. $IAKsom, $PRQ. They use global variables and gotos. They make every language into the language that they learned first.

They don’t understand relational databases. They use too many tables.

They code without designing, they design without coding. They stay up late finishing projects that are behind deadline. They’re underappreciated and overbudget.

They don’t test nearly enough. They get it working and then move on to the next task. They don’t document what they’ve done for the next person. They use clever programming tricks to write lines of code more ‘concisely’.

They code in a language because that’s what everybody else is using. They only have a hammer, and every problem looks like a nail. They use Design Patterns. They create massive object heirarchies.

They own their domain so thoroughly that they assume you give a shit and are willing to learn, too.

They use Java, PHP, XSLT. Their error messages are misspelled and grammatically incorrect. They use Hungarian Notation, and they use it wrong.

They try to quantify things that can’t be quantified. They overpromise and underdeliver.

They don’t understand recursion or pointers. They free their own memory and they are proud of it. They don’t encapsulate anything. They hard code important variables into their programs.

Their programs are so flexible that they could do anything. They have rules engines and customizations and parallel databases. They organize groups into projects and projects into domains.

They specialize in one technology in exclusion of all else.

They don’t build software to do one thing well. They build software to do many things, terribly.

They believe that all software should only do one thing well.

They see a contradiction and they can’t parse it. Everything has to be one or the other, it can’t be both!

They are so used to Linux that they cannot imagine how stupid users can really be.

They don’t know Linux at all.

They don’t assert() things. If it’s never supposed to happen, it will never happen, right?

They use Rational Rose, Oracle, massive software packages that suffer from the same defects as their own massive software packages.

They use underpowered free-as-in-beer solutions because they aren’t willing to pay for decent tools.

They make enterprise software. They make mid-market solutions. They use the word “solutions” and mean it. They make CMS’s. They promise that their software is so flexible that it can be customized any-which-way.

They are only compatible with IE6. They are only compatible with FireFox.

They never experiment with new languages. If it’s not going to be around in 10 years, what’s the point?

They never experiment with old languages. If nobody uses it anymore, what’s the point?

They’ll work with trendy technologies. They think that the fact that it’s an AJAX-enabled Ruby-on-rails Web 2.0 Adobe-Flex Fiesta Extravaganza will make all of their shortcomings go away.

They won’t budge from Waterfall. They hop on every management trend designed to improve the quality of their software. They’re certified… for Quality!

They work in big companies and small companies. They pull the wool over the eyes of people who don’t know better. They hire more of themselves. They respect bluster- clearly this guy knows something about C++!

They want it all in the spec. The spec is Lord and they never question the spec. To change the spec requires a 4-man team and a week of time.

They can’t decide whether to add a feature or not, so they just add the feature as an ‘option’.

They are in a GANTT chart.

They don’t usability test. They don’t load-test. By the time they do, it’s too late.

They remember algorithmic complexity, but they never really understood it that well and just hope to forget as much of it as possible.

They want to work at Google. They care more about their own personal projects. This is only their day-job.

They are crappy developers. I am one of them. I try not to be one of them. It’s not easy.

Once there was a horse tied up on the side of the street. Whenever someone tried to pass, the horse would kick them. Soon a crowd gathered around the horse until a wise man was seen coming close. The people said “This horse will surely kill anyone who tries to pass. What are we going to do?” The wise man looked at the horse, turned and walked down another street.




